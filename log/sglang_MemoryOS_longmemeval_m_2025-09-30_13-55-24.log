/home/shm/anaconda3/envs/rag/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:55:31.867437 2770326 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:55:31.867437 2770326 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-30 13:55:32] server_args=ServerArgs(model_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30004, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.98, max_running_requests=50, max_queued_requests=9223372036854775807, max_total_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1030813945, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-customer-labels', tokenizer_metrics_allowed_customer_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, enable_trace=False, oltp_traces_endpoint='localhost:4317', api_key=None, served_model_name='LLAMA', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='triton', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=True, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=True, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_cutedsl_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:55:32] Using default HuggingFace chat template with detected content format: string
/home/shm/anaconda3/envs/rag/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/shm/anaconda3/envs/rag/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:55:38.126892 2770650 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:55:38.126892 2770650 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0930 13:55:38.446456 2770651 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:55:38.446456 2770651 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:55:39] Init torch distributed begin.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-09-30 13:55:39] Init torch distributed ends. mem usage=0.00 GB
[2025-09-30 13:55:39] CUDA-fused xIELU not available (No module named 'xielu') – falling back to a Python version.
For CUDA xIELU (experimental), `pip install git+https://github.com/nickjbrowning/XIELU`
[2025-09-30 13:55:39] MOE_RUNNER_BACKEND is not initialized, using triton backend
[2025-09-30 13:55:40] Load weight begin. avail mem=23.13 GB
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.05s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.41it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]

[2025-09-30 13:55:42] Load weight end. type=LlamaForCausalLM, dtype=torch.bfloat16, avail mem=17.01 GB, mem usage=6.12 GB.
[2025-09-30 13:55:42] KV Cache is allocated. #tokens: 64000, K size: 3.42 GB, V size: 3.42 GB
[2025-09-30 13:55:42] Memory pool end. avail mem=10.14 GB
[2025-09-30 13:55:42] Capture cuda graph begin. This can take up to several minutes. avail mem=10.10 GB
[2025-09-30 13:55:42] Capture cuda graph bs [1, 2, 4, 8]
  0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=10.10 GB):   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=10.10 GB):  25%|██▌       | 1/4 [00:15<00:45, 15.13s/it]Capturing batches (bs=4 avail_mem=10.05 GB):  25%|██▌       | 1/4 [00:15<00:45, 15.13s/it]Capturing batches (bs=2 avail_mem=10.04 GB):  25%|██▌       | 1/4 [00:15<00:45, 15.13s/it]Capturing batches (bs=2 avail_mem=10.04 GB):  75%|███████▌  | 3/4 [00:15<00:03,  3.96s/it]Capturing batches (bs=1 avail_mem=10.04 GB):  75%|███████▌  | 3/4 [00:15<00:03,  3.96s/it]Capturing batches (bs=1 avail_mem=10.04 GB): 100%|██████████| 4/4 [00:15<00:00,  3.82s/it]
[2025-09-30 13:55:57] Capture cuda graph end. Time elapsed: 15.67 s. mem usage=0.07 GB. avail mem=10.04 GB.
[2025-09-30 13:55:58] max_total_num_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, max_running_requests=50, context_len=131072, available_gpu_mem=10.04 GB
[2025-09-30 13:55:58] INFO:     Started server process [2770326]
[2025-09-30 13:55:58] INFO:     Waiting for application startup.
[2025-09-30 13:55:58] INFO:     Application startup complete.
[2025-09-30 13:55:58] INFO:     Uvicorn running on http://0.0.0.0:30004 (Press CTRL+C to quit)
[2025-09-30 13:55:59] INFO:     127.0.0.1:51778 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 13:55:59] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:51792 - "POST /generate HTTP/1.1" 200 OK
[2025-09-30 13:56:00] The server is fired up and ready to roll!
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:29] Decode batch. #running-req: 1, #token: 625, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1.29, #queue-req: 0, 
[2025-09-30 13:56:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:29] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.32, #queue-req: 0, 
[2025-09-30 13:56:30] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.35, #queue-req: 0, 
[2025-09-30 13:56:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:30] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:30] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.36, #queue-req: 0, 
[2025-09-30 13:56:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:30] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:31] Prefill batch. #new-seq: 1, #new-token: 745, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:31] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 445, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.52, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.84, #queue-req: 0, 
[2025-09-30 13:56:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:31] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.05, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.00, #queue-req: 0, 
[2025-09-30 13:56:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:32] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:32] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:32] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.53, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 579, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.84, #queue-req: 0, 
[2025-09-30 13:56:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:33] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.06, #queue-req: 0, 
[2025-09-30 13:56:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:33] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.05, #queue-req: 0, 
[2025-09-30 13:56:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:33] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:34] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:34] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.68, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:56:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:34] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.09, #queue-req: 0, 
[2025-09-30 13:56:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:35] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:35] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:35] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:35] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 474, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.60, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 514, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.56, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.96, #queue-req: 0, 
[2025-09-30 13:56:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:36] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.43, #queue-req: 0, 
[2025-09-30 13:56:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:36] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.22, #queue-req: 0, 
[2025-09-30 13:56:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:36] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:37] Prefill batch. #new-seq: 1, #new-token: 583, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:37] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.50, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.84, #queue-req: 0, 
[2025-09-30 13:56:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:37] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.85, #queue-req: 0, 
[2025-09-30 13:56:38] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.13, #queue-req: 0, 
[2025-09-30 13:56:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:38] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:38] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.19, #queue-req: 0, 
[2025-09-30 13:56:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:38] Prefill batch. #new-seq: 1, #new-token: 646, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:38] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:39] Decode batch. #running-req: 1, #token: 499, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.68, #queue-req: 0, 
[2025-09-30 13:56:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:39] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:39] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 13:56:39] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.06, #queue-req: 0, 
[2025-09-30 13:56:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:39] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:39] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.58, #queue-req: 0, 
[2025-09-30 13:56:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:40] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:40] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.89, #queue-req: 0, 
[2025-09-30 13:56:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.80, #queue-req: 0, 
[2025-09-30 13:56:40] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.88, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 417, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.11, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.74, #queue-req: 0, 
[2025-09-30 13:56:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:42] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.92, #queue-req: 0, 
[2025-09-30 13:56:43] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.91, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.69, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.93, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 287, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:44] Prefill batch. #new-seq: 1, #new-token: 1858, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 1902, token usage: 0.03, cuda graph: True, gen throughput (token/s): 88.26, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 1942, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 1982, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 2022, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 2062, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.30, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 2102, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.96, #queue-req: 0, 
[2025-09-30 13:56:46] Decode batch. #running-req: 1, #token: 2142, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.94, #queue-req: 0, 
[2025-09-30 13:56:46] Decode batch. #running-req: 1, #token: 2182, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 13:56:46] Decode batch. #running-req: 1, #token: 2222, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 2262, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 2302, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 13:56:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:47] Prefill batch. #new-seq: 1, #new-token: 1838, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 1874, token usage: 0.03, cuda graph: True, gen throughput (token/s): 98.34, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.84, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 13:56:48] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] Decode batch. #running-req: 1, #token: 392, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.42, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 1007, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 704, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] Decode batch. #running-req: 1, #token: 899, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.48, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 939, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 13:56:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:50] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 125.55, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 13:56:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:50] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.12, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 1450, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 752, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] Decode batch. #running-req: 1, #token: 921, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.61, #queue-req: 0, 
[2025-09-30 13:56:51] Decode batch. #running-req: 1, #token: 961, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.85, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 13:56:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:52] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:52] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 833, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.20, #queue-req: 0, 
[2025-09-30 13:56:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 1211, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 464, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] Decode batch. #running-req: 1, #token: 654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.61, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 13:56:53] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 13:56:54] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.39, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 533, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 537, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.75, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 1043, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 765, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.78, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 13:56:56] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:56:56] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 583, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 999, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.76, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:57] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.66, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.88, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 1055, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.64, #queue-req: 0, 
[2025-09-30 13:56:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.60, #queue-req: 0, 
[2025-09-30 13:56:58] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.82, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 639, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 89.69, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 711, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 1203, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.04, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.80, #queue-req: 0, 
[2025-09-30 13:57:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:00] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.85, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.03, #queue-req: 0, 
[2025-09-30 13:57:01] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 13:57:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:01] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:01] Prefill batch. #new-seq: 1, #new-token: 561, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:01] Decode batch. #running-req: 1, #token: 652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.83, #queue-req: 0, 
[2025-09-30 13:57:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:01] Prefill batch. #new-seq: 1, #new-token: 1216, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:01] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.96, #queue-req: 0, 
[2025-09-30 13:57:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:02] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.03, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:57:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:03] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:03] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:03] Prefill batch. #new-seq: 1, #new-token: 1310, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:03] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 828, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.05, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 13:57:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:04] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.35, #queue-req: 0, 
[2025-09-30 13:57:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:04] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.09, #queue-req: 0, 
[2025-09-30 13:57:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:04] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:05] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:05] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.57, #queue-req: 0, 
[2025-09-30 13:57:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:05] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 726, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:05] Prefill batch. #new-seq: 1, #new-token: 1329, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:05] Prefill batch. #new-seq: 1, #new-token: 675, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:05] Decode batch. #running-req: 1, #token: 852, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.09, #queue-req: 0, 
[2025-09-30 13:57:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:05] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:06] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 13:57:06] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:06] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:06] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:06] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.43, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 1238, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.06, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.83, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 237, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 13:57:08] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 13:57:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:08] Prefill batch. #new-seq: 1, #new-token: 1232, #cached-token: 117, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:08] Prefill batch. #new-seq: 1, #new-token: 709, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:08] Decode batch. #running-req: 1, #token: 883, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.94, #queue-req: 0, 
[2025-09-30 13:57:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:08] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 13:57:09] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 13:57:09] Decode batch. #running-req: 1, #token: 405, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:57:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 704, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] Decode batch. #running-req: 1, #token: 793, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.24, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 775, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] Decode batch. #running-req: 1, #token: 799, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.79, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.55, #queue-req: 0, 
[2025-09-30 13:57:11] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.27, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.95, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 136, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.38, #queue-req: 0, 
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.60, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:14] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.07, #queue-req: 0, 
[2025-09-30 13:57:14] Decode batch. #running-req: 1, #token: 662, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.42, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:14] Decode batch. #running-req: 1, #token: 459, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 13:57:15] Decode batch. #running-req: 1, #token: 499, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 13:57:15] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.81, #queue-req: 0, 
[2025-09-30 13:57:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:15] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:15] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 535, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.40, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 514, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.36, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.05, #queue-req: 0, 
[2025-09-30 13:57:17] Decode batch. #running-req: 1, #token: 431, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 13:57:17] Decode batch. #running-req: 1, #token: 471, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.75, #queue-req: 0, 
[2025-09-30 13:57:18] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 464, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.93, #queue-req: 0, 
[2025-09-30 13:57:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:18] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.82, #queue-req: 0, 
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 403, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.50, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.64, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 431, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 13:57:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:20] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.28, #queue-req: 0, 
[2025-09-30 13:57:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:20] Prefill batch. #new-seq: 1, #new-token: 943, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:21] Prefill batch. #new-seq: 1, #new-token: 672, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:21] Decode batch. #running-req: 1, #token: 872, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.64, #queue-req: 0, 
[2025-09-30 13:57:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:21] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:21] Decode batch. #running-req: 1, #token: 586, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.18, #queue-req: 0, 
[2025-09-30 13:57:21] Decode batch. #running-req: 1, #token: 626, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.29, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.13, #queue-req: 0, 
[2025-09-30 13:57:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:22] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:22] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.13, #queue-req: 0, 
[2025-09-30 13:57:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:22] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:23] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.10, #queue-req: 0, 
[2025-09-30 13:57:23] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 13:57:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:23] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:23] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:24] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:24] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.25, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 694, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.15, #queue-req: 0, 
[2025-09-30 13:57:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:24] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.54, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 13:57:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:25] Prefill batch. #new-seq: 1, #new-token: 1092, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:25] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:25] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.73, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.93, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:57:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:26] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:26] Prefill batch. #new-seq: 1, #new-token: 606, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.45, #queue-req: 0, 
[2025-09-30 13:57:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:27] Prefill batch. #new-seq: 1, #new-token: 1255, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:27] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:27] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.86, #queue-req: 0, 
[2025-09-30 13:57:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:27] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:27] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.30, #queue-req: 0, 
[2025-09-30 13:57:28] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:28] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:28] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:28] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.32, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:28] Prefill batch. #new-seq: 1, #new-token: 1230, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:28] Prefill batch. #new-seq: 1, #new-token: 583, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:29] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.12, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 13:57:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] Decode batch. #running-req: 1, #token: 665, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.54, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 1090, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] Decode batch. #running-req: 1, #token: 702, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.93, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.58, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] Decode batch. #running-req: 1, #token: 598, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.42, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 1064, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 73.18, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.00, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.67, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 627, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] Decode batch. #running-req: 1, #token: 631, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.88, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 1191, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.64, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.42, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.11, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] Decode batch. #running-req: 1, #token: 734, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.30, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:35] Prefill batch. #new-seq: 1, #new-token: 1351, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:35] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] Decode batch. #running-req: 1, #token: 909, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.28, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.38, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 788, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.70, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 1493, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 784, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:37] Decode batch. #running-req: 1, #token: 972, token usage: 0.02, cuda graph: True, gen throughput (token/s): 63.09, #queue-req: 0, 
[2025-09-30 13:57:37] Decode batch. #running-req: 1, #token: 1012, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.18, #queue-req: 0, 
[2025-09-30 13:57:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:38] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:38] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 870, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.26, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:39] Prefill batch. #new-seq: 1, #new-token: 1305, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:39] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:39] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.11, #queue-req: 0, 
[2025-09-30 13:57:39] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.65, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:40] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:40] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.88, #queue-req: 0, 
[2025-09-30 13:57:40] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 13:57:40] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:40] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:40] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] Decode batch. #running-req: 1, #token: 617, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.81, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 595, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] Decode batch. #running-req: 1, #token: 615, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.65, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 1026, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 220, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:42] Decode batch. #running-req: 1, #token: 797, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.60, #queue-req: 0, 
[2025-09-30 13:57:42] Decode batch. #running-req: 1, #token: 837, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.40, #queue-req: 0, 
[2025-09-30 13:57:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:42] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:42] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.10, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:57:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.98, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 572, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] Decode batch. #running-req: 1, #token: 4574, token usage: 0.07, cuda graph: True, gen throughput (token/s): 40.58, #queue-req: 0, 
[2025-09-30 13:57:45] Decode batch. #running-req: 1, #token: 4614, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.92, #queue-req: 0, 
[2025-09-30 13:57:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:45] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] Decode batch. #running-req: 1, #token: 4607, token usage: 0.07, cuda graph: True, gen throughput (token/s): 71.31, #queue-req: 0, 
[2025-09-30 13:57:46] Decode batch. #running-req: 1, #token: 4647, token usage: 0.07, cuda graph: True, gen throughput (token/s): 122.09, #queue-req: 0, 
[2025-09-30 13:57:46] Decode batch. #running-req: 1, #token: 4687, token usage: 0.07, cuda graph: True, gen throughput (token/s): 122.02, #queue-req: 0, 
[2025-09-30 13:57:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:46] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:46] Decode batch. #running-req: 1, #token: 110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.46, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] Decode batch. #running-req: 1, #token: 4496, token usage: 0.07, cuda graph: True, gen throughput (token/s): 65.78, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4474, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:48] Decode batch. #running-req: 1, #token: 4483, token usage: 0.07, cuda graph: True, gen throughput (token/s): 69.91, #queue-req: 0, 
[2025-09-30 13:57:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:48] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:48] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:48] Prefill batch. #new-seq: 1, #new-token: 298, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:48] Decode batch. #running-req: 1, #token: 485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.56, #queue-req: 0, 
[2025-09-30 13:57:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:49] Decode batch. #running-req: 1, #token: 226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 13:57:49] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.11, #queue-req: 0, 
[2025-09-30 13:57:49] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 13:57:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.97, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.08, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.90, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.10, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.14, #queue-req: 0, 
[2025-09-30 13:57:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:52] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.57, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:57:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:52] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:52] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 230, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.24, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] Decode batch. #running-req: 1, #token: 481, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.24, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.03, #queue-req: 0, 
[2025-09-30 13:57:54] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.15, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.74, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 465, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.88, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:55] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:55] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.32, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.22, #queue-req: 0, 
[2025-09-30 13:57:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.96, #queue-req: 0, 
[2025-09-30 13:57:57] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.03, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:57] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:57] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:57] Decode batch. #running-req: 1, #token: 424, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.37, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:57] Prefill batch. #new-seq: 1, #new-token: 1900, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:58] Decode batch. #running-req: 1, #token: 1964, token usage: 0.03, cuda graph: True, gen throughput (token/s): 59.60, #queue-req: 0, 
[2025-09-30 13:57:58] Decode batch. #running-req: 1, #token: 2004, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.30, #queue-req: 0, 
[2025-09-30 13:57:58] Decode batch. #running-req: 1, #token: 2044, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.38, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 2084, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 2124, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 2164, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 2204, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 2244, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 2284, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 13:58:01] Decode batch. #running-req: 1, #token: 2324, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.54, #queue-req: 0, 
[2025-09-30 13:58:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:01] Prefill batch. #new-seq: 1, #new-token: 1880, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:01] Decode batch. #running-req: 1, #token: 1927, token usage: 0.03, cuda graph: True, gen throughput (token/s): 98.54, #queue-req: 0, 
[2025-09-30 13:58:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:01] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:01] Decode batch. #running-req: 1, #token: 922, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.40, #queue-req: 0, 
[2025-09-30 13:58:02] Decode batch. #running-req: 1, #token: 962, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 13:58:02] Decode batch. #running-req: 1, #token: 1002, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.86, #queue-req: 0, 
[2025-09-30 13:58:02] Decode batch. #running-req: 1, #token: 1042, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.65, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 1082, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 1122, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 1162, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 1202, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.27, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 1242, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 1282, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.17, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 1322, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 1362, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 1402, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 1442, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 1482, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 1522, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.58, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 1562, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.29, #queue-req: 0, 
[2025-09-30 13:58:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:07] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:07] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.08, #queue-req: 0, 
[2025-09-30 13:58:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:07] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.25, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.01, #queue-req: 0, 
[2025-09-30 13:58:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:08] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:08] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:08] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:08] Decode batch. #running-req: 1, #token: 572, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.89, #queue-req: 0, 
[2025-09-30 13:58:08] Decode batch. #running-req: 1, #token: 612, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.14, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.03, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 692, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.91, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 732, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.73, #queue-req: 0, 
[2025-09-30 13:58:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:09] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:10] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.53, #queue-req: 0, 
[2025-09-30 13:58:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:10] Prefill batch. #new-seq: 1, #new-token: 929, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:10] Decode batch. #running-req: 1, #token: 1080, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.43, #queue-req: 0, 
[2025-09-30 13:58:10] Decode batch. #running-req: 1, #token: 1120, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 1160, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 1200, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.35, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 1240, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 1280, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 1320, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 1360, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 1400, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 1440, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 1480, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 1520, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.57, #queue-req: 0, 
[2025-09-30 13:58:14] Decode batch. #running-req: 1, #token: 1560, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 13:58:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:14] Prefill batch. #new-seq: 1, #new-token: 878, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:14] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:14] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.62, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.81, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 1010, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 637, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.03, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.33, #queue-req: 0, 
[2025-09-30 13:58:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:16] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.85, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 13:58:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] Decode batch. #running-req: 1, #token: 554, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.27, #queue-req: 0, 
[2025-09-30 13:58:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 538, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.79, #queue-req: 0, 
[2025-09-30 13:58:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:18] Prefill batch. #new-seq: 1, #new-token: 1011, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:18] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:18] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.51, #queue-req: 0, 
[2025-09-30 13:58:18] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 13:58:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:18] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:19] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.54, #queue-req: 0, 
[2025-09-30 13:58:19] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:58:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:19] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.38, #queue-req: 0, 
[2025-09-30 13:58:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:20] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:20] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 614, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] Decode batch. #running-req: 1, #token: 617, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.15, #queue-req: 0, 
[2025-09-30 13:58:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:20] Prefill batch. #new-seq: 1, #new-token: 967, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:20] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.69, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:21] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.98, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:21] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.46, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:21] Prefill batch. #new-seq: 1, #new-token: 425, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:22] Prefill batch. #new-seq: 1, #new-token: 1159, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:22] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:22] Decode batch. #running-req: 1, #token: 905, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.90, #queue-req: 0, 
[2025-09-30 13:58:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:22] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:22] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.67, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 13:58:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:23] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:23] Prefill batch. #new-seq: 1, #new-token: 731, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.76, #queue-req: 0, 
[2025-09-30 13:58:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:24] Prefill batch. #new-seq: 1, #new-token: 1169, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:24] Prefill batch. #new-seq: 1, #new-token: 440, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:24] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:24] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.26, #queue-req: 0, 
[2025-09-30 13:58:24] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 13:58:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:25] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.00, #queue-req: 0, 
[2025-09-30 13:58:25] Prefill batch. #new-seq: 1, #new-token: 436, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.28, #queue-req: 0, 
[2025-09-30 13:58:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:26] Prefill batch. #new-seq: 1, #new-token: 892, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:26] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:26] Decode batch. #running-req: 1, #token: 659, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.19, #queue-req: 0, 
[2025-09-30 13:58:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:26] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:26] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.93, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 13:58:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:27] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:27] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:28] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.70, #queue-req: 0, 
[2025-09-30 13:58:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 525, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:28] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.22, #queue-req: 0, 
[2025-09-30 13:58:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 870, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 613, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.42, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.02, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.03, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:30] Prefill batch. #new-seq: 1, #new-token: 852, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:30] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.74, #queue-req: 0, 
[2025-09-30 13:58:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:30] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:30] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.43, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 683, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.27, #queue-req: 0, 
[2025-09-30 13:58:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:31] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:58:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:31] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] Decode batch. #running-req: 1, #token: 517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.16, #queue-req: 0, 
[2025-09-30 13:58:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 1282, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 848, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] Decode batch. #running-req: 1, #token: 1033, token usage: 0.02, cuda graph: True, gen throughput (token/s): 53.27, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:33] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.15, #queue-req: 0, 
[2025-09-30 13:58:33] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:58:33] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:34] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:34] Decode batch. #running-req: 1, #token: 933, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.57, #queue-req: 0, 
[2025-09-30 13:58:34] Decode batch. #running-req: 1, #token: 973, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 13:58:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 913, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:35] Decode batch. #running-req: 1, #token: 918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.92, #queue-req: 0, 
[2025-09-30 13:58:35] Decode batch. #running-req: 1, #token: 958, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.01, #queue-req: 0, 
[2025-09-30 13:58:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 1240, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 583, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.45, #queue-req: 0, 
[2025-09-30 13:58:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:36] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.04, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 13:58:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:37] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:37] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.36, #queue-req: 0, 
[2025-09-30 13:58:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:37] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:37] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:37] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 466, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:37] Decode batch. #running-req: 1, #token: 472, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.88, #queue-req: 0, 
[2025-09-30 13:58:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:38] Prefill batch. #new-seq: 1, #new-token: 890, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:38] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.67, #queue-req: 0, 
[2025-09-30 13:58:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:38] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.05, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 566, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:40] Prefill batch. #new-seq: 1, #new-token: 957, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:40] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:40] Decode batch. #running-req: 1, #token: 632, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.55, #queue-req: 0, 
[2025-09-30 13:58:40] Decode batch. #running-req: 1, #token: 672, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 13:58:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:40] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:40] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 13:58:41] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 462, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:41] Decode batch. #running-req: 1, #token: 554, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.33, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:42] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:42] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.32, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 13:58:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] Decode batch. #running-req: 1, #token: 547, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.19, #queue-req: 0, 
[2025-09-30 13:58:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 13:58:44] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.91, #queue-req: 0, 
[2025-09-30 13:58:44] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:44] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:44] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:45] Prefill batch. #new-seq: 1, #new-token: 882, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:45] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.15, #queue-req: 0, 
[2025-09-30 13:58:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:45] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.04, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] Decode batch. #running-req: 1, #token: 631, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.01, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 1180, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 631, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.23, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 13:58:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:47] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 13:58:48] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:48] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:48] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.99, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:48] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:48] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.88, #queue-req: 0, 
[2025-09-30 13:58:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 699, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 13:58:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 1018, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 476, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 659, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.27, #queue-req: 0, 
[2025-09-30 13:58:50] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 13:58:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:50] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:50] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 13:58:50] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.59, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 1004, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:52] Decode batch. #running-req: 1, #token: 792, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.30, #queue-req: 0, 
[2025-09-30 13:58:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:52] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:52] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.11, #queue-req: 0, 
[2025-09-30 13:58:52] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 13:58:52] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:58:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:53] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:53] Prefill batch. #new-seq: 1, #new-token: 611, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] Decode batch. #running-req: 1, #token: 712, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.98, #queue-req: 0, 
[2025-09-30 13:58:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:53] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:53] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 684, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.58, #queue-req: 0, 
[2025-09-30 13:58:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 1090, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:54] Decode batch. #running-req: 1, #token: 713, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.96, #queue-req: 0, 
[2025-09-30 13:58:54] Decode batch. #running-req: 1, #token: 753, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 13:58:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:55] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:55] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.16, #queue-req: 0, 
[2025-09-30 13:58:55] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 13:58:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:55] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:56] Decode batch. #running-req: 1, #token: 556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.55, #queue-req: 0, 
[2025-09-30 13:58:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 1033, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:56] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.56, #queue-req: 0, 
[2025-09-30 13:58:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.30, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.72, #queue-req: 0, 
[2025-09-30 13:58:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:57] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] Decode batch. #running-req: 1, #token: 125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 87.20, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 979, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 425, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] Decode batch. #running-req: 1, #token: 600, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.93, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.48, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 379, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 13:58:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:59] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:59] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:59] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:00] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.48, #queue-req: 0, 
[2025-09-30 13:59:00] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.18, #queue-req: 0, 
[2025-09-30 13:59:00] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 13:59:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:00] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:00] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:01] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:01] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:01] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.15, #queue-req: 0, 
[2025-09-30 13:59:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:01] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:01] Decode batch. #running-req: 1, #token: 215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.05, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.16, #queue-req: 0, 
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 108.33, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:03] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.53, #queue-req: 0, 
[2025-09-30 13:59:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:03] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:03] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:03] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.00, #queue-req: 0, 
[2025-09-30 13:59:03] Decode batch. #running-req: 1, #token: 532, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.08, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 13:59:04] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] Decode batch. #running-req: 1, #token: 379, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.70, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:05] Decode batch. #running-req: 1, #token: 518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.52, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:06] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.70, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:06] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.90, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] Decode batch. #running-req: 1, #token: 209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 13:59:07] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.23, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.35, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 380, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:09] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.18, #queue-req: 0, 
[2025-09-30 13:59:09] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.32, #queue-req: 0, 
[2025-09-30 13:59:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:09] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.11, #queue-req: 0, 
[2025-09-30 13:59:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:10] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:10] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:10] Decode batch. #running-req: 1, #token: 509, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.69, #queue-req: 0, 
[2025-09-30 13:59:10] Decode batch. #running-req: 1, #token: 549, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.01, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.75, #queue-req: 0, 
[2025-09-30 13:59:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:11] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.27, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.88, #queue-req: 0, 
[2025-09-30 13:59:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] Decode batch. #running-req: 1, #token: 412, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.79, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] Decode batch. #running-req: 1, #token: 516, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.51, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.49, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.96, #queue-req: 0, 
[2025-09-30 13:59:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:13] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:13] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 393, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.65, #queue-req: 0, 
[2025-09-30 13:59:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:14] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:14] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:14] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.51, #queue-req: 0, 
[2025-09-30 13:59:14] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.50, #queue-req: 0, 
[2025-09-30 13:59:15] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.88, #queue-req: 0, 
[2025-09-30 13:59:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:15] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:15] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 13:59:15] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 13:59:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:16] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:16] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:16] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.78, #queue-req: 0, 
[2025-09-30 13:59:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:16] Prefill batch. #new-seq: 1, #new-token: 649, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:16] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:17] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.12, #queue-req: 0, 
[2025-09-30 13:59:17] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.67, #queue-req: 0, 
[2025-09-30 13:59:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:17] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:17] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.37, #queue-req: 0, 
[2025-09-30 13:59:17] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:18] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:18] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:18] Decode batch. #running-req: 1, #token: 440, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.03, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:18] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:18] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:19] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.67, #queue-req: 0, 
[2025-09-30 13:59:19] Decode batch. #running-req: 1, #token: 410, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.88, #queue-req: 0, 
[2025-09-30 13:59:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:19] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:19] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.08, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.88, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 13:59:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:20] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 73.04, #queue-req: 0, 
[2025-09-30 13:59:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.12, #queue-req: 0, 
[2025-09-30 13:59:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 13:59:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 13:59:22] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:22] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.57, #queue-req: 0, 
[2025-09-30 13:59:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:23] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:23] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:23] Decode batch. #running-req: 1, #token: 474, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.54, #queue-req: 0, 
[2025-09-30 13:59:23] Decode batch. #running-req: 1, #token: 514, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.45, #queue-req: 0, 
[2025-09-30 13:59:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:24] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.27, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 13:59:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:24] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:25] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:25] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.02, #queue-req: 0, 
[2025-09-30 13:59:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:25] Prefill batch. #new-seq: 1, #new-token: 495, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:25] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:25] Decode batch. #running-req: 1, #token: 511, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.61, #queue-req: 0, 
[2025-09-30 13:59:26] Decode batch. #running-req: 1, #token: 551, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.89, #queue-req: 0, 
[2025-09-30 13:59:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:26] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:26] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 13:59:26] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:59:27] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.21, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 60.86, #queue-req: 0, 
[2025-09-30 13:59:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:28] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:59:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:28] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.20, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.80, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.79, #queue-req: 0, 
[2025-09-30 13:59:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:30] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.01, #queue-req: 0, 
[2025-09-30 13:59:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 13:59:31] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:31] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:31] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.57, #queue-req: 0, 
[2025-09-30 13:59:31] Decode batch. #running-req: 1, #token: 440, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.80, #queue-req: 0, 
[2025-09-30 13:59:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:31] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:32] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 13:59:32] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 13:59:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:32] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:32] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:32] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.93, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 373, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.97, #queue-req: 0, 
[2025-09-30 13:59:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:33] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.84, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.71, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.15, #queue-req: 0, 
[2025-09-30 13:59:35] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.12, #queue-req: 0, 
[2025-09-30 13:59:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:35] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:35] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:35] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:35] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.07, #queue-req: 0, 
[2025-09-30 13:59:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:36] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:36] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.44, #queue-req: 0, 
[2025-09-30 13:59:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:36] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.25, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.99, #queue-req: 0, 
[2025-09-30 13:59:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:36] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:36] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:37] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:37] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.70, #queue-req: 0, 
[2025-09-30 13:59:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:37] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.70, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.00, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:39] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.16, #queue-req: 0, 
[2025-09-30 13:59:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:39] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:39] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.46, #queue-req: 0, 
[2025-09-30 13:59:39] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:59:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:39] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:39] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:40] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.92, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 13:59:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:40] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 85.70, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.36, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.96, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 13:59:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:42] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:42] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.68, #queue-req: 0, 
[2025-09-30 13:59:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:43] Prefill batch. #new-seq: 1, #new-token: 939, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:43] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:43] Decode batch. #running-req: 1, #token: 944, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.84, #queue-req: 0, 
[2025-09-30 13:59:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:43] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:43] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 13:59:44] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 13:59:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:44] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:44] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:44] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.95, #queue-req: 0, 
[2025-09-30 13:59:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:45] Prefill batch. #new-seq: 1, #new-token: 1582, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:45] Prefill batch. #new-seq: 1, #new-token: 838, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:45] Decode batch. #running-req: 1, #token: 1038, token usage: 0.02, cuda graph: True, gen throughput (token/s): 52.04, #queue-req: 0, 
[2025-09-30 13:59:45] Decode batch. #running-req: 1, #token: 1078, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 13:59:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:45] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:46] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.42, #queue-req: 0, 
[2025-09-30 13:59:46] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 13:59:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:46] Prefill batch. #new-seq: 1, #new-token: 1466, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:46] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.94, #queue-req: 0, 
[2025-09-30 13:59:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:47] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.08, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:59:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:48] Prefill batch. #new-seq: 1, #new-token: 1357, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:48] Prefill batch. #new-seq: 1, #new-token: 777, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:48] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 50.00, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 1006, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 13:59:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:49] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.89, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 13:59:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:49] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:50] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.54, #queue-req: 0, 
[2025-09-30 13:59:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:50] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:50] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:50] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 0, token usage: 0.06, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 4870, token usage: 0.08, cuda graph: True, gen throughput (token/s): 34.89, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 4910, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.49, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 4950, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.48, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 4990, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.42, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 5030, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.47, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 5070, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.42, #queue-req: 0, 
[2025-09-30 13:59:53] Decode batch. #running-req: 1, #token: 5110, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.42, #queue-req: 0, 
[2025-09-30 13:59:53] Decode batch. #running-req: 1, #token: 5150, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.05, #queue-req: 0, 
[2025-09-30 13:59:53] Decode batch. #running-req: 1, #token: 5190, token usage: 0.08, cuda graph: True, gen throughput (token/s): 120.97, #queue-req: 0, 
[2025-09-30 13:59:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:54] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:54] Prefill batch. #new-seq: 1, #new-token: 701, #cached-token: 0, token usage: 0.06, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:54] Decode batch. #running-req: 1, #token: 4834, token usage: 0.08, cuda graph: True, gen throughput (token/s): 67.56, #queue-req: 0, 
[2025-09-30 13:59:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:54] Prefill batch. #new-seq: 1, #new-token: 982, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:54] Decode batch. #running-req: 1, #token: 1028, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.39, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 1068, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.54, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 1108, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 1148, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 1188, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 13:59:56] Decode batch. #running-req: 1, #token: 1228, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.26, #queue-req: 0, 
[2025-09-30 13:59:56] Decode batch. #running-req: 1, #token: 1268, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 13:59:56] Decode batch. #running-req: 1, #token: 1308, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 13:59:57] Decode batch. #running-req: 1, #token: 1348, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 13:59:57] Decode batch. #running-req: 1, #token: 1388, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 13:59:57] Decode batch. #running-req: 1, #token: 1428, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 1468, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.64, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 1508, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.65, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 1548, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 13:59:59] Decode batch. #running-req: 1, #token: 1588, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 13:59:59] Decode batch. #running-req: 1, #token: 1628, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 13:59:59] Decode batch. #running-req: 1, #token: 1668, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 13:59:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:00] Prefill batch. #new-seq: 1, #new-token: 1507, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.82, #queue-req: 0, 
[2025-09-30 14:00:00] Prefill batch. #new-seq: 1, #new-token: 784, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 988, token usage: 0.02, cuda graph: True, gen throughput (token/s): 113.00, #queue-req: 0, 
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 1028, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.07, #queue-req: 0, 
[2025-09-30 14:00:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:01] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:01] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.97, #queue-req: 0, 
[2025-09-30 14:00:01] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:00:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:02] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:02] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:02] Decode batch. #running-req: 1, #token: 4788, token usage: 0.07, cuda graph: True, gen throughput (token/s): 37.05, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 4828, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.88, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 4868, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.84, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 4908, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.47, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 4948, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.44, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 4988, token usage: 0.08, cuda graph: True, gen throughput (token/s): 121.52, #queue-req: 0, 
[2025-09-30 14:00:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:04] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:04] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 4743, token usage: 0.07, cuda graph: True, gen throughput (token/s): 70.36, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 4783, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.94, #queue-req: 0, 
[2025-09-30 14:00:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:05] Prefill batch. #new-seq: 1, #new-token: 859, #cached-token: 218, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 1084, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.33, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 1124, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:00:06] Decode batch. #running-req: 1, #token: 1164, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.33, #queue-req: 0, 
[2025-09-30 14:00:06] Decode batch. #running-req: 1, #token: 1204, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.23, #queue-req: 0, 
[2025-09-30 14:00:06] Decode batch. #running-req: 1, #token: 1244, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 1284, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.16, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 1324, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 1364, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1404, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1444, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.64, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1484, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1524, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1564, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.34, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1604, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1644, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 1684, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 1724, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 1764, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:00:11] Decode batch. #running-req: 1, #token: 1804, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.85, #queue-req: 0, 
[2025-09-30 14:00:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:11] Prefill batch. #new-seq: 1, #new-token: 1507, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:11] Prefill batch. #new-seq: 1, #new-token: 730, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:11] Decode batch. #running-req: 1, #token: 910, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.22, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 950, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.24, #queue-req: 0, 
[2025-09-30 14:00:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:12] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.73, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:00:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:13] Prefill batch. #new-seq: 1, #new-token: 777, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.05, #queue-req: 0, 
[2025-09-30 14:00:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:13] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:13] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:13] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.46, #queue-req: 0, 
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.09, #queue-req: 0, 
[2025-09-30 14:00:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:00:14] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:14] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:15] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:15] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:15] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.94, #queue-req: 0, 
[2025-09-30 14:00:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:15] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:15] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.94, #queue-req: 0, 
[2025-09-30 14:00:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:15] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:16] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.97, #queue-req: 0, 
[2025-09-30 14:00:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:16] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.46, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.98, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] Decode batch. #running-req: 1, #token: 163, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.80, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 158, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] Decode batch. #running-req: 1, #token: 167, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.73, #queue-req: 0, 
[2025-09-30 14:00:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:18] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:18] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:18] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.29, #queue-req: 0, 
[2025-09-30 14:00:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:18] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:18] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.96, #queue-req: 0, 
[2025-09-30 14:00:19] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.93, #queue-req: 0, 
[2025-09-30 14:00:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:19] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:19] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.16, #queue-req: 0, 
[2025-09-30 14:00:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:20] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:20] Decode batch. #running-req: 1, #token: 751, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.82, #queue-req: 0, 
[2025-09-30 14:00:20] Decode batch. #running-req: 1, #token: 791, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.43, #queue-req: 0, 
[2025-09-30 14:00:21] Decode batch. #running-req: 1, #token: 831, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:00:21] Decode batch. #running-req: 1, #token: 871, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.17, #queue-req: 0, 
[2025-09-30 14:00:21] Decode batch. #running-req: 1, #token: 911, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.10, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 951, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.03, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 991, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 1031, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.80, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 1071, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 1111, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.42, #queue-req: 0, 
[2025-09-30 14:00:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:23] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.34, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.77, #queue-req: 0, 
[2025-09-30 14:00:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:23] Prefill batch. #new-seq: 1, #new-token: 1173, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:24] Decode batch. #running-req: 1, #token: 1333, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.88, #queue-req: 0, 
[2025-09-30 14:00:24] Decode batch. #running-req: 1, #token: 1373, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:00:24] Decode batch. #running-req: 1, #token: 1413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1453, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1493, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.57, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1533, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.55, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1613, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1653, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1693, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.96, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1733, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1773, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1813, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.71, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1853, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1893, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.35, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1933, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.38, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 1973, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.35, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 2013, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.34, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 2053, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.29, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 2093, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 2133, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 2173, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.71, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 2213, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 2253, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.66, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 2293, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.70, #queue-req: 0, 
[2025-09-30 14:00:32] Decode batch. #running-req: 1, #token: 2333, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.35, #queue-req: 0, 
[2025-09-30 14:00:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:32] Prefill batch. #new-seq: 1, #new-token: 792, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:32] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:32] Decode batch. #running-req: 1, #token: 795, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.67, #queue-req: 0, 
[2025-09-30 14:00:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:32] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.06, #queue-req: 0, 
[2025-09-30 14:00:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:33] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:33] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 703, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.22, #queue-req: 0, 
[2025-09-30 14:00:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:34] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:34] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 696, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:34] Decode batch. #running-req: 1, #token: 701, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.84, #queue-req: 0, 
[2025-09-30 14:00:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:34] Prefill batch. #new-seq: 1, #new-token: 1215, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:35] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.62, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:00:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:35] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.28, #queue-req: 0, 
[2025-09-30 14:00:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:36] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:36] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.95, #queue-req: 0, 
[2025-09-30 14:00:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:36] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:36] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:36] Decode batch. #running-req: 1, #token: 1158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 53.40, #queue-req: 0, 
[2025-09-30 14:00:37] Decode batch. #running-req: 1, #token: 1198, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 14:00:37] Decode batch. #running-req: 1, #token: 1238, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.26, #queue-req: 0, 
[2025-09-30 14:00:37] Decode batch. #running-req: 1, #token: 1278, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 1318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 1358, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 1398, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:00:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:39] Decode batch. #running-req: 1, #token: 1139, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.78, #queue-req: 0, 
[2025-09-30 14:00:39] Decode batch. #running-req: 1, #token: 1179, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:00:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 1314, #cached-token: 136, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:39] Decode batch. #running-req: 1, #token: 1459, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.36, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 1499, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.61, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 1539, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.56, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 1579, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 1619, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 1659, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 1699, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 1739, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 1779, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.91, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 1819, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.69, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 1859, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:00:43] Decode batch. #running-req: 1, #token: 1899, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:00:43] Decode batch. #running-req: 1, #token: 1939, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:00:43] Decode batch. #running-req: 1, #token: 1979, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 2019, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 2059, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.26, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 2099, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 2139, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 2179, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 2219, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:00:46] Decode batch. #running-req: 1, #token: 2259, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:00:46] Decode batch. #running-req: 1, #token: 2299, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.75, #queue-req: 0, 
[2025-09-30 14:00:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:46] Prefill batch. #new-seq: 1, #new-token: 1137, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:46] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.76, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.97, #queue-req: 0, 
[2025-09-30 14:00:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:47] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:00:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:48] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:48] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:48] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:48] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.81, #queue-req: 0, 
[2025-09-30 14:00:48] Prefill batch. #new-seq: 1, #new-token: 513, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.93, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 746, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.02, #queue-req: 0, 
[2025-09-30 14:00:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:49] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.61, #queue-req: 0, 
[2025-09-30 14:00:50] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.95, #queue-req: 0, 
[2025-09-30 14:00:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:50] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:50] Decode batch. #running-req: 1, #token: 516, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.18, #queue-req: 0, 
[2025-09-30 14:00:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:50] Prefill batch. #new-seq: 1, #new-token: 1160, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:50] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 928, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.94, #queue-req: 0, 
[2025-09-30 14:00:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:51] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.59, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 730, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 1266, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] Decode batch. #running-req: 1, #token: 714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.16, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:53] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:00:53] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:53] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:54] Prefill batch. #new-seq: 1, #new-token: 535, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:54] Prefill batch. #new-seq: 1, #new-token: 1149, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:54] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.94, #queue-req: 0, 
[2025-09-30 14:00:54] Prefill batch. #new-seq: 1, #new-token: 618, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:54] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.26, #queue-req: 0, 
[2025-09-30 14:00:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:54] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:55] Decode batch. #running-req: 1, #token: 456, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.21, #queue-req: 0, 
[2025-09-30 14:00:55] Decode batch. #running-req: 1, #token: 496, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:00:55] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.85, #queue-req: 0, 
[2025-09-30 14:00:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:55] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 613, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] Decode batch. #running-req: 1, #token: 698, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.23, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] Decode batch. #running-req: 1, #token: 134, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.62, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 683, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 1245, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:57] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.11, #queue-req: 0, 
[2025-09-30 14:00:57] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:58] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 14:00:58] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:00:58] Decode batch. #running-req: 1, #token: 467, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:00:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:58] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:58] Prefill batch. #new-seq: 1, #new-token: 631, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:59] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.40, #queue-req: 0, 
[2025-09-30 14:00:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:59] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 701, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:59] Decode batch. #running-req: 1, #token: 707, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.44, #queue-req: 0, 
[2025-09-30 14:01:00] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.69, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 722, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.25, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.94, #queue-req: 0, 
[2025-09-30 14:01:01] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:02] Decode batch. #running-req: 1, #token: 874, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.45, #queue-req: 0, 
[2025-09-30 14:01:02] Decode batch. #running-req: 1, #token: 914, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:01:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:02] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:02] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.95, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 522, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.99, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:03] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.68, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:03] Prefill batch. #new-seq: 1, #new-token: 688, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.22, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 1328, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:04] Decode batch. #running-req: 1, #token: 840, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.30, #queue-req: 0, 
[2025-09-30 14:01:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:05] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 14:01:05] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:01:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:05] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:05] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:05] Decode batch. #running-req: 1, #token: 712, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.36, #queue-req: 0, 
[2025-09-30 14:01:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:06] Prefill batch. #new-seq: 1, #new-token: 1364, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:06] Prefill batch. #new-seq: 1, #new-token: 730, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] Decode batch. #running-req: 1, #token: 906, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.89, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 946, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.26, #queue-req: 0, 
[2025-09-30 14:01:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:07] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.02, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:01:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 726, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] Decode batch. #running-req: 1, #token: 821, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.23, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 797, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:09] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.28, #queue-req: 0, 
[2025-09-30 14:01:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:09] Prefill batch. #new-seq: 1, #new-token: 2746, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:09] Decode batch. #running-req: 1, #token: 3125, token usage: 0.05, cuda graph: True, gen throughput (token/s): 48.44, #queue-req: 0, 
[2025-09-30 14:01:10] Decode batch. #running-req: 1, #token: 3165, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.44, #queue-req: 0, 
[2025-09-30 14:01:10] Decode batch. #running-req: 1, #token: 3205, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:01:10] Decode batch. #running-req: 1, #token: 3245, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:01:11] Decode batch. #running-req: 1, #token: 3285, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:01:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:11] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 14:01:11] Prefill batch. #new-seq: 1, #new-token: 2745, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:12] Decode batch. #running-req: 1, #token: 3107, token usage: 0.05, cuda graph: True, gen throughput (token/s): 87.20, #queue-req: 0, 
[2025-09-30 14:01:12] Decode batch. #running-req: 1, #token: 3147, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.53, #queue-req: 0, 
[2025-09-30 14:01:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:12] Prefill batch. #new-seq: 1, #new-token: 1111, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:12] Decode batch. #running-req: 1, #token: 1254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.14, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 1294, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.18, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 1334, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 1374, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 1414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:01:14] Decode batch. #running-req: 1, #token: 1454, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.66, #queue-req: 0, 
[2025-09-30 14:01:14] Decode batch. #running-req: 1, #token: 1494, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.64, #queue-req: 0, 
[2025-09-30 14:01:14] Decode batch. #running-req: 1, #token: 1534, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 14:01:15] Decode batch. #running-req: 1, #token: 1574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:01:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:15] Prefill batch. #new-seq: 1, #new-token: 1263, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:15] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:15] Decode batch. #running-req: 1, #token: 713, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.61, #queue-req: 0, 
[2025-09-30 14:01:16] Decode batch. #running-req: 1, #token: 753, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.12, #queue-req: 0, 
[2025-09-30 14:01:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:16] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:16] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.33, #queue-req: 0, 
[2025-09-30 14:01:16] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:01:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:16] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] Decode batch. #running-req: 1, #token: 627, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.88, #queue-req: 0, 
[2025-09-30 14:01:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 1229, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 697, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:18] Decode batch. #running-req: 1, #token: 892, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.66, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:18] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:18] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.50, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:18] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:18] Decode batch. #running-req: 1, #token: 112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.23, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:19] Decode batch. #running-req: 1, #token: 798, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.26, #queue-req: 0, 
[2025-09-30 14:01:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 1277, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:20] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.46, #queue-req: 0, 
[2025-09-30 14:01:20] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:01:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:20] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:20] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 14:01:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:21] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:21] Prefill batch. #new-seq: 1, #new-token: 584, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.07, #queue-req: 0, 
[2025-09-30 14:01:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.94, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 656, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] Decode batch. #running-req: 1, #token: 688, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.77, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:23] Prefill batch. #new-seq: 1, #new-token: 1162, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:23] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 757, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.54, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 797, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:01:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:23] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.62, #queue-req: 0, 
[2025-09-30 14:01:24] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 14:01:24] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:24] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:24] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] Decode batch. #running-req: 1, #token: 674, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.72, #queue-req: 0, 
[2025-09-30 14:01:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:25] Prefill batch. #new-seq: 1, #new-token: 1120, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:25] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:25] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.83, #queue-req: 0, 
[2025-09-30 14:01:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:26] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 14:01:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:26] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:26] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 620, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.98, #queue-req: 0, 
[2025-09-30 14:01:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:27] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 615, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:27] Decode batch. #running-req: 1, #token: 619, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.87, #queue-req: 0, 
[2025-09-30 14:01:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:28] Prefill batch. #new-seq: 1, #new-token: 1218, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:28] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:28] Decode batch. #running-req: 1, #token: 865, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.38, #queue-req: 0, 
[2025-09-30 14:01:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:28] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:28] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.57, #queue-req: 0, 
[2025-09-30 14:01:29] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:01:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:29] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:29] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.10, #queue-req: 0, 
[2025-09-30 14:01:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:29] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:30] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:30] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.06, #queue-req: 0, 
[2025-09-30 14:01:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:30] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 747, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:30] Prefill batch. #new-seq: 1, #new-token: 1306, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:31] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.36, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:01:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:31] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 128.19, #queue-req: 0, 
[2025-09-30 14:01:32] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 14:01:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:32] Prefill batch. #new-seq: 1, #new-token: 1138, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:32] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:32] Decode batch. #running-req: 1, #token: 698, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.28, #queue-req: 0, 
[2025-09-30 14:01:33] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:01:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:33] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 203, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:33] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:01:33] Decode batch. #running-req: 1, #token: 380, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.58, #queue-req: 0, 
[2025-09-30 14:01:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:34] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:01:34] Prefill batch. #new-seq: 1, #new-token: 1143, #cached-token: 85, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:34] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:34] Decode batch. #running-req: 1, #token: 844, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.56, #queue-req: 0, 
[2025-09-30 14:01:35] Decode batch. #running-req: 1, #token: 884, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:01:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:35] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:35] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.21, #queue-req: 0, 
[2025-09-30 14:01:35] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:01:36] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:01:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:36] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:36] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.63, #queue-req: 0, 
[2025-09-30 14:01:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:37] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 128.58, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:01:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:38] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:38] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:38] Decode batch. #running-req: 1, #token: 582, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.64, #queue-req: 0, 
[2025-09-30 14:01:38] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.62, #queue-req: 0, 
[2025-09-30 14:01:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:38] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:38] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.39, #queue-req: 0, 
[2025-09-30 14:01:39] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 14:01:39] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:39] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:39] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.42, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 464, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 972, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] Decode batch. #running-req: 1, #token: 752, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.54, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 792, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.78, #queue-req: 0, 
[2025-09-30 14:01:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:41] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.71, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:01:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:42] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:42] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.25, #queue-req: 0, 
[2025-09-30 14:01:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:42] Prefill batch. #new-seq: 1, #new-token: 1141, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:42] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 763, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.95, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 803, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.63, #queue-req: 0, 
[2025-09-30 14:01:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:43] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.89, #queue-req: 0, 
[2025-09-30 14:01:44] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] Decode batch. #running-req: 1, #token: 656, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.90, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 1181, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:45] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.72, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 14:01:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:45] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 1352, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] Decode batch. #running-req: 1, #token: 919, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.92, #queue-req: 0, 
[2025-09-30 14:01:47] Decode batch. #running-req: 1, #token: 959, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 14:01:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:47] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:47] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.44, #queue-req: 0, 
[2025-09-30 14:01:47] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 14:01:48] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 1418, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.47, #queue-req: 0, 
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 681, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:49] Decode batch. #running-req: 1, #token: 884, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.10, #queue-req: 0, 
[2025-09-30 14:01:49] Decode batch. #running-req: 1, #token: 924, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:01:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:49] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:49] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.71, #queue-req: 0, 
[2025-09-30 14:01:50] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 14:01:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:50] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:50] Prefill batch. #new-seq: 1, #new-token: 677, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:50] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.04, #queue-req: 0, 
[2025-09-30 14:01:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 748, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] Decode batch. #running-req: 1, #token: 751, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.58, #queue-req: 0, 
[2025-09-30 14:01:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 1310, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 629, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] Decode batch. #running-req: 1, #token: 814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.64, #queue-req: 0, 
[2025-09-30 14:01:52] Decode batch. #running-req: 1, #token: 854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:01:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:52] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:52] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.74, #queue-req: 0, 
[2025-09-30 14:01:52] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.96, #queue-req: 0, 
[2025-09-30 14:01:53] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:01:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:53] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:53] Decode batch. #running-req: 1, #token: 115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.97, #queue-req: 0, 
[2025-09-30 14:01:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:53] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:54] Prefill batch. #new-seq: 1, #new-token: 1217, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:54] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:54] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.83, #queue-req: 0, 
[2025-09-30 14:01:54] Decode batch. #running-req: 1, #token: 799, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.59, #queue-req: 0, 
[2025-09-30 14:01:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:55] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.15, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 586, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.41, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 626, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.22, #queue-req: 0, 
[2025-09-30 14:01:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:55] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:56] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.07, #queue-req: 0, 
[2025-09-30 14:01:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:56] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:56] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:56] Decode batch. #running-req: 1, #token: 111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.53, #queue-req: 0, 
[2025-09-30 14:01:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 660, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:57] Decode batch. #running-req: 1, #token: 696, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.58, #queue-req: 0, 
[2025-09-30 14:01:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:57] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:57] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:57] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.17, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.03, #queue-req: 0, 
[2025-09-30 14:01:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:58] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.70, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.11, #queue-req: 0, 
[2025-09-30 14:01:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:58] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:58] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.51, #queue-req: 0, 
[2025-09-30 14:01:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:59] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:59] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:59] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.79, #queue-req: 0, 
[2025-09-30 14:01:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:59] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:00] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 128.12, #queue-req: 0, 
[2025-09-30 14:02:00] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 14:02:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:00] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:00] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.31, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.21, #queue-req: 0, 
[2025-09-30 14:02:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.10, #queue-req: 0, 
[2025-09-30 14:02:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:02] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.60, #queue-req: 0, 
[2025-09-30 14:02:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:02] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:02] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:02] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 553, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 565, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.98, #queue-req: 0, 
[2025-09-30 14:02:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:03] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:03] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:03] Decode batch. #running-req: 1, #token: 856, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.43, #queue-req: 0, 
[2025-09-30 14:02:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:03] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:03] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:02:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:04] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:04] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.40, #queue-req: 0, 
[2025-09-30 14:02:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:04] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:04] Prefill batch. #new-seq: 1, #new-token: 1114, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:05] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:05] Decode batch. #running-req: 1, #token: 623, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.52, #queue-req: 0, 
[2025-09-30 14:02:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:05] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:05] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.56, #queue-req: 0, 
[2025-09-30 14:02:05] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:02:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:05] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.10, #queue-req: 0, 
[2025-09-30 14:02:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] Decode batch. #running-req: 1, #token: 642, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.24, #queue-req: 0, 
[2025-09-30 14:02:07] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0, 
[2025-09-30 14:02:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:07] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:07] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.43, #queue-req: 0, 
[2025-09-30 14:02:07] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] Decode batch. #running-req: 1, #token: 543, token usage: 0.01, cuda graph: True, gen throughput (token/s): 108.32, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 787, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.30, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 827, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:02:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:09] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:10] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.80, #queue-req: 0, 
[2025-09-30 14:02:10] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:10] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:10] Prefill batch. #new-seq: 1, #new-token: 532, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:10] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.28, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 1082, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:11] Decode batch. #running-req: 1, #token: 744, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.83, #queue-req: 0, 
[2025-09-30 14:02:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:12] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.91, #queue-req: 0, 
[2025-09-30 14:02:12] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:02:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:12] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:12] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.82, #queue-req: 0, 
[2025-09-30 14:02:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:12] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:13] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:13] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:13] Decode batch. #running-req: 1, #token: 607, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.95, #queue-req: 0, 
[2025-09-30 14:02:13] Decode batch. #running-req: 1, #token: 647, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:02:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:14] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:14] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.31, #queue-req: 0, 
[2025-09-30 14:02:14] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.98, #queue-req: 0, 
[2025-09-30 14:02:14] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:02:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.44, #queue-req: 0, 
[2025-09-30 14:02:15] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.88, #queue-req: 0, 
[2025-09-30 14:02:16] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:02:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:16] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:16] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:16] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.09, #queue-req: 0, 
[2025-09-30 14:02:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 938, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] Decode batch. #running-req: 1, #token: 640, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.62, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.59, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:18] Prefill batch. #new-seq: 1, #new-token: 888, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:18] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:18] Decode batch. #running-req: 1, #token: 655, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.92, #queue-req: 0, 
[2025-09-30 14:02:18] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:02:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:18] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.96, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:19] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] Decode batch. #running-req: 1, #token: 534, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.00, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:19] Prefill batch. #new-seq: 1, #new-token: 889, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] Decode batch. #running-req: 1, #token: 648, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.57, #queue-req: 0, 
[2025-09-30 14:02:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:02:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] Decode batch. #running-req: 1, #token: 527, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.46, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] Decode batch. #running-req: 1, #token: 444, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.81, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:22] Decode batch. #running-req: 1, #token: 220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:02:22] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.18, #queue-req: 0, 
[2025-09-30 14:02:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:22] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:22] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.85, #queue-req: 0, 
[2025-09-30 14:02:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:22] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:23] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:23] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:23] Decode batch. #running-req: 1, #token: 404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.41, #queue-req: 0, 
[2025-09-30 14:02:24] Decode batch. #running-req: 1, #token: 444, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.76, #queue-req: 0, 
[2025-09-30 14:02:24] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.46, #queue-req: 0, 
[2025-09-30 14:02:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:24] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:24] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.05, #queue-req: 0, 
[2025-09-30 14:02:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:25] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:25] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:25] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.59, #queue-req: 0, 
[2025-09-30 14:02:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:25] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:25] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 14:02:25] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:02:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:26] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:26] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:26] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.70, #queue-req: 0, 
[2025-09-30 14:02:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:26] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:27] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.09, #queue-req: 0, 
[2025-09-30 14:02:27] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 14:02:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:28] Prefill batch. #new-seq: 1, #new-token: 1665, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:28] Decode batch. #running-req: 1, #token: 1719, token usage: 0.03, cuda graph: True, gen throughput (token/s): 43.24, #queue-req: 0, 
[2025-09-30 14:02:28] Decode batch. #running-req: 1, #token: 1759, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 1799, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.91, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 1839, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 1879, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 1919, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:02:30] Decode batch. #running-req: 1, #token: 1959, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:02:30] Decode batch. #running-req: 1, #token: 1999, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:02:30] Decode batch. #running-req: 1, #token: 2039, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.37, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 2079, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.05, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 2119, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 2159, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:02:32] Decode batch. #running-req: 1, #token: 2199, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:02:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:32] Prefill batch. #new-seq: 1, #new-token: 1645, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:32] Decode batch. #running-req: 1, #token: 1686, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.85, #queue-req: 0, 
[2025-09-30 14:02:32] Decode batch. #running-req: 1, #token: 1726, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 1766, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.00, #queue-req: 0, 
[2025-09-30 14:02:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:33] Prefill batch. #new-seq: 1, #new-token: 970, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 1014, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.39, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 1054, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:02:34] Decode batch. #running-req: 1, #token: 1094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:02:34] Decode batch. #running-req: 1, #token: 1134, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:02:34] Decode batch. #running-req: 1, #token: 1174, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.42, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 1214, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.34, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 1254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.23, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 1294, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.14, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 1334, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:02:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:36] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:36] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:36] Decode batch. #running-req: 1, #token: 553, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.18, #queue-req: 0, 
[2025-09-30 14:02:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:37] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.93, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 14:02:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:37] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:38] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:38] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:38] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.84, #queue-req: 0, 
[2025-09-30 14:02:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:39] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:39] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:02:39] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:02:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:39] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:39] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:40] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:40] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.26, #queue-req: 0, 
[2025-09-30 14:02:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 328, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:41] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:41] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 465, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.67, #queue-req: 0, 
[2025-09-30 14:02:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:41] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.70, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:02:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:42] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:42] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:42] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.72, #queue-req: 0, 
[2025-09-30 14:02:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] Decode batch. #running-req: 1, #token: 456, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.47, #queue-req: 0, 
[2025-09-30 14:02:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:02:44] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:02:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:44] Prefill batch. #new-seq: 1, #new-token: 679, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:44] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:45] Decode batch. #running-req: 1, #token: 617, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.75, #queue-req: 0, 
[2025-09-30 14:02:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:45] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:45] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.27, #queue-req: 0, 
[2025-09-30 14:02:45] Decode batch. #running-req: 1, #token: 373, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:02:46] Decode batch. #running-req: 1, #token: 413, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:46] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:46] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:46] Decode batch. #running-req: 1, #token: 503, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.54, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:47] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:47] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:47] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.86, #queue-req: 0, 
[2025-09-30 14:02:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:47] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:47] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:48] Decode batch. #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.58, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:49] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:49] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.83, #queue-req: 0, 
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.67, #queue-req: 0, 
[2025-09-30 14:02:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:49] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:50] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.22, #queue-req: 0, 
[2025-09-30 14:02:50] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:50] Prefill batch. #new-seq: 1, #new-token: 584, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:50] Decode batch. #running-req: 1, #token: 660, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.56, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:51] Prefill batch. #new-seq: 1, #new-token: 1198, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:51] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:52] Decode batch. #running-req: 1, #token: 796, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.01, #queue-req: 0, 
[2025-09-30 14:02:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:52] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:52] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 14:02:52] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 14:02:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:53] Prefill batch. #new-seq: 1, #new-token: 1069, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:53] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 637, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.52, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.32, #queue-req: 0, 
[2025-09-30 14:02:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:54] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:54] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.66, #queue-req: 0, 
[2025-09-30 14:02:54] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:02:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:55] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:55] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.42, #queue-req: 0, 
[2025-09-30 14:02:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:55] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:55] Prefill batch. #new-seq: 1, #new-token: 1090, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:56] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 881, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.61, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 921, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 14:02:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:56] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:02:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:57] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.13, #queue-req: 0, 
[2025-09-30 14:02:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:57] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.26, #queue-req: 0, 
[2025-09-30 14:02:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:58] Prefill batch. #new-seq: 1, #new-token: 3570, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 3939, token usage: 0.06, cuda graph: True, gen throughput (token/s): 30.53, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 3979, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 4019, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.62, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 4059, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.58, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 4099, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.58, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 4139, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.09, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 4179, token usage: 0.07, cuda graph: True, gen throughput (token/s): 123.04, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 4219, token usage: 0.07, cuda graph: True, gen throughput (token/s): 123.06, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 4259, token usage: 0.07, cuda graph: True, gen throughput (token/s): 123.02, #queue-req: 0, 
[2025-09-30 14:03:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:01] Prefill batch. #new-seq: 1, #new-token: 3570, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 3914, token usage: 0.06, cuda graph: True, gen throughput (token/s): 79.07, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 3954, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 14:03:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:02] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 148, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 836, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.31, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 876, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 916, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.08, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 956, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1036, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.85, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1076, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:03:05] Decode batch. #running-req: 1, #token: 1116, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:03:05] Decode batch. #running-req: 1, #token: 1156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:03:05] Decode batch. #running-req: 1, #token: 1196, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 14:03:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:05] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.20, #queue-req: 0, 
[2025-09-30 14:03:06] Prefill batch. #new-seq: 1, #new-token: 963, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:06] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:06] Decode batch. #running-req: 1, #token: 540, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-09-30 14:03:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:06] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:07] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.54, #queue-req: 0, 
[2025-09-30 14:03:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:07] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:07] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.31, #queue-req: 0, 
[2025-09-30 14:03:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:07] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:08] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:08] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:08] Decode batch. #running-req: 1, #token: 433, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.76, #queue-req: 0, 
[2025-09-30 14:03:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:08] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:09] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:03:09] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:09] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:09] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:09] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 102.31, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:10] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 270, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:10] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.69, #queue-req: 0, 
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.73, #queue-req: 0, 
[2025-09-30 14:03:11] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.12, #queue-req: 0, 
[2025-09-30 14:03:12] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:03:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:12] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:12] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:13] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:13] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:13] Decode batch. #running-req: 1, #token: 458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.34, #queue-req: 0, 
[2025-09-30 14:03:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:13] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:13] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:03:14] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.16, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:14] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:14] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.81, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:14] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 560, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:15] Decode batch. #running-req: 1, #token: 452, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.24, #queue-req: 0, 
[2025-09-30 14:03:15] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.57, #queue-req: 0, 
[2025-09-30 14:03:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:16] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.97, #queue-req: 0, 
[2025-09-30 14:03:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:16] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:16] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.07, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:17] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.50, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:18] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 14:03:18] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:03:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:18] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:19] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:19] Decode batch. #running-req: 1, #token: 154, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.32, #queue-req: 0, 
[2025-09-30 14:03:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:19] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:19] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:20] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.97, #queue-req: 0, 
[2025-09-30 14:03:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:20] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:20] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.66, #queue-req: 0, 
[2025-09-30 14:03:20] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:03:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:21] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:21] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:21] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.74, #queue-req: 0, 
[2025-09-30 14:03:21] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.94, #queue-req: 0, 
[2025-09-30 14:03:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:22] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:22] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.52, #queue-req: 0, 
[2025-09-30 14:03:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:23] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:23] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.75, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.00, #queue-req: 0, 
[2025-09-30 14:03:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:23] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:03:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:24] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:24] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.61, #queue-req: 0, 
[2025-09-30 14:03:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 26.32, #queue-req: 0, 
[2025-09-30 14:03:26] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:26] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.27, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.01, #queue-req: 0, 
[2025-09-30 14:03:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:27] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.12, #queue-req: 0, 
[2025-09-30 14:03:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:27] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:27] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.08, #queue-req: 0, 
[2025-09-30 14:03:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:28] Prefill batch. #new-seq: 1, #new-token: 1271, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:28] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:28] Decode batch. #running-req: 1, #token: 971, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.56, #queue-req: 0, 
[2025-09-30 14:03:28] Decode batch. #running-req: 1, #token: 1011, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.17, #queue-req: 0, 
[2025-09-30 14:03:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:29] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:03:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:29] Prefill batch. #new-seq: 1, #new-token: 1321, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 108.40, #queue-req: 0, 
[2025-09-30 14:03:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:29] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 857, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.54, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 897, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 14:03:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:30] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.74, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 14:03:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:31] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.39, #queue-req: 0, 
[2025-09-30 14:03:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:31] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:32] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.66, #queue-req: 0, 
[2025-09-30 14:03:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:32] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 627, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:33] Prefill batch. #new-seq: 1, #new-token: 1157, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:33] Prefill batch. #new-seq: 1, #new-token: 611, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:33] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.68, #queue-req: 0, 
[2025-09-30 14:03:33] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:03:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:33] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:34] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.83, #queue-req: 0, 
[2025-09-30 14:03:34] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:34] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:34] Prefill batch. #new-seq: 1, #new-token: 607, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:35] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 677, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:35] Decode batch. #running-req: 1, #token: 681, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.27, #queue-req: 0, 
[2025-09-30 14:03:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 521, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] Decode batch. #running-req: 1, #token: 704, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.33, #queue-req: 0, 
[2025-09-30 14:03:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:03:37] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 14:03:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:37] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:03:37] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:37] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:37] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.48, #queue-req: 0, 
[2025-09-30 14:03:38] Prefill batch. #new-seq: 1, #new-token: 981, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:38] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:39] Decode batch. #running-req: 1, #token: 702, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.94, #queue-req: 0, 
[2025-09-30 14:03:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:39] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:39] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.96, #queue-req: 0, 
[2025-09-30 14:03:39] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 14:03:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:39] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:39] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 503, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.59, #queue-req: 0, 
[2025-09-30 14:03:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:40] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 14:03:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:40] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:41] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.99, #queue-req: 0, 
[2025-09-30 14:03:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:41] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:41] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 381, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:42] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.19, #queue-req: 0, 
[2025-09-30 14:03:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:42] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:42] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:42] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.99, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:43] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:43] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:03:43] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:43] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:43] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.79, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:43] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.52, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.73, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.90, #queue-req: 0, 
[2025-09-30 14:03:46] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:03:46] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 14:03:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:46] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:46] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:47] Prefill batch. #new-seq: 1, #new-token: 685, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:47] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 30.50, #queue-req: 0, 
[2025-09-30 14:03:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:47] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.24, #queue-req: 0, 
[2025-09-30 14:03:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:48] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.45, #queue-req: 0, 
[2025-09-30 14:03:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:48] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.58, #queue-req: 0, 
[2025-09-30 14:03:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:48] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:49] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:49] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:49] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.75, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 535, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.00, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 575, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.62, #queue-req: 0, 
[2025-09-30 14:03:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:50] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 14:03:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:51] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:51] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.31, #queue-req: 0, 
[2025-09-30 14:03:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:51] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:52] Prefill batch. #new-seq: 1, #new-token: 712, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:52] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 569, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.27, #queue-req: 0, 
[2025-09-30 14:03:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:52] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.52, #queue-req: 0, 
[2025-09-30 14:03:53] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.11, #queue-req: 0, 
[2025-09-30 14:03:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:53] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:53] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.98, #queue-req: 0, 
[2025-09-30 14:03:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:53] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:54] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:54] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.13, #queue-req: 0, 
[2025-09-30 14:03:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:54] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 461, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:55] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:55] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:55] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.40, #queue-req: 0, 
[2025-09-30 14:03:55] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.93, #queue-req: 0, 
[2025-09-30 14:03:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:55] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:56] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.28, #queue-req: 0, 
[2025-09-30 14:03:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:56] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:56] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.75, #queue-req: 0, 
[2025-09-30 14:03:56] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:57] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:57] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 206, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:57] Decode batch. #running-req: 1, #token: 213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.03, #queue-req: 0, 
[2025-09-30 14:03:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:58] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:58] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:58] Decode batch. #running-req: 1, #token: 488, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.23, #queue-req: 0, 
[2025-09-30 14:03:58] Decode batch. #running-req: 1, #token: 528, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.17, #queue-req: 0, 
[2025-09-30 14:03:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:58] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:59] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:03:59] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.91, #queue-req: 0, 
[2025-09-30 14:03:59] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:03:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:59] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:59] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:00] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.51, #queue-req: 0, 
[2025-09-30 14:04:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:00] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:01] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:01] Decode batch. #running-req: 1, #token: 573, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.31, #queue-req: 0, 
[2025-09-30 14:04:01] Decode batch. #running-req: 1, #token: 613, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.45, #queue-req: 0, 
[2025-09-30 14:04:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:01] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:01] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.54, #queue-req: 0, 
[2025-09-30 14:04:02] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.01, #queue-req: 0, 
[2025-09-30 14:04:02] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:04:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:03] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:03] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 230, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:03] Decode batch. #running-req: 1, #token: 619, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.92, #queue-req: 0, 
[2025-09-30 14:04:03] Decode batch. #running-req: 1, #token: 659, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.41, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:04] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:04] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 14:04:04] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.96, #queue-req: 0, 
[2025-09-30 14:04:04] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.72, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:05] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:05] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:05] Decode batch. #running-req: 1, #token: 520, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.29, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 560, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.76, #queue-req: 0, 
[2025-09-30 14:04:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:06] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:04:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:07] Prefill batch. #new-seq: 1, #new-token: 1798, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:07] Decode batch. #running-req: 1, #token: 2145, token usage: 0.03, cuda graph: True, gen throughput (token/s): 37.88, #queue-req: 0, 
[2025-09-30 14:04:08] Decode batch. #running-req: 1, #token: 2185, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:04:08] Decode batch. #running-req: 1, #token: 2225, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.75, #queue-req: 0, 
[2025-09-30 14:04:08] Decode batch. #running-req: 1, #token: 2265, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.72, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 2305, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 2345, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.32, #queue-req: 0, 
[2025-09-30 14:04:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:09] Prefill batch. #new-seq: 1, #new-token: 1798, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 2139, token usage: 0.03, cuda graph: True, gen throughput (token/s): 97.54, #queue-req: 0, 
[2025-09-30 14:04:10] Decode batch. #running-req: 1, #token: 2179, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.76, #queue-req: 0, 
[2025-09-30 14:04:10] Decode batch. #running-req: 1, #token: 2219, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.71, #queue-req: 0, 
[2025-09-30 14:04:10] Decode batch. #running-req: 1, #token: 2259, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.71, #queue-req: 0, 
[2025-09-30 14:04:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:10] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 742, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.22, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.56, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.26, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 862, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.18, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 902, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 942, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.09, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 982, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.98, #queue-req: 0, 
[2025-09-30 14:04:13] Decode batch. #running-req: 1, #token: 1022, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 14:04:13] Decode batch. #running-req: 1, #token: 1062, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:04:13] Decode batch. #running-req: 1, #token: 1102, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:04:14] Decode batch. #running-req: 1, #token: 1142, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:04:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:14] Prefill batch. #new-seq: 1, #new-token: 789, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:14] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:14] Decode batch. #running-req: 1, #token: 638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.56, #queue-req: 0, 
[2025-09-30 14:04:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:15] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:15] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.48, #queue-req: 0, 
[2025-09-30 14:04:15] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 14:04:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:16] Prefill batch. #new-seq: 1, #new-token: 1122, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:16] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:16] Decode batch. #running-req: 1, #token: 891, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.07, #queue-req: 0, 
[2025-09-30 14:04:16] Decode batch. #running-req: 1, #token: 931, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:17] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:17] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.18, #queue-req: 0, 
[2025-09-30 14:04:17] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:17] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:17] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.47, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:17] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:18] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:18] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.19, #queue-req: 0, 
[2025-09-30 14:04:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 742, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:19] Prefill batch. #new-seq: 1, #new-token: 1157, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:19] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:19] Decode batch. #running-req: 1, #token: 658, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.49, #queue-req: 0, 
[2025-09-30 14:04:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:20] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:20] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:04:20] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:04:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:21] Prefill batch. #new-seq: 1, #new-token: 874, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:21] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.61, #queue-req: 0, 
[2025-09-30 14:04:21] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:21] Decode batch. #running-req: 1, #token: 596, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.36, #queue-req: 0, 
[2025-09-30 14:04:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:22] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:22] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 14:04:22] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 14:04:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 738, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:23] Decode batch. #running-req: 1, #token: 538, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.44, #queue-req: 0, 
[2025-09-30 14:04:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:23] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.24, #queue-req: 0, 
[2025-09-30 14:04:24] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.85, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:24] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:24] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:24] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.28, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 966, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 29.53, #queue-req: 0, 
[2025-09-30 14:04:26] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 14:04:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:26] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:04:26] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:26] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:27] Prefill batch. #new-seq: 1, #new-token: 1187, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:27] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 745, token usage: 0.01, cuda graph: True, gen throughput (token/s): 27.50, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 785, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.82, #queue-req: 0, 
[2025-09-30 14:04:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:28] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.29, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] Decode batch. #running-req: 1, #token: 404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 108.22, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.21, #queue-req: 0, 
[2025-09-30 14:04:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:30] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:30] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.56, #queue-req: 0, 
[2025-09-30 14:04:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:30] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:31] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 175, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.98, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:31] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:31] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.48, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:32] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:33] Prefill batch. #new-seq: 1, #new-token: 508, #cached-token: 90, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:33] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 175, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:33] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 29.86, #queue-req: 0, 
[2025-09-30 14:04:33] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.56, #queue-req: 0, 
[2025-09-30 14:04:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:33] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:33] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:04:34] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:04:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:35] Prefill batch. #new-seq: 1, #new-token: 1155, #cached-token: 90, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:35] Prefill batch. #new-seq: 1, #new-token: 972, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:35] Decode batch. #running-req: 1, #token: 1140, token usage: 0.02, cuda graph: True, gen throughput (token/s): 36.75, #queue-req: 0, 
[2025-09-30 14:04:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:35] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:35] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.12, #queue-req: 0, 
[2025-09-30 14:04:35] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.06, #queue-req: 0, 
[2025-09-30 14:04:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:36] Prefill batch. #new-seq: 1, #new-token: 1423, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:36] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] Decode batch. #running-req: 1, #token: 700, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.53, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 14:04:37] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.99, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:38] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:38] Decode batch. #running-req: 1, #token: 594, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.39, #queue-req: 0, 
[2025-09-30 14:04:38] Decode batch. #running-req: 1, #token: 634, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.08, #queue-req: 0, 
[2025-09-30 14:04:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:39] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:39] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 590, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 1169, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 818, token usage: 0.01, cuda graph: True, gen throughput (token/s): 22.71, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 858, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:04:41] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.93, #queue-req: 0, 
[2025-09-30 14:04:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:41] Prefill batch. #new-seq: 1, #new-token: 1383, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:42] Prefill batch. #new-seq: 1, #new-token: 743, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] Decode batch. #running-req: 1, #token: 915, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.25, #queue-req: 0, 
[2025-09-30 14:04:42] Decode batch. #running-req: 1, #token: 955, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.27, #queue-req: 0, 
[2025-09-30 14:04:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:42] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.08, #queue-req: 0, 
[2025-09-30 14:04:43] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.00, #queue-req: 0, 
[2025-09-30 14:04:43] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:04:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:43] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:43] Prefill batch. #new-seq: 1, #new-token: 739, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:43] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.39, #queue-req: 0, 
[2025-09-30 14:04:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 1297, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 560, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] Decode batch. #running-req: 1, #token: 733, token usage: 0.01, cuda graph: True, gen throughput (token/s): 28.73, #queue-req: 0, 
[2025-09-30 14:04:45] Decode batch. #running-req: 1, #token: 773, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:04:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:04:46] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 14:04:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:46] Prefill batch. #new-seq: 1, #new-token: 1068, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] Decode batch. #running-req: 1, #token: 703, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.65, #queue-req: 0, 
[2025-09-30 14:04:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:04:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 508, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] Decode batch. #running-req: 1, #token: 594, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.92, #queue-req: 0, 
[2025-09-30 14:04:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:49] Prefill batch. #new-seq: 1, #new-token: 3000, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:49] Decode batch. #running-req: 1, #token: 3362, token usage: 0.05, cuda graph: True, gen throughput (token/s): 27.70, #queue-req: 0, 
[2025-09-30 14:04:49] Decode batch. #running-req: 1, #token: 3402, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 3442, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.80, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 3482, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 3522, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 3562, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:04:51] Decode batch. #running-req: 1, #token: 3602, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:04:51] Decode batch. #running-req: 1, #token: 3642, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.34, #queue-req: 0, 
[2025-09-30 14:04:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:51] Prefill batch. #new-seq: 1, #new-token: 3000, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:52] Decode batch. #running-req: 1, #token: 3328, token usage: 0.05, cuda graph: True, gen throughput (token/s): 83.49, #queue-req: 0, 
[2025-09-30 14:04:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:52] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:52] Decode batch. #running-req: 1, #token: 927, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.03, #queue-req: 0, 
[2025-09-30 14:04:52] Decode batch. #running-req: 1, #token: 967, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:04:53] Decode batch. #running-req: 1, #token: 1007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 14:04:53] Decode batch. #running-req: 1, #token: 1047, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:04:53] Decode batch. #running-req: 1, #token: 1087, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.47, #queue-req: 0, 
[2025-09-30 14:04:53] Decode batch. #running-req: 1, #token: 1127, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 1167, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.35, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 1207, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 1247, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.24, #queue-req: 0, 
[2025-09-30 14:04:55] Decode batch. #running-req: 1, #token: 1287, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.17, #queue-req: 0, 
[2025-09-30 14:04:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:55] Prefill batch. #new-seq: 1, #new-token: 1178, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:55] Prefill batch. #new-seq: 1, #new-token: 717, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 884, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.18, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 924, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 964, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.29, #queue-req: 0, 
[2025-09-30 14:04:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:56] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 209, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:57] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.85, #queue-req: 0, 
[2025-09-30 14:04:57] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:04:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:57] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:57] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:58] Decode batch. #running-req: 1, #token: 756, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.51, #queue-req: 0, 
[2025-09-30 14:04:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:58] Prefill batch. #new-seq: 1, #new-token: 1049, #cached-token: 91, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:58] Prefill batch. #new-seq: 1, #new-token: 396, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:58] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.06, #queue-req: 0, 
[2025-09-30 14:04:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:58] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.98, #queue-req: 0, 
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.78, #queue-req: 0, 
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 14:04:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:59] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:00] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:00] Decode batch. #running-req: 1, #token: 472, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.55, #queue-req: 0, 
[2025-09-30 14:05:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:01] Prefill batch. #new-seq: 1, #new-token: 846, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:01] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:01] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.99, #queue-req: 0, 
[2025-09-30 14:05:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:01] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:01] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.92, #queue-req: 0, 
[2025-09-30 14:05:01] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.05, #queue-req: 0, 
[2025-09-30 14:05:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:02] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:05:02] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:02] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:03] Prefill batch. #new-seq: 1, #new-token: 2176, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:03] Decode batch. #running-req: 1, #token: 2524, token usage: 0.04, cuda graph: True, gen throughput (token/s): 33.70, #queue-req: 0, 
[2025-09-30 14:05:03] Decode batch. #running-req: 1, #token: 2564, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.09, #queue-req: 0, 
[2025-09-30 14:05:03] Decode batch. #running-req: 1, #token: 2604, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:05:04] Decode batch. #running-req: 1, #token: 2644, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:04] Decode batch. #running-req: 1, #token: 2684, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:04] Decode batch. #running-req: 1, #token: 2724, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:05:05] Decode batch. #running-req: 1, #token: 2764, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:05] Prefill batch. #new-seq: 1, #new-token: 2176, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:05] Decode batch. #running-req: 1, #token: 2526, token usage: 0.04, cuda graph: True, gen throughput (token/s): 93.72, #queue-req: 0, 
[2025-09-30 14:05:05] Decode batch. #running-req: 1, #token: 2566, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.11, #queue-req: 0, 
[2025-09-30 14:05:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:06] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 277, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 767, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.03, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 807, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.21, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 847, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.20, #queue-req: 0, 
[2025-09-30 14:05:07] Decode batch. #running-req: 1, #token: 887, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:05:07] Decode batch. #running-req: 1, #token: 927, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.01, #queue-req: 0, 
[2025-09-30 14:05:07] Decode batch. #running-req: 1, #token: 967, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.03, #queue-req: 0, 
[2025-09-30 14:05:08] Decode batch. #running-req: 1, #token: 1007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.89, #queue-req: 0, 
[2025-09-30 14:05:08] Decode batch. #running-req: 1, #token: 1047, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:05:08] Decode batch. #running-req: 1, #token: 1087, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:05:09] Decode batch. #running-req: 1, #token: 1127, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.41, #queue-req: 0, 
[2025-09-30 14:05:09] Decode batch. #running-req: 1, #token: 1167, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:05:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:10] Prefill batch. #new-seq: 1, #new-token: 1113, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:10] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] Decode batch. #running-req: 1, #token: 882, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.09, #queue-req: 0, 
[2025-09-30 14:05:10] Decode batch. #running-req: 1, #token: 922, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.33, #queue-req: 0, 
[2025-09-30 14:05:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:10] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:05:11] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.93, #queue-req: 0, 
[2025-09-30 14:05:11] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:05:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:11] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:11] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:11] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.90, #queue-req: 0, 
[2025-09-30 14:05:12] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 731, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:12] Decode batch. #running-req: 1, #token: 755, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.28, #queue-req: 0, 
[2025-09-30 14:05:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:13] Prefill batch. #new-seq: 1, #new-token: 963, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:13] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 160, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:13] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.27, #queue-req: 0, 
[2025-09-30 14:05:13] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.42, #queue-req: 0, 
[2025-09-30 14:05:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:14] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 14:05:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:14] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.05, #queue-req: 0, 
[2025-09-30 14:05:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:15] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:15] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.15, #queue-req: 0, 
[2025-09-30 14:05:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.08, #queue-req: 0, 
[2025-09-30 14:05:16] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.97, #queue-req: 0, 
[2025-09-30 14:05:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:17] Decode batch. #running-req: 1, #token: 405, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.07, #queue-req: 0, 
[2025-09-30 14:05:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:18] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 29.11, #queue-req: 0, 
[2025-09-30 14:05:18] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.98, #queue-req: 0, 
[2025-09-30 14:05:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 203, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:19] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:19] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 196, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.24, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:20] Prefill batch. #new-seq: 1, #new-token: 395, #cached-token: 85, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:20] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:20] Decode batch. #running-req: 1, #token: 465, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.13, #queue-req: 0, 
[2025-09-30 14:05:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:21] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.32, #queue-req: 0, 
[2025-09-30 14:05:21] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:21] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.27, #queue-req: 0, 
[2025-09-30 14:05:21] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 14:05:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:22] Prefill batch. #new-seq: 1, #new-token: 443, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:22] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:22] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.32, #queue-req: 0, 
[2025-09-30 14:05:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:23] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.64, #queue-req: 0, 
[2025-09-30 14:05:23] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.87, #queue-req: 0, 
[2025-09-30 14:05:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:23] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.98, #queue-req: 0, 
[2025-09-30 14:05:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:24] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:24] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.37, #queue-req: 0, 
[2025-09-30 14:05:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 231, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:25] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:25] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.93, #queue-req: 0, 
[2025-09-30 14:05:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:26] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:26] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.09, #queue-req: 0, 
[2025-09-30 14:05:26] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.91, #queue-req: 0, 
[2025-09-30 14:05:26] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:05:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:27] Prefill batch. #new-seq: 1, #new-token: 412, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:27] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:27] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.75, #queue-req: 0, 
[2025-09-30 14:05:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:28] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.67, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:05:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:28] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:28] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 102.49, #queue-req: 0, 
[2025-09-30 14:05:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:30] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:30] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 418, token usage: 0.01, cuda graph: True, gen throughput (token/s): 28.81, #queue-req: 0, 
[2025-09-30 14:05:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:30] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.19, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:05:31] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:05:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:31] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:31] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:32] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:32] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 36.29, #queue-req: 0, 
[2025-09-30 14:05:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:32] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 304, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:33] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:33] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 436, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.25, #queue-req: 0, 
[2025-09-30 14:05:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:33] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.88, #queue-req: 0, 
[2025-09-30 14:05:34] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:05:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:34] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:34] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:34] Decode batch. #running-req: 1, #token: 346, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.85, #queue-req: 0, 
[2025-09-30 14:05:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:35] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:35] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.22, #queue-req: 0, 
[2025-09-30 14:05:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 323, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:36] Prefill batch. #new-seq: 1, #new-token: 481, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:36] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.13, #queue-req: 0, 
[2025-09-30 14:05:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:36] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:05:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:37] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.70, #queue-req: 0, 
[2025-09-30 14:05:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:37] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:38] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:38] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 860, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.40, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 900, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:05:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:38] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.31, #queue-req: 0, 
[2025-09-30 14:05:39] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 14:05:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:39] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:39] Prefill batch. #new-seq: 1, #new-token: 682, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:39] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.11, #queue-req: 0, 
[2025-09-30 14:05:39] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:40] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 754, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:40] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.08, #queue-req: 0, 
[2025-09-30 14:05:40] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:41] Prefill batch. #new-seq: 1, #new-token: 1258, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:41] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:41] Decode batch. #running-req: 1, #token: 765, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.12, #queue-req: 0, 
[2025-09-30 14:05:41] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:41] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:41] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.80, #queue-req: 0, 
[2025-09-30 14:05:42] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:05:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:42] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:42] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:42] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.04, #queue-req: 0, 
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 1166, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:43] Decode batch. #running-req: 1, #token: 794, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.67, #queue-req: 0, 
[2025-09-30 14:05:43] Decode batch. #running-req: 1, #token: 834, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 14:05:43] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:44] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.25, #queue-req: 0, 
[2025-09-30 14:05:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:44] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:44] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.30, #queue-req: 0, 
[2025-09-30 14:05:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:44] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:44] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:45] Prefill batch. #new-seq: 1, #new-token: 1230, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:45] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:45] Decode batch. #running-req: 1, #token: 833, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.75, #queue-req: 0, 
[2025-09-30 14:05:45] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:45] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:46] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.02, #queue-req: 0, 
[2025-09-30 14:05:46] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:05:46] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:47] Prefill batch. #new-seq: 1, #new-token: 1397, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:47] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 941, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.40, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 981, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.23, #queue-req: 0, 
[2025-09-30 14:05:47] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:47] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.29, #queue-req: 0, 
[2025-09-30 14:05:48] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:05:48] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:05:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:48] Prefill batch. #new-seq: 1, #new-token: 758, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:48] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:48] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 102.57, #queue-req: 0, 
[2025-09-30 14:05:49] Prefill batch. #new-seq: 1, #new-token: 968, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:49] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:49] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.09, #queue-req: 0, 
[2025-09-30 14:05:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:50] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 14:05:50] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:51] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:51] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:51] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.98, #queue-req: 0, 
[2025-09-30 14:05:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:51] Prefill batch. #new-seq: 1, #new-token: 737, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:51] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:51] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 716, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.01, #queue-req: 0, 
[2025-09-30 14:05:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:52] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.00, #queue-req: 0, 
[2025-09-30 14:05:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:52] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.36, #queue-req: 0, 
[2025-09-30 14:05:52] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:52] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:53] Prefill batch. #new-seq: 1, #new-token: 1077, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:53] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:53] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:53] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.60, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 770, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:05:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.58, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 14:05:54] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:54] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:55] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.74, #queue-req: 0, 
[2025-09-30 14:05:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:55] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:55] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:56] Prefill batch. #new-seq: 1, #new-token: 1229, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:56] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.07, #queue-req: 0, 
[2025-09-30 14:05:56] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:56] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.75, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.08, #queue-req: 0, 
[2025-09-30 14:05:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:57] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:57] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.64, #queue-req: 0, 
[2025-09-30 14:05:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:57] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:57] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:58] Prefill batch. #new-seq: 1, #new-token: 1352, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:58] Prefill batch. #new-seq: 1, #new-token: 675, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:58] Decode batch. #running-req: 1, #token: 846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.74, #queue-req: 0, 
[2025-09-30 14:05:58] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.35, #queue-req: 0, 
[2025-09-30 14:05:58] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:58] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.65, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.99, #queue-req: 0, 
[2025-09-30 14:05:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:59] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.27, #queue-req: 0, 
[2025-09-30 14:05:59] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:59] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:00] Prefill batch. #new-seq: 1, #new-token: 1242, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:00] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:00] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:00] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.99, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 787, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:06:01] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:01] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:06:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:02] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:02] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:02] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.17, #queue-req: 0, 
[2025-09-30 14:06:02] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 1087, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.10, #queue-req: 0, 
[2025-09-30 14:06:03] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.38, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:04] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:04] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.08, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:04] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:04] Prefill batch. #new-seq: 1, #new-token: 957, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:05] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.52, #queue-req: 0, 
[2025-09-30 14:06:05] Prefill batch. #new-seq: 1, #new-token: 440, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:05] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:05] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.80, #queue-req: 0, 
[2025-09-30 14:06:05] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:06:05] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:06:05] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:06] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:06] Prefill batch. #new-seq: 1, #new-token: 436, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:06] Decode batch. #running-req: 1, #token: 531, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.73, #queue-req: 0, 
[2025-09-30 14:06:06] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:07] Prefill batch. #new-seq: 1, #new-token: 973, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:07] Prefill batch. #new-seq: 1, #new-token: 539, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:07] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-09-30 14:06:07] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.02, #queue-req: 0, 
[2025-09-30 14:06:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:08] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:08] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.28, #queue-req: 0, 
[2025-09-30 14:06:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:08] Prefill batch. #new-seq: 1, #new-token: 535, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:08] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:09] Prefill batch. #new-seq: 1, #new-token: 1001, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:09] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:09] Decode batch. #running-req: 1, #token: 642, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.22, #queue-req: 0, 
[2025-09-30 14:06:09] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.32, #queue-req: 0, 
[2025-09-30 14:06:09] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:09] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.97, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:06:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:10] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:10] Prefill batch. #new-seq: 1, #new-token: 464, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.82, #queue-req: 0, 
[2025-09-30 14:06:10] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:11] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:11] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:11] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.41, #queue-req: 0, 
[2025-09-30 14:06:11] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:11] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:12] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 14:06:12] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 14:06:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:12] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:12] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:12] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:13] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:13] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:13] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.47, #queue-req: 0, 
[2025-09-30 14:06:13] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:13] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:13] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:06:14] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.09, #queue-req: 0, 
[2025-09-30 14:06:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:14] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:14] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:14] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.98, #queue-req: 0, 
[2025-09-30 14:06:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:15] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:15] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:15] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:15] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.22, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.84, #queue-req: 0, 
[2025-09-30 14:06:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:16] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.87, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.83, #queue-req: 0, 
[2025-09-30 14:06:16] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:17] Prefill batch. #new-seq: 1, #new-token: 927, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:17] Prefill batch. #new-seq: 1, #new-token: 733, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:17] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:17] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:17] Decode batch. #running-req: 1, #token: 888, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.52, #queue-req: 0, 
[2025-09-30 14:06:17] Decode batch. #running-req: 1, #token: 928, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 968, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.91, #queue-req: 0, 
[2025-09-30 14:06:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 14:06:18] Prefill batch. #new-seq: 1, #new-token: 1050, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:18] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:18] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:18] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 98.30, #queue-req: 0, 
[2025-09-30 14:06:19] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.05, #queue-req: 0, 
[2025-09-30 14:06:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:19] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:19] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:19] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.53, #queue-req: 0, 
[2025-09-30 14:06:19] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:20] Prefill batch. #new-seq: 1, #new-token: 1100, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:20] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:20] Decode batch. #running-req: 1, #token: 974, token usage: 0.02, cuda graph: True, gen throughput (token/s): 33.62, #queue-req: 0, 
[2025-09-30 14:06:20] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:20] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.20, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 14:06:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:21] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:06:21] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:21] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:22] Decode batch. #running-req: 1, #token: 874, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.90, #queue-req: 0, 
[2025-09-30 14:06:22] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 1391, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:23] Decode batch. #running-req: 1, #token: 856, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.53, #queue-req: 0, 
[2025-09-30 14:06:23] Decode batch. #running-req: 1, #token: 896, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:06:23] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:24] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:06:24] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 14:06:24] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:25] Prefill batch. #new-seq: 1, #new-token: 1229, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:25] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:25] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.73, #queue-req: 0, 
[2025-09-30 14:06:25] Decode batch. #running-req: 1, #token: 823, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:06:25] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:25] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:25] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 14:06:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:26] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:26] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.20, #queue-req: 0, 
[2025-09-30 14:06:26] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:27] Prefill batch. #new-seq: 1, #new-token: 1417, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:27] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:27] Prefill batch. #new-seq: 1, #new-token: 860, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:27] Decode batch. #running-req: 1, #token: 1046, token usage: 0.02, cuda graph: True, gen throughput (token/s): 33.07, #queue-req: 0, 
[2025-09-30 14:06:28] Decode batch. #running-req: 1, #token: 1086, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:06:28] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:28] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:28] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:06:28] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 14:06:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:29] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 124, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.14, #queue-req: 0, 
[2025-09-30 14:06:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:29] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 903, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.08, #queue-req: 0, 
[2025-09-30 14:06:29] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:30] Prefill batch. #new-seq: 1, #new-token: 1538, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:30] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:30] Prefill batch. #new-seq: 1, #new-token: 736, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 32.77, #queue-req: 0, 
[2025-09-30 14:06:31] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:06:31] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:31] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.84, #queue-req: 0, 
[2025-09-30 14:06:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:32] Prefill batch. #new-seq: 1, #new-token: 732, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:32] Decode batch. #running-req: 1, #token: 844, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.71, #queue-req: 0, 
[2025-09-30 14:06:32] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:33] Prefill batch. #new-seq: 1, #new-token: 1334, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:33] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:33] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:33] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.06, #queue-req: 0, 
[2025-09-30 14:06:33] Decode batch. #running-req: 1, #token: 816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.49, #queue-req: 0, 
[2025-09-30 14:06:34] Decode batch. #running-req: 1, #token: 856, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.49, #queue-req: 0, 
[2025-09-30 14:06:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:34] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:34] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:06:34] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 14:06:34] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:35] Prefill batch. #new-seq: 1, #new-token: 791, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:35] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:35] Decode batch. #running-req: 1, #token: 384, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.29, #queue-req: 0, 
[2025-09-30 14:06:35] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:35] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.60, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 14:06:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:36] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:36] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.67, #queue-req: 0, 
[2025-09-30 14:06:36] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:37] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:37] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:37] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:37] Decode batch. #running-req: 1, #token: 432, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.16, #queue-req: 0, 
[2025-09-30 14:06:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:38] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:38] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.80, #queue-req: 0, 
[2025-09-30 14:06:38] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.03, #queue-req: 0, 
[2025-09-30 14:06:38] INFO:     127.0.0.1:54968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:37] INFO:     127.0.0.1:55128 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 14:31:41] [http_server] Error: Request is disconnected from the client side (type 1). Abort request obj.rid='4185abf8506b4b43a35edf07741e424b'
[2025-09-30 14:32:19] INFO:     127.0.0.1:38698 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 14:42:19] [http_server] Error: Request is disconnected from the client side (type 1). Abort request obj.rid='49dc9b83adbd468b94e9eb867f6b5ece'
[2025-09-30 17:30:35] INFO:     127.0.0.1:33766 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 17:40:35] [http_server] Error: Request is disconnected from the client side (type 1). Abort request obj.rid='54d3b9f857ab49e5b0769d97e68709a6'
