/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:52:54.400768 2766500 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:52:54.400768 2766500 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-30 13:52:54] server_args=ServerArgs(model_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30002, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.98, max_running_requests=50, max_queued_requests=9223372036854775807, max_total_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=862289119, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-customer-labels', tokenizer_metrics_allowed_customer_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, enable_trace=False, oltp_traces_endpoint='localhost:4317', api_key=None, served_model_name='LLAMA', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='triton', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=True, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=True, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_cutedsl_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:52:55] Using default HuggingFace chat template with detected content format: string
/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:53:00.742167 2766767 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:53:00.742167 2766767 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0930 13:53:01.123183 2766768 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:53:01.123183 2766768 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:53:01] Init torch distributed begin.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-09-30 13:53:01] Init torch distributed ends. mem usage=0.00 GB
[2025-09-30 13:53:01] CUDA-fused xIELU not available (No module named 'xielu') â€“ falling back to a Python version.
For CUDA xIELU (experimental), `pip install git+https://github.com/nickjbrowning/XIELU`
[2025-09-30 13:53:01] MOE_RUNNER_BACKEND is not initialized, using triton backend
[2025-09-30 13:53:02] Load weight begin. avail mem=22.65 GB
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.23it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.87it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.73it/s]

[2025-09-30 13:53:03] Load weight end. type=LlamaForCausalLM, dtype=torch.bfloat16, avail mem=16.53 GB, mem usage=6.12 GB.
[2025-09-30 13:53:03] KV Cache is allocated. #tokens: 64000, K size: 3.42 GB, V size: 3.42 GB
[2025-09-30 13:53:03] Memory pool end. avail mem=9.65 GB
[2025-09-30 13:53:03] Capture cuda graph begin. This can take up to several minutes. avail mem=9.62 GB
[2025-09-30 13:53:03] Capture cuda graph bs [1, 2, 4, 8]
  0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=9.62 GB):   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=9.62 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s]Capturing batches (bs=4 avail_mem=9.56 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s]Capturing batches (bs=2 avail_mem=9.56 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s]Capturing batches (bs=1 avail_mem=9.56 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.84it/s]Capturing batches (bs=1 avail_mem=9.56 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.45it/s]Capturing batches (bs=1 avail_mem=9.56 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.07it/s]
[2025-09-30 13:53:04] Capture cuda graph end. Time elapsed: 0.99 s. mem usage=0.07 GB. avail mem=9.55 GB.
[2025-09-30 13:53:04] max_total_num_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, max_running_requests=50, context_len=131072, available_gpu_mem=9.55 GB
[2025-09-30 13:53:05] INFO:     Started server process [2766500]
[2025-09-30 13:53:05] INFO:     Waiting for application startup.
[2025-09-30 13:53:05] INFO:     Application startup complete.
[2025-09-30 13:53:05] INFO:     Uvicorn running on http://0.0.0.0:30002 (Press CTRL+C to quit)
[2025-09-30 13:53:06] INFO:     127.0.0.1:60120 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 13:53:06] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:06] INFO:     127.0.0.1:60136 - "POST /generate HTTP/1.1" 200 OK
[2025-09-30 13:53:06] The server is fired up and ready to roll!
[2025-09-30 13:53:16] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:16] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:16] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:16] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3.41, #queue-req: 0, 
[2025-09-30 13:53:16] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.12, #queue-req: 0, 
[2025-09-30 13:53:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:17] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 13:53:17] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:17] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:17] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:17] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:18] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.37, #queue-req: 0, 
[2025-09-30 13:53:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:18] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:18] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 13:53:18] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.89, #queue-req: 0, 
[2025-09-30 13:53:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:18] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:18] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:19] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.17, #queue-req: 0, 
[2025-09-30 13:53:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:19] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:19] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.80, #queue-req: 0, 
[2025-09-30 13:53:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:19] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:19] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.57, #queue-req: 0, 
[2025-09-30 13:53:19] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.88, #queue-req: 0, 
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 138, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:20] Decode batch. #running-req: 1, #token: 217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.27, #queue-req: 0, 
[2025-09-30 13:53:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:21] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.12, #queue-req: 0, 
[2025-09-30 13:53:21] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.80, #queue-req: 0, 
[2025-09-30 13:53:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:21] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:21] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:21] Decode batch. #running-req: 1, #token: 121, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.66, #queue-req: 0, 
[2025-09-30 13:53:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:21] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:21] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:22] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:22] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.29, #queue-req: 0, 
[2025-09-30 13:53:22] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.99, #queue-req: 0, 
[2025-09-30 13:53:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:22] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:22] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:22] Decode batch. #running-req: 1, #token: 120, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.10, #queue-req: 0, 
[2025-09-30 13:53:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:22] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:22] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:23] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.97, #queue-req: 0, 
[2025-09-30 13:53:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:23] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:23] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.69, #queue-req: 0, 
[2025-09-30 13:53:23] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 13:53:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:23] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] Decode batch. #running-req: 1, #token: 151, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.88, #queue-req: 0, 
[2025-09-30 13:53:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 145, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] Decode batch. #running-req: 1, #token: 208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.08, #queue-req: 0, 
[2025-09-30 13:53:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:24] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:24] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.83, #queue-req: 0, 
[2025-09-30 13:53:25] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.92, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] Decode batch. #running-req: 1, #token: 115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.25, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:25] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.15, #queue-req: 0, 
[2025-09-30 13:53:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:25] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:26] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.22, #queue-req: 0, 
[2025-09-30 13:53:26] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 13:53:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:26] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:26] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:26] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:26] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:26] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.67, #queue-req: 0, 
[2025-09-30 13:53:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:27] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:27] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.30, #queue-req: 0, 
[2025-09-30 13:53:27] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:53:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:27] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:27] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:27] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.28, #queue-req: 0, 
[2025-09-30 13:53:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:27] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:28] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:28] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:28] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.39, #queue-req: 0, 
[2025-09-30 13:53:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:28] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:28] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.31, #queue-req: 0, 
[2025-09-30 13:53:28] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:53:29] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 13:53:29] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:29] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:29] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:29] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:29] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.05, #queue-req: 0, 
[2025-09-30 13:53:29] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.81, #queue-req: 0, 
[2025-09-30 13:53:29] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:29] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:30] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.15, #queue-req: 0, 
[2025-09-30 13:53:30] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:53:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:30] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:30] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:30] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:30] Decode batch. #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.44, #queue-req: 0, 
[2025-09-30 13:53:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:30] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 148, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:31] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:31] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:31] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.46, #queue-req: 0, 
[2025-09-30 13:53:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:31] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:31] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.77, #queue-req: 0, 
[2025-09-30 13:53:31] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 13:53:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:31] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:31] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:32] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:32] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] Decode batch. #running-req: 1, #token: 152, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.53, #queue-req: 0, 
[2025-09-30 13:53:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:32] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:32] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.90, #queue-req: 0, 
[2025-09-30 13:53:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:32] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:32] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 13:53:33] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 13:53:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:33] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:33] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:33] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:33] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:33] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.69, #queue-req: 0, 
[2025-09-30 13:53:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:33] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:33] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.94, #queue-req: 0, 
[2025-09-30 13:53:34] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 13:53:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:34] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:34] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:34] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.65, #queue-req: 0, 
[2025-09-30 13:53:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:34] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:34] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 13:53:35] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.84, #queue-req: 0, 
[2025-09-30 13:53:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:35] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:35] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:35] Decode batch. #running-req: 1, #token: 131, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.76, #queue-req: 0, 
[2025-09-30 13:53:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:35] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:36] Decode batch. #running-req: 1, #token: 142, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.19, #queue-req: 0, 
[2025-09-30 13:53:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:36] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:36] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:36] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.51, #queue-req: 0, 
[2025-09-30 13:53:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:36] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:36] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.90, #queue-req: 0, 
[2025-09-30 13:53:36] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] Decode batch. #running-req: 1, #token: 148, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.05, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:37] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:37] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 87.59, #queue-req: 0, 
[2025-09-30 13:53:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:38] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:38] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.34, #queue-req: 0, 
[2025-09-30 13:53:38] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 13:53:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:38] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.64, #queue-req: 0, 
[2025-09-30 13:53:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:38] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:39] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:39] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:39] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.79, #queue-req: 0, 
[2025-09-30 13:53:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:39] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:39] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.50, #queue-req: 0, 
[2025-09-30 13:53:39] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 13:53:40] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 13:53:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:40] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:40] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:40] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:40] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:40] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.66, #queue-req: 0, 
[2025-09-30 13:53:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:40] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:40] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.02, #queue-req: 0, 
[2025-09-30 13:53:41] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 13:53:41] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 13:53:41] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:41] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:41] Decode batch. #running-req: 1, #token: 651, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.88, #queue-req: 0, 
[2025-09-30 13:53:42] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.63, #queue-req: 0, 
[2025-09-30 13:53:42] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.52, #queue-req: 0, 
[2025-09-30 13:53:42] Decode batch. #running-req: 1, #token: 771, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.39, #queue-req: 0, 
[2025-09-30 13:53:43] Decode batch. #running-req: 1, #token: 811, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.08, #queue-req: 0, 
[2025-09-30 13:53:43] Decode batch. #running-req: 1, #token: 851, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.03, #queue-req: 0, 
[2025-09-30 13:53:43] Decode batch. #running-req: 1, #token: 891, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 13:53:43] Decode batch. #running-req: 1, #token: 931, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.84, #queue-req: 0, 
[2025-09-30 13:53:44] Decode batch. #running-req: 1, #token: 971, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.76, #queue-req: 0, 
[2025-09-30 13:53:44] Decode batch. #running-req: 1, #token: 1011, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.78, #queue-req: 0, 
[2025-09-30 13:53:44] Decode batch. #running-req: 1, #token: 1051, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 13:53:45] Decode batch. #running-req: 1, #token: 1091, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 13:53:45] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:45] Prefill batch. #new-seq: 1, #new-token: 573, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:45] Decode batch. #running-req: 1, #token: 609, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.12, #queue-req: 0, 
[2025-09-30 13:53:45] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:45] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:45] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:45] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:45] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.52, #queue-req: 0, 
[2025-09-30 13:53:46] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:46] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:46] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 13:53:46] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:53:46] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:46] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:46] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.41, #queue-req: 0, 
[2025-09-30 13:53:47] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:47] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:47] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:47] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:47] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:47] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:47] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.38, #queue-req: 0, 
[2025-09-30 13:53:47] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.82, #queue-req: 0, 
[2025-09-30 13:53:47] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:47] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:47] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.58, #queue-req: 0, 
[2025-09-30 13:53:48] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 13:53:48] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:48] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:48] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:48] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:48] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.53, #queue-req: 0, 
[2025-09-30 13:53:48] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:48] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:48] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:48] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:49] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.30, #queue-req: 0, 
[2025-09-30 13:53:49] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:49] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:49] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.15, #queue-req: 0, 
[2025-09-30 13:53:49] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:53:49] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:49] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:49] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:49] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:49] Decode batch. #running-req: 1, #token: 155, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.44, #queue-req: 0, 
[2025-09-30 13:53:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:50] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:50] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:50] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.05, #queue-req: 0, 
[2025-09-30 13:53:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:50] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:50] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.52, #queue-req: 0, 
[2025-09-30 13:53:50] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 13:53:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:51] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:51] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:51] Decode batch. #running-req: 1, #token: 168, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.10, #queue-req: 0, 
[2025-09-30 13:53:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:51] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:51] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:51] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.30, #queue-req: 0, 
[2025-09-30 13:53:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:51] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:52] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.78, #queue-req: 0, 
[2025-09-30 13:53:52] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 13:53:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:52] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:52] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:52] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.05, #queue-req: 0, 
[2025-09-30 13:53:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:52] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:53] Decode batch. #running-req: 1, #token: 1026, token usage: 0.02, cuda graph: True, gen throughput (token/s): 100.53, #queue-req: 0, 
[2025-09-30 13:53:53] Decode batch. #running-req: 1, #token: 1066, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 13:53:53] Decode batch. #running-req: 1, #token: 1106, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 13:53:54] Decode batch. #running-req: 1, #token: 1146, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.20, #queue-req: 0, 
[2025-09-30 13:53:54] Decode batch. #running-req: 1, #token: 1186, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.11, #queue-req: 0, 
[2025-09-30 13:53:54] Decode batch. #running-req: 1, #token: 1226, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 13:53:55] Decode batch. #running-req: 1, #token: 1266, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.12, #queue-req: 0, 
[2025-09-30 13:53:55] Decode batch. #running-req: 1, #token: 1306, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 13:53:55] Decode batch. #running-req: 1, #token: 1346, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.64, #queue-req: 0, 
[2025-09-30 13:53:55] Decode batch. #running-req: 1, #token: 1386, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.55, #queue-req: 0, 
[2025-09-30 13:53:56] Decode batch. #running-req: 1, #token: 1426, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.47, #queue-req: 0, 
[2025-09-30 13:53:56] Decode batch. #running-req: 1, #token: 1466, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.45, #queue-req: 0, 
[2025-09-30 13:53:56] Decode batch. #running-req: 1, #token: 1506, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.44, #queue-req: 0, 
[2025-09-30 13:53:57] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:57] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:57] Decode batch. #running-req: 1, #token: 978, token usage: 0.02, cuda graph: True, gen throughput (token/s): 115.16, #queue-req: 0, 
[2025-09-30 13:53:57] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:53:57] Prefill batch. #new-seq: 1, #new-token: 1013, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:53:57] Decode batch. #running-req: 1, #token: 1058, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.45, #queue-req: 0, 
[2025-09-30 13:53:57] Decode batch. #running-req: 1, #token: 1098, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.22, #queue-req: 0, 
[2025-09-30 13:53:58] Decode batch. #running-req: 1, #token: 1138, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.09, #queue-req: 0, 
[2025-09-30 13:53:58] Decode batch. #running-req: 1, #token: 1178, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 13:53:58] Decode batch. #running-req: 1, #token: 1218, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.03, #queue-req: 0, 
[2025-09-30 13:53:59] Decode batch. #running-req: 1, #token: 1258, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 13:53:59] Decode batch. #running-req: 1, #token: 1298, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 13:53:59] Decode batch. #running-req: 1, #token: 1338, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.56, #queue-req: 0, 
[2025-09-30 13:54:00] Decode batch. #running-req: 1, #token: 1378, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.51, #queue-req: 0, 
[2025-09-30 13:54:00] Decode batch. #running-req: 1, #token: 1418, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.40, #queue-req: 0, 
[2025-09-30 13:54:00] Decode batch. #running-req: 1, #token: 1458, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.40, #queue-req: 0, 
[2025-09-30 13:54:00] Decode batch. #running-req: 1, #token: 1498, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 13:54:01] Decode batch. #running-req: 1, #token: 1538, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 13:54:01] Decode batch. #running-req: 1, #token: 1578, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.90, #queue-req: 0, 
[2025-09-30 13:54:01] Decode batch. #running-req: 1, #token: 1618, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.83, #queue-req: 0, 
[2025-09-30 13:54:02] Decode batch. #running-req: 1, #token: 1658, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.73, #queue-req: 0, 
[2025-09-30 13:54:02] Decode batch. #running-req: 1, #token: 1698, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.79, #queue-req: 0, 
[2025-09-30 13:54:02] Decode batch. #running-req: 1, #token: 1738, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.74, #queue-req: 0, 
[2025-09-30 13:54:03] Decode batch. #running-req: 1, #token: 1778, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.77, #queue-req: 0, 
[2025-09-30 13:54:03] Decode batch. #running-req: 1, #token: 1818, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 13:54:03] Decode batch. #running-req: 1, #token: 1858, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.22, #queue-req: 0, 
[2025-09-30 13:54:03] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:03] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:03] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:03] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:04] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:04] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.56, #queue-req: 0, 
[2025-09-30 13:54:04] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.00, #queue-req: 0, 
[2025-09-30 13:54:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:04] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:04] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.05, #queue-req: 0, 
[2025-09-30 13:54:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:04] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:05] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:05] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:05] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.59, #queue-req: 0, 
[2025-09-30 13:54:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:05] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:05] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.60, #queue-req: 0, 
[2025-09-30 13:54:05] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:54:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:06] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:06] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:06] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.13, #queue-req: 0, 
[2025-09-30 13:54:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:06] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:06] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.75, #queue-req: 0, 
[2025-09-30 13:54:07] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 13:54:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:07] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:07] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:07] Decode batch. #running-req: 1, #token: 138, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.33, #queue-req: 0, 
[2025-09-30 13:54:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:07] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:07] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:07] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.07, #queue-req: 0, 
[2025-09-30 13:54:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:07] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:08] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.23, #queue-req: 0, 
[2025-09-30 13:54:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:08] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:08] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.23, #queue-req: 0, 
[2025-09-30 13:54:08] Decode batch. #running-req: 1, #token: 675, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.73, #queue-req: 0, 
[2025-09-30 13:54:09] Decode batch. #running-req: 1, #token: 715, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.54, #queue-req: 0, 
[2025-09-30 13:54:09] Decode batch. #running-req: 1, #token: 755, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.44, #queue-req: 0, 
[2025-09-30 13:54:09] Decode batch. #running-req: 1, #token: 795, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 13:54:10] Decode batch. #running-req: 1, #token: 835, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 13:54:10] Decode batch. #running-req: 1, #token: 875, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.91, #queue-req: 0, 
[2025-09-30 13:54:10] Decode batch. #running-req: 1, #token: 915, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.85, #queue-req: 0, 
[2025-09-30 13:54:10] Decode batch. #running-req: 1, #token: 955, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.78, #queue-req: 0, 
[2025-09-30 13:54:11] Decode batch. #running-req: 1, #token: 995, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.71, #queue-req: 0, 
[2025-09-30 13:54:11] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 13:54:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:11] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:11] Decode batch. #running-req: 1, #token: 626, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.23, #queue-req: 0, 
[2025-09-30 13:54:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:12] Prefill batch. #new-seq: 1, #new-token: 1249, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:12] Decode batch. #running-req: 1, #token: 1381, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.31, #queue-req: 0, 
[2025-09-30 13:54:12] Decode batch. #running-req: 1, #token: 1421, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.36, #queue-req: 0, 
[2025-09-30 13:54:12] Decode batch. #running-req: 1, #token: 1461, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.32, #queue-req: 0, 
[2025-09-30 13:54:13] Decode batch. #running-req: 1, #token: 1501, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 13:54:13] Decode batch. #running-req: 1, #token: 1541, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 13:54:13] Decode batch. #running-req: 1, #token: 1581, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.90, #queue-req: 0, 
[2025-09-30 13:54:14] Decode batch. #running-req: 1, #token: 1621, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.84, #queue-req: 0, 
[2025-09-30 13:54:14] Decode batch. #running-req: 1, #token: 1661, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.78, #queue-req: 0, 
[2025-09-30 13:54:14] Decode batch. #running-req: 1, #token: 1701, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.77, #queue-req: 0, 
[2025-09-30 13:54:15] Decode batch. #running-req: 1, #token: 1741, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.75, #queue-req: 0, 
[2025-09-30 13:54:15] Decode batch. #running-req: 1, #token: 1781, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.76, #queue-req: 0, 
[2025-09-30 13:54:15] Decode batch. #running-req: 1, #token: 1821, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 13:54:16] Decode batch. #running-req: 1, #token: 1861, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.18, #queue-req: 0, 
[2025-09-30 13:54:16] Decode batch. #running-req: 1, #token: 1901, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.11, #queue-req: 0, 
[2025-09-30 13:54:16] Decode batch. #running-req: 1, #token: 1941, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.09, #queue-req: 0, 
[2025-09-30 13:54:16] Decode batch. #running-req: 1, #token: 1981, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.14, #queue-req: 0, 
[2025-09-30 13:54:17] Decode batch. #running-req: 1, #token: 2021, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.09, #queue-req: 0, 
[2025-09-30 13:54:17] Decode batch. #running-req: 1, #token: 2061, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 13:54:17] Decode batch. #running-req: 1, #token: 2101, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.58, #queue-req: 0, 
[2025-09-30 13:54:18] Decode batch. #running-req: 1, #token: 2141, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.54, #queue-req: 0, 
[2025-09-30 13:54:18] Decode batch. #running-req: 1, #token: 2181, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.53, #queue-req: 0, 
[2025-09-30 13:54:18] Decode batch. #running-req: 1, #token: 2221, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.51, #queue-req: 0, 
[2025-09-30 13:54:19] Decode batch. #running-req: 1, #token: 2261, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.54, #queue-req: 0, 
[2025-09-30 13:54:19] Decode batch. #running-req: 1, #token: 2301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.49, #queue-req: 0, 
[2025-09-30 13:54:19] Decode batch. #running-req: 1, #token: 2341, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.03, #queue-req: 0, 
[2025-09-30 13:54:20] Decode batch. #running-req: 1, #token: 2381, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.96, #queue-req: 0, 
[2025-09-30 13:54:20] Decode batch. #running-req: 1, #token: 2421, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.00, #queue-req: 0, 
[2025-09-30 13:54:20] Decode batch. #running-req: 1, #token: 2461, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.95, #queue-req: 0, 
[2025-09-30 13:54:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:20] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:20] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:21] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:21] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 85.01, #queue-req: 0, 
[2025-09-30 13:54:21] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 13:54:21] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 13:54:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:21] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:21] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:21] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:22] Decode batch. #running-req: 1, #token: 171, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.32, #queue-req: 0, 
[2025-09-30 13:54:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:22] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:22] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:22] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.29, #queue-req: 0, 
[2025-09-30 13:54:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:22] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:22] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 13:54:23] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 13:54:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:23] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:23] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.68, #queue-req: 0, 
[2025-09-30 13:54:23] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:24] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 13:54:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:24] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:24] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.48, #queue-req: 0, 
[2025-09-30 13:54:24] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 13:54:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:24] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:24] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:24] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:24] Decode batch. #running-req: 1, #token: 185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.98, #queue-req: 0, 
[2025-09-30 13:54:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:25] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:25] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:25] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.71, #queue-req: 0, 
[2025-09-30 13:54:25] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:25] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:25] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 13:54:26] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:54:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:26] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:26] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:26] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.75, #queue-req: 0, 
[2025-09-30 13:54:26] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:26] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:26] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.71, #queue-req: 0, 
[2025-09-30 13:54:27] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 13:54:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:27] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:27] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:27] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.02, #queue-req: 0, 
[2025-09-30 13:54:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:27] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:27] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 13:54:28] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:54:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:28] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:28] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:28] Decode batch. #running-req: 1, #token: 158, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.88, #queue-req: 0, 
[2025-09-30 13:54:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:28] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:28] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:29] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 88.50, #queue-req: 0, 
[2025-09-30 13:54:29] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:29] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:29] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.29, #queue-req: 0, 
[2025-09-30 13:54:29] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 13:54:29] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:29] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:30] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:30] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.28, #queue-req: 0, 
[2025-09-30 13:54:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:30] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:30] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:30] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 88.56, #queue-req: 0, 
[2025-09-30 13:54:30] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:30] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:30] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 13:54:31] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 13:54:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:31] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:31] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:31] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.84, #queue-req: 0, 
[2025-09-30 13:54:31] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:31] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:32] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 13:54:32] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 13:54:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:32] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:32] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:32] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.73, #queue-req: 0, 
[2025-09-30 13:54:32] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:33] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:33] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 13:54:33] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 13:54:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:33] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:33] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.15, #queue-req: 0, 
[2025-09-30 13:54:33] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:33] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:34] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:34] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:34] Decode batch. #running-req: 1, #token: 175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.56, #queue-req: 0, 
[2025-09-30 13:54:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:34] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:34] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:34] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.92, #queue-req: 0, 
[2025-09-30 13:54:34] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:34] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:35] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 13:54:35] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 13:54:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:35] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:35] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:35] Decode batch. #running-req: 1, #token: 208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.33, #queue-req: 0, 
[2025-09-30 13:54:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:35] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:35] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:36] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.46, #queue-req: 0, 
[2025-09-30 13:54:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:36] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:36] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 13:54:36] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 13:54:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:36] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:36] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:37] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:37] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.87, #queue-req: 0, 
[2025-09-30 13:54:37] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.79, #queue-req: 0, 
[2025-09-30 13:54:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:37] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:37] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:37] Decode batch. #running-req: 1, #token: 135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.80, #queue-req: 0, 
[2025-09-30 13:54:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:38] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:38] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:38] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.29, #queue-req: 0, 
[2025-09-30 13:54:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:38] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:38] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 128.66, #queue-req: 0, 
[2025-09-30 13:54:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:38] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:39] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.16, #queue-req: 0, 
[2025-09-30 13:54:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:39] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:39] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:39] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:39] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.65, #queue-req: 0, 
[2025-09-30 13:54:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:39] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:39] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 13:54:40] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 13:54:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:40] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:40] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:40] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.48, #queue-req: 0, 
[2025-09-30 13:54:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:40] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:40] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.74, #queue-req: 0, 
[2025-09-30 13:54:41] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 13:54:41] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:41] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:41] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:41] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:41] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:41] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:41] Decode batch. #running-req: 1, #token: 567, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.46, #queue-req: 0, 
[2025-09-30 13:54:41] Decode batch. #running-req: 1, #token: 607, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.98, #queue-req: 0, 
[2025-09-30 13:54:42] Decode batch. #running-req: 1, #token: 647, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.85, #queue-req: 0, 
[2025-09-30 13:54:42] Decode batch. #running-req: 1, #token: 687, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.68, #queue-req: 0, 
[2025-09-30 13:54:42] Decode batch. #running-req: 1, #token: 727, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.54, #queue-req: 0, 
[2025-09-30 13:54:43] Decode batch. #running-req: 1, #token: 767, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.40, #queue-req: 0, 
[2025-09-30 13:54:43] Decode batch. #running-req: 1, #token: 807, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.99, #queue-req: 0, 
[2025-09-30 13:54:43] Decode batch. #running-req: 1, #token: 847, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.84, #queue-req: 0, 
[2025-09-30 13:54:44] Decode batch. #running-req: 1, #token: 887, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.82, #queue-req: 0, 
[2025-09-30 13:54:44] Decode batch. #running-req: 1, #token: 927, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.77, #queue-req: 0, 
[2025-09-30 13:54:44] Decode batch. #running-req: 1, #token: 967, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.74, #queue-req: 0, 
[2025-09-30 13:54:44] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:44] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:45] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.40, #queue-req: 0, 
[2025-09-30 13:54:45] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:45] Prefill batch. #new-seq: 1, #new-token: 1508, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:45] Decode batch. #running-req: 1, #token: 1646, token usage: 0.03, cuda graph: True, gen throughput (token/s): 104.55, #queue-req: 0, 
[2025-09-30 13:54:45] Decode batch. #running-req: 1, #token: 1686, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.73, #queue-req: 0, 
[2025-09-30 13:54:46] Decode batch. #running-req: 1, #token: 1726, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.72, #queue-req: 0, 
[2025-09-30 13:54:46] Decode batch. #running-req: 1, #token: 1766, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.72, #queue-req: 0, 
[2025-09-30 13:54:46] Decode batch. #running-req: 1, #token: 1806, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 13:54:46] Decode batch. #running-req: 1, #token: 1846, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.28, #queue-req: 0, 
[2025-09-30 13:54:47] Decode batch. #running-req: 1, #token: 1886, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.15, #queue-req: 0, 
[2025-09-30 13:54:47] Decode batch. #running-req: 1, #token: 1926, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.12, #queue-req: 0, 
[2025-09-30 13:54:47] Decode batch. #running-req: 1, #token: 1966, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.13, #queue-req: 0, 
[2025-09-30 13:54:48] Decode batch. #running-req: 1, #token: 2006, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 13:54:48] Decode batch. #running-req: 1, #token: 2046, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.06, #queue-req: 0, 
[2025-09-30 13:54:48] Decode batch. #running-req: 1, #token: 2086, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.64, #queue-req: 0, 
[2025-09-30 13:54:49] Decode batch. #running-req: 1, #token: 2126, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.55, #queue-req: 0, 
[2025-09-30 13:54:49] Decode batch. #running-req: 1, #token: 2166, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.51, #queue-req: 0, 
[2025-09-30 13:54:49] Decode batch. #running-req: 1, #token: 2206, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.54, #queue-req: 0, 
[2025-09-30 13:54:50] Decode batch. #running-req: 1, #token: 2246, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.49, #queue-req: 0, 
[2025-09-30 13:54:50] Decode batch. #running-req: 1, #token: 2286, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.49, #queue-req: 0, 
[2025-09-30 13:54:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:50] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:50] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:50] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:50] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:50] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.32, #queue-req: 0, 
[2025-09-30 13:54:51] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 134.03, #queue-req: 0, 
[2025-09-30 13:54:51] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:54:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:51] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:51] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:51] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:52] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:52] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:52] Decode batch. #running-req: 1, #token: 214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.59, #queue-req: 0, 
[2025-09-30 13:54:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:52] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:52] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.33, #queue-req: 0, 
[2025-09-30 13:54:52] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 13:54:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:52] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:53] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:53] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:53] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.50, #queue-req: 0, 
[2025-09-30 13:54:53] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:53] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:53] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.76, #queue-req: 0, 
[2025-09-30 13:54:53] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:53] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 13:54:53] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:53] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:53] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:54] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.09, #queue-req: 0, 
[2025-09-30 13:54:54] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:54] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:54] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.49, #queue-req: 0, 
[2025-09-30 13:54:54] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 13:54:54] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:54] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.27, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 131, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:55] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.88, #queue-req: 0, 
[2025-09-30 13:54:55] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:54:56] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:56] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:56] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:56] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:56] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.35, #queue-req: 0, 
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.35, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.76, #queue-req: 0, 
[2025-09-30 13:54:58] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] Decode batch. #running-req: 1, #token: 171, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.33, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 69.96, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.53, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.57, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.24, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.52, #queue-req: 0, 
[2025-09-30 13:55:01] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:01] Decode batch. #running-req: 1, #token: 160, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.07, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.24, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.88, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.45, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:03] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:03] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.66, #queue-req: 0, 
[2025-09-30 13:55:03] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:03] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 360, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 13:55:04] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.12, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.01, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.97, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.22, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.61, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.33, #queue-req: 0, 
[2025-09-30 13:55:06] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.83, #queue-req: 0, 
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.60, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 13:55:08] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:55:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:08] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:08] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:08] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 75.95, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.59, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:09] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.79, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:09] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:09] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 164, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.05, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.74, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.12, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.07, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.32, #queue-req: 0, 
[2025-09-30 13:55:12] Decode batch. #running-req: 1, #token: 336, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.78, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] Decode batch. #running-req: 1, #token: 174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.85, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 915, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.56, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 955, token usage: 0.01, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 995, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.71, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 1035, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 1075, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 1115, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.23, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 1155, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.62, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 880, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.49, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 920, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 900, #cached-token: 141, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 1050, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.72, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 1090, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.22, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 1130, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.04, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 1170, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.84, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 1210, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.05, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 1250, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.05, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 1290, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.76, #queue-req: 0, 
[2025-09-30 13:55:18] Decode batch. #running-req: 1, #token: 1330, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.34, #queue-req: 0, 
[2025-09-30 13:55:18] Decode batch. #running-req: 1, #token: 1370, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.48, #queue-req: 0, 
[2025-09-30 13:55:18] Decode batch. #running-req: 1, #token: 1410, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 1450, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 1490, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.27, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 1530, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 1570, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 1610, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.87, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 1650, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.83, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 1690, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.75, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 1730, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.75, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 1770, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.76, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 1810, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 13:55:22] Decode batch. #running-req: 1, #token: 1850, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.21, #queue-req: 0, 
[2025-09-30 13:55:22] Decode batch. #running-req: 1, #token: 1890, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.22, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:22] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:22] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.69, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.99, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 148, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.37, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:24] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.16, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 748, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.08, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 788, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.35, #queue-req: 0, 
[2025-09-30 13:55:25] Decode batch. #running-req: 1, #token: 828, token usage: 0.01, cuda graph: True, gen throughput (token/s): 128.85, #queue-req: 0, 
[2025-09-30 13:55:25] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.40, #queue-req: 0, 
[2025-09-30 13:55:25] Decode batch. #running-req: 1, #token: 908, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.84, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 948, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.82, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 988, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.61, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 1028, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 1068, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.39, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 1108, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 13:55:27] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:27] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.97, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.67, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 13:55:28] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:28] Prefill batch. #new-seq: 1, #new-token: 1106, #cached-token: 278, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 1386, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.44, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 1426, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.30, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 1466, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 1506, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 1546, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.05, #queue-req: 0, 
[2025-09-30 13:55:30] Decode batch. #running-req: 1, #token: 1586, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.49, #queue-req: 0, 
[2025-09-30 13:55:30] Decode batch. #running-req: 1, #token: 1626, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.81, #queue-req: 0, 
[2025-09-30 13:55:30] Decode batch. #running-req: 1, #token: 1666, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.80, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 1706, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.78, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 1746, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.76, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 1786, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.76, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 1826, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 1866, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.24, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 1906, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.22, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 1946, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.17, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 1986, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.17, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 2026, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.16, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 2066, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.94, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 2106, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.59, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 2146, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.57, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 2186, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.47, #queue-req: 0, 
[2025-09-30 13:55:35] Decode batch. #running-req: 1, #token: 2226, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.52, #queue-req: 0, 
[2025-09-30 13:55:35] Decode batch. #running-req: 1, #token: 2266, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.52, #queue-req: 0, 
[2025-09-30 13:55:35] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:35] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:36] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:36] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 60.68, #queue-req: 0, 
[2025-09-30 13:55:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:36] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:36] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 13:55:36] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:37] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.70, #queue-req: 0, 
[2025-09-30 13:55:37] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.23, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.90, #queue-req: 0, 
[2025-09-30 13:55:37] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] Decode batch. #running-req: 1, #token: 137, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.07, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] Decode batch. #running-req: 1, #token: 215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.25, #queue-req: 0, 
[2025-09-30 13:55:39] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] Decode batch. #running-req: 1, #token: 120, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.33, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.28, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.30, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:40] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:40] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.40, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:41] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:41] Decode batch. #running-req: 1, #token: 1044, token usage: 0.02, cuda graph: True, gen throughput (token/s): 63.13, #queue-req: 0, 
[2025-09-30 13:55:41] Decode batch. #running-req: 1, #token: 1084, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 13:55:41] Decode batch. #running-req: 1, #token: 1124, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.71, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 1164, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 1204, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.06, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 1244, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 1284, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 1324, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.57, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 1364, token usage: 0.02, cuda graph: True, gen throughput (token/s): 127.59, #queue-req: 0, 
[2025-09-30 13:55:44] Decode batch. #running-req: 1, #token: 1404, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.93, #queue-req: 0, 
[2025-09-30 13:55:44] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:44] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:44] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:44] Prefill batch. #new-seq: 1, #new-token: 1091, #cached-token: 349, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:44] Decode batch. #running-req: 1, #token: 1447, token usage: 0.02, cuda graph: True, gen throughput (token/s): 95.74, #queue-req: 0, 
[2025-09-30 13:55:44] Decode batch. #running-req: 1, #token: 1487, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.30, #queue-req: 0, 
[2025-09-30 13:55:45] Decode batch. #running-req: 1, #token: 1527, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 13:55:45] Decode batch. #running-req: 1, #token: 1567, token usage: 0.02, cuda graph: True, gen throughput (token/s): 126.93, #queue-req: 0, 
[2025-09-30 13:55:45] Decode batch. #running-req: 1, #token: 1607, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 1647, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.74, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 1687, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.74, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 1727, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.73, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 1767, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.76, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 1807, token usage: 0.03, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 1847, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.38, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 1887, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.22, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 1927, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.17, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 1967, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.13, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 2007, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 2047, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.57, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 2087, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.64, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 2127, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.55, #queue-req: 0, 
[2025-09-30 13:55:50] Decode batch. #running-req: 1, #token: 2167, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.21, #queue-req: 0, 
[2025-09-30 13:55:50] Decode batch. #running-req: 1, #token: 2207, token usage: 0.03, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 13:55:50] Decode batch. #running-req: 1, #token: 2247, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.51, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 2287, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.39, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 2327, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 2367, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.52, #queue-req: 0, 
[2025-09-30 13:55:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.81, #queue-req: 0, 
[2025-09-30 13:55:52] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.45, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.81, #queue-req: 0, 
[2025-09-30 13:55:53] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:53] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:53] Decode batch. #running-req: 1, #token: 695, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.18, #queue-req: 0, 
[2025-09-30 13:55:53] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.01, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 775, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.27, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 815, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.94, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 855, token usage: 0.01, cuda graph: True, gen throughput (token/s): 128.06, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 895, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.05, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 935, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.80, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 975, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 1015, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 13:55:56] Decode batch. #running-req: 1, #token: 1055, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 13:55:56] Decode batch. #running-req: 1, #token: 1095, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.69, #queue-req: 0, 
[2025-09-30 13:55:56] Decode batch. #running-req: 1, #token: 1135, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.40, #queue-req: 0, 
[2025-09-30 13:55:56] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:56] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 700, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.32, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.58, #queue-req: 0, 
[2025-09-30 13:55:57] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:57] Prefill batch. #new-seq: 1, #new-token: 1151, #cached-token: 374, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 1541, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.09, #queue-req: 0, 
[2025-09-30 13:55:58] Decode batch. #running-req: 1, #token: 1581, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.07, #queue-req: 0, 
[2025-09-30 13:55:58] Decode batch. #running-req: 1, #token: 1621, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.82, #queue-req: 0, 
[2025-09-30 13:55:58] Decode batch. #running-req: 1, #token: 1661, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.79, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 1701, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.43, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 1741, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.74, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 1781, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.74, #queue-req: 0, 
[2025-09-30 13:56:00] Decode batch. #running-req: 1, #token: 1821, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 13:56:00] Decode batch. #running-req: 1, #token: 1861, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.72, #queue-req: 0, 
[2025-09-30 13:56:00] Decode batch. #running-req: 1, #token: 1901, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.57, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 1941, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.14, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 1981, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.16, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 2021, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.14, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 2061, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.53, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 2101, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.80, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 2141, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.21, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 2181, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.56, #queue-req: 0, 
[2025-09-30 13:56:03] Decode batch. #running-req: 1, #token: 2221, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.47, #queue-req: 0, 
[2025-09-30 13:56:03] Decode batch. #running-req: 1, #token: 2261, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.46, #queue-req: 0, 
[2025-09-30 13:56:03] Decode batch. #running-req: 1, #token: 2301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.79, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 2341, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.08, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 2381, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.01, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 2421, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.01, #queue-req: 0, 
[2025-09-30 13:56:05] Decode batch. #running-req: 1, #token: 2461, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.89, #queue-req: 0, 
[2025-09-30 13:56:05] Decode batch. #running-req: 1, #token: 2501, token usage: 0.04, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 13:56:05] Decode batch. #running-req: 1, #token: 2541, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.18, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 2581, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.72, #queue-req: 0, 
[2025-09-30 13:56:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:06] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:06] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.85, #queue-req: 0, 
[2025-09-30 13:56:06] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:06] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.83, #queue-req: 0, 
[2025-09-30 13:56:07] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.85, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.85, #queue-req: 0, 
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.71, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.99, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 60.68, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.77, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.73, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.75, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.65, #queue-req: 0, 
[2025-09-30 13:56:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:11] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:11] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.09, #queue-req: 0, 
[2025-09-30 13:56:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:12] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.89, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:56:12] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:12] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] Decode batch. #running-req: 1, #token: 196, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.70, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 178, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.26, #queue-req: 0, 
[2025-09-30 13:56:14] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.14, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:14] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.91, #queue-req: 0, 
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:56:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.96, #queue-req: 0, 
[2025-09-30 13:56:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.60, #queue-req: 0, 
[2025-09-30 13:56:15] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 181, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.49, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 13:56:17] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.25, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.83, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 143, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] Decode batch. #running-req: 1, #token: 152, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.49, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:18] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:18] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.78, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:18] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.87, #queue-req: 0, 
[2025-09-30 13:56:19] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.42, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.26, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 13:56:20] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:56:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:20] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:20] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:20] INFO:     127.0.0.1:49064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
