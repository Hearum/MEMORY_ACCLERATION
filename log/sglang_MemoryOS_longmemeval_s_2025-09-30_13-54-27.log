/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:54:33.373996 2768455 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:54:33.373996 2768455 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-30 13:54:33] server_args=ServerArgs(model_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_path='/mnt/data/models/Llama-3.2-3B-Instruct', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30003, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.98, max_running_requests=50, max_queued_requests=9223372036854775807, max_total_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=153836219, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-customer-labels', tokenizer_metrics_allowed_customer_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, enable_trace=False, oltp_traces_endpoint='localhost:4317', api_key=None, served_model_name='LLAMA', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='triton', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=True, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=True, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_cutedsl_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:54:34] Using default HuggingFace chat template with detected content format: string
/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/shm/anaconda3/envs/sglang/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0930 13:54:39.870558 2768744 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:54:39.870558 2768744 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0930 13:54:40.188240 2768743 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0930 13:54:40.188240 2768743 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-30 13:54:40] Init torch distributed begin.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-09-30 13:54:41] Init torch distributed ends. mem usage=0.00 GB
[2025-09-30 13:54:41] CUDA-fused xIELU not available (No module named 'xielu') – falling back to a Python version.
For CUDA xIELU (experimental), `pip install git+https://github.com/nickjbrowning/XIELU`
[2025-09-30 13:54:41] MOE_RUNNER_BACKEND is not initialized, using triton backend
[2025-09-30 13:54:41] Load weight begin. avail mem=23.13 GB
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.06s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]

[2025-09-30 13:54:43] Load weight end. type=LlamaForCausalLM, dtype=torch.bfloat16, avail mem=17.01 GB, mem usage=6.12 GB.
[2025-09-30 13:54:43] KV Cache is allocated. #tokens: 64000, K size: 3.42 GB, V size: 3.42 GB
[2025-09-30 13:54:43] Memory pool end. avail mem=10.14 GB
[2025-09-30 13:54:43] Capture cuda graph begin. This can take up to several minutes. avail mem=10.10 GB
[2025-09-30 13:54:43] Capture cuda graph bs [1, 2, 4, 8]
  0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=10.10 GB):   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=10.10 GB):  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Capturing batches (bs=4 avail_mem=10.05 GB):  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Capturing batches (bs=2 avail_mem=10.04 GB):  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Capturing batches (bs=1 avail_mem=10.04 GB):  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Capturing batches (bs=1 avail_mem=10.04 GB): 100%|██████████| 4/4 [00:00<00:00,  7.10it/s]Capturing batches (bs=1 avail_mem=10.04 GB): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]
[2025-09-30 13:54:44] Capture cuda graph end. Time elapsed: 1.12 s. mem usage=0.07 GB. avail mem=10.04 GB.
[2025-09-30 13:54:44] max_total_num_tokens=64000, chunked_prefill_size=4096, max_prefill_tokens=16384, max_running_requests=50, context_len=131072, available_gpu_mem=10.04 GB
[2025-09-30 13:54:45] INFO:     Started server process [2768455]
[2025-09-30 13:54:45] INFO:     Waiting for application startup.
[2025-09-30 13:54:45] INFO:     Application startup complete.
[2025-09-30 13:54:45] INFO:     Uvicorn running on http://0.0.0.0:30003 (Press CTRL+C to quit)
[2025-09-30 13:54:46] INFO:     127.0.0.1:44012 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 13:54:46] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:46] INFO:     127.0.0.1:44024 - "POST /generate HTTP/1.1" 200 OK
[2025-09-30 13:54:46] The server is fired up and ready to roll!
[2025-09-30 13:54:55] Prefill batch. #new-seq: 1, #new-token: 465, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 499, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3.58, #queue-req: 0, 
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.64, #queue-req: 0, 
[2025-09-30 13:54:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:56] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:56] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.78, #queue-req: 0, 
[2025-09-30 13:54:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.24, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 967, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 623, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] Decode batch. #running-req: 1, #token: 816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.58, #queue-req: 0, 
[2025-09-30 13:54:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:57] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:57] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 13:54:58] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:58] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.40, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 689, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 1320, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 704, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.82, #queue-req: 0, 
[2025-09-30 13:54:59] Decode batch. #running-req: 1, #token: 908, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 13:54:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:54:59] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.54, #queue-req: 0, 
[2025-09-30 13:55:00] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 1123, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:00] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:00] Decode batch. #running-req: 1, #token: 598, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.48, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:01] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.91, #queue-req: 0, 
[2025-09-30 13:55:01] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 13:55:01] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:55:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:01] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 497, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.88, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 493, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 496, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.17, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 1008, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:02] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:02] Decode batch. #running-req: 1, #token: 763, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.90, #queue-req: 0, 
[2025-09-30 13:55:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:03] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.70, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 13:55:03] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:55:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:03] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 583, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.48, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 989, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:04] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:04] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.47, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 646, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.91, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.79, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:05] Prefill batch. #new-seq: 1, #new-token: 404, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:05] Decode batch. #running-req: 1, #token: 498, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.81, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 476, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] Decode batch. #running-req: 1, #token: 504, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.40, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 889, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:06] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:06] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.88, #queue-req: 0, 
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 482, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.93, #queue-req: 0, 
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:07] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 125.03, #queue-req: 0, 
[2025-09-30 13:55:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:07] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:08] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 13:55:08] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 13:55:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:08] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:08] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:08] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.66, #queue-req: 0, 
[2025-09-30 13:55:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:08] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:09] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 723, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.83, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 763, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 13:55:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:09] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:09] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.82, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.35, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 482, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.73, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 1139, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:10] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 860, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.42, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.72, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:11] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.60, #queue-req: 0, 
[2025-09-30 13:55:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:11] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] Decode batch. #running-req: 1, #token: 723, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.61, #queue-req: 0, 
[2025-09-30 13:55:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:12] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:12] Decode batch. #running-req: 1, #token: 220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.32, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 13:55:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:13] Prefill batch. #new-seq: 1, #new-token: 1309, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:13] Prefill batch. #new-seq: 1, #new-token: 766, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 931, token usage: 0.01, cuda graph: True, gen throughput (token/s): 84.38, #queue-req: 0, 
[2025-09-30 13:55:13] Decode batch. #running-req: 1, #token: 971, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 13:55:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:14] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.94, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 13:55:14] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:55:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:14] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 836, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.40, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 1176, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 416, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 88.85, #queue-req: 0, 
[2025-09-30 13:55:15] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.16, #queue-req: 0, 
[2025-09-30 13:55:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:15] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.61, #queue-req: 0, 
[2025-09-30 13:55:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:16] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.88, #queue-req: 0, 
[2025-09-30 13:55:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:16] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:16] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:16] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:16] Decode batch. #running-req: 1, #token: 517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.34, #queue-req: 0, 
[2025-09-30 13:55:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:17] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.82, #queue-req: 0, 
[2025-09-30 13:55:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:17] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:17] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:17] Decode batch. #running-req: 1, #token: 424, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.56, #queue-req: 0, 
[2025-09-30 13:55:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:18] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:18] Prefill batch. #new-seq: 1, #new-token: 386, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:18] Decode batch. #running-req: 1, #token: 580, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.56, #queue-req: 0, 
[2025-09-30 13:55:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:18] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:18] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 382, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 88.43, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 452, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:19] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:19] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.44, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 563, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.40, #queue-req: 0, 
[2025-09-30 13:55:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:20] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.33, #queue-req: 0, 
[2025-09-30 13:55:20] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 13:55:21] Decode batch. #running-req: 1, #token: 392, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 13:55:22] Decode batch. #running-req: 1, #token: 432, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.97, #queue-req: 0, 
[2025-09-30 13:55:22] Decode batch. #running-req: 1, #token: 472, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.84, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:22] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:22] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:22] Decode batch. #running-req: 1, #token: 201, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.96, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:22] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.74, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 92.84, #queue-req: 0, 
[2025-09-30 13:55:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:23] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:23] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.54, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 380, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 13:55:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:24] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:24] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:24] Decode batch. #running-req: 1, #token: 602, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.76, #queue-req: 0, 
[2025-09-30 13:55:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:24] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:25] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 592, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:25] Decode batch. #running-req: 1, #token: 597, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.46, #queue-req: 0, 
[2025-09-30 13:55:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:25] Prefill batch. #new-seq: 1, #new-token: 1064, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:25] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:25] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.38, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 13:55:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:26] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.91, #queue-req: 0, 
[2025-09-30 13:55:26] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:55:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:27] Prefill batch. #new-seq: 1, #new-token: 905, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:27] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 538, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.76, #queue-req: 0, 
[2025-09-30 13:55:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:27] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.36, #queue-req: 0, 
[2025-09-30 13:55:27] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 13:55:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:28] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:28] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 455, token usage: 0.01, cuda graph: True, gen throughput (token/s): 89.72, #queue-req: 0, 
[2025-09-30 13:55:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:28] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:28] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:28] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.88, #queue-req: 0, 
[2025-09-30 13:55:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:29] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.62, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:55:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:29] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:29] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:29] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.52, #queue-req: 0, 
[2025-09-30 13:55:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:30] Prefill batch. #new-seq: 1, #new-token: 2869, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:30] Decode batch. #running-req: 1, #token: 2922, token usage: 0.05, cuda graph: True, gen throughput (token/s): 68.42, #queue-req: 0, 
[2025-09-30 13:55:30] Decode batch. #running-req: 1, #token: 2962, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.49, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 3002, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.46, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 3042, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 13:55:31] Decode batch. #running-req: 1, #token: 3082, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.31, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 3122, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 3162, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 13:55:32] Decode batch. #running-req: 1, #token: 3202, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 3242, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 3282, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.92, #queue-req: 0, 
[2025-09-30 13:55:33] Decode batch. #running-req: 1, #token: 3322, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 3362, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 3402, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 13:55:34] Decode batch. #running-req: 1, #token: 3442, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 13:55:35] Decode batch. #running-req: 1, #token: 3482, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 13:55:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:35] Prefill batch. #new-seq: 1, #new-token: 2849, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:35] Decode batch. #running-req: 1, #token: 2907, token usage: 0.05, cuda graph: True, gen throughput (token/s): 85.70, #queue-req: 0, 
[2025-09-30 13:55:35] Decode batch. #running-req: 1, #token: 2947, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.53, #queue-req: 0, 
[2025-09-30 13:55:36] Decode batch. #running-req: 1, #token: 2987, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.54, #queue-req: 0, 
[2025-09-30 13:55:36] Decode batch. #running-req: 1, #token: 3027, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.50, #queue-req: 0, 
[2025-09-30 13:55:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:36] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:36] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.05, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 498, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.87, #queue-req: 0, 
[2025-09-30 13:55:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:37] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 13:55:37] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.25, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 504, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:38] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:38] Decode batch. #running-req: 1, #token: 479, token usage: 0.01, cuda graph: True, gen throughput (token/s): 92.05, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.30, #queue-req: 0, 
[2025-09-30 13:55:39] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 13:55:39] Decode batch. #running-req: 1, #token: 380, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:39] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.16, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:40] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:40] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:40] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.67, #queue-req: 0, 
[2025-09-30 13:55:40] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:55:41] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:55:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:41] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:41] Prefill batch. #new-seq: 1, #new-token: 476, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:41] Decode batch. #running-req: 1, #token: 571, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.78, #queue-req: 0, 
[2025-09-30 13:55:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:41] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:42] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 548, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 560, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.22, #queue-req: 0, 
[2025-09-30 13:55:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:42] Prefill batch. #new-seq: 1, #new-token: 1173, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:42] Prefill batch. #new-seq: 1, #new-token: 699, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.01, #queue-req: 0, 
[2025-09-30 13:55:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:42] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:42] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 13:55:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:43] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:43] Prefill batch. #new-seq: 1, #new-token: 695, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:43] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.57, #queue-req: 0, 
[2025-09-30 13:55:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:44] Prefill batch. #new-seq: 1, #new-token: 1169, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:44] Prefill batch. #new-seq: 1, #new-token: 476, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:44] Decode batch. #running-req: 1, #token: 664, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.00, #queue-req: 0, 
[2025-09-30 13:55:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:44] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:44] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.73, #queue-req: 0, 
[2025-09-30 13:55:45] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:55:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:45] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:45] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:45] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.16, #queue-req: 0, 
[2025-09-30 13:55:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:45] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:45] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 544, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:46] Prefill batch. #new-seq: 1, #new-token: 980, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:46] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.67, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 13:55:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:46] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:46] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:55:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:47] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:47] Decode batch. #running-req: 1, #token: 116, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.21, #queue-req: 0, 
[2025-09-30 13:55:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:47] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:47] Prefill batch. #new-seq: 1, #new-token: 1088, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:47] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.48, #queue-req: 0, 
[2025-09-30 13:55:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:48] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 13:55:48] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:55:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:48] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:49] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.57, #queue-req: 0, 
[2025-09-30 13:55:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:49] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 13:55:49] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:55:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:50] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 13:55:50] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:50] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:50] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:50] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:50] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.48, #queue-req: 0, 
[2025-09-30 13:55:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:50] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.52, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 13:55:51] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.37, #queue-req: 0, 
[2025-09-30 13:55:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:51] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:51] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.41, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 392, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.33, #queue-req: 0, 
[2025-09-30 13:55:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:52] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:52] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 13:55:53] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 13:55:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:53] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:53] Prefill batch. #new-seq: 1, #new-token: 531, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:53] Decode batch. #running-req: 1, #token: 695, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.89, #queue-req: 0, 
[2025-09-30 13:55:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:53] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.96, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 13:55:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:54] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:54] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:54] Decode batch. #running-req: 1, #token: 601, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.96, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 641, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.60, #queue-req: 0, 
[2025-09-30 13:55:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:55] Prefill batch. #new-seq: 1, #new-token: 1148, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:55] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 804, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.08, #queue-req: 0, 
[2025-09-30 13:55:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:55] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:55] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 13:55:56] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 13:55:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:56] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:56] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.95, #queue-req: 0, 
[2025-09-30 13:55:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:56] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:57] Prefill batch. #new-seq: 1, #new-token: 887, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:57] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.34, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 13:55:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:57] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:57] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 13:55:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:57] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:58] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:58] Decode batch. #running-req: 1, #token: 353, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.13, #queue-req: 0, 
[2025-09-30 13:55:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:58] Prefill batch. #new-seq: 1, #new-token: 629, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:58] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:58] Decode batch. #running-req: 1, #token: 556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.37, #queue-req: 0, 
[2025-09-30 13:55:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:58] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:59] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.70, #queue-req: 0, 
[2025-09-30 13:55:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:59] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:59] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:55:59] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 570, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.41, #queue-req: 0, 
[2025-09-30 13:55:59] Decode batch. #running-req: 1, #token: 610, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:00] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:00] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:00] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:00] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:00] Decode batch. #running-req: 1, #token: 489, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.93, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:00] Prefill batch. #new-seq: 1, #new-token: 743, #cached-token: 88, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:00] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 562, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.29, #queue-req: 0, 
[2025-09-30 13:56:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:01] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.39, #queue-req: 0, 
[2025-09-30 13:56:01] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 13:56:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:01] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:02] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 435, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.27, #queue-req: 0, 
[2025-09-30 13:56:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:02] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:02] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.10, #queue-req: 0, 
[2025-09-30 13:56:02] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.29, #queue-req: 0, 
[2025-09-30 13:56:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:03] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:03] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.92, #queue-req: 0, 
[2025-09-30 13:56:03] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 13:56:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:03] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:03] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 588, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.80, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 13:56:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:04] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:04] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 13:56:05] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:56:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:05] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:05] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.72, #queue-req: 0, 
[2025-09-30 13:56:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:05] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:05] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:05] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.88, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.37, #queue-req: 0, 
[2025-09-30 13:56:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:06] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.83, #queue-req: 0, 
[2025-09-30 13:56:06] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 13:56:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:06] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.02, #queue-req: 0, 
[2025-09-30 13:56:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:07] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:07] Decode batch. #running-req: 1, #token: 212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 13:56:08] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:08] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.51, #queue-req: 0, 
[2025-09-30 13:56:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:08] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.89, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:09] Decode batch. #running-req: 1, #token: 420, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.14, #queue-req: 0, 
[2025-09-30 13:56:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:09] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.82, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.06, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:10] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.63, #queue-req: 0, 
[2025-09-30 13:56:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:11] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 13:56:11] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 13:56:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:11] Prefill batch. #new-seq: 1, #new-token: 532, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:11] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.15, #queue-req: 0, 
[2025-09-30 13:56:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:12] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 13:56:12] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 13:56:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.76, #queue-req: 0, 
[2025-09-30 13:56:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:13] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:13] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.57, #queue-req: 0, 
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 13:56:14] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:14] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:14] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:14] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 541, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.12, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 581, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.20, #queue-req: 0, 
[2025-09-30 13:56:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:15] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.69, #queue-req: 0, 
[2025-09-30 13:56:15] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:56:16] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:16] Decode batch. #running-req: 1, #token: 463, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.63, #queue-req: 0, 
[2025-09-30 13:56:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:16] Prefill batch. #new-seq: 1, #new-token: 987, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] Decode batch. #running-req: 1, #token: 815, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.15, #queue-req: 0, 
[2025-09-30 13:56:17] Decode batch. #running-req: 1, #token: 855, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 13:56:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:17] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:17] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.18, #queue-req: 0, 
[2025-09-30 13:56:18] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:18] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.60, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:18] Prefill batch. #new-seq: 1, #new-token: 611, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 69.47, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 685, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 1467, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:19] Prefill batch. #new-seq: 1, #new-token: 856, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:19] Decode batch. #running-req: 1, #token: 1032, token usage: 0.02, cuda graph: True, gen throughput (token/s): 63.08, #queue-req: 0, 
[2025-09-30 13:56:20] Decode batch. #running-req: 1, #token: 1072, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.34, #queue-req: 0, 
[2025-09-30 13:56:20] Decode batch. #running-req: 1, #token: 1112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 13:56:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:20] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:20] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.50, #queue-req: 0, 
[2025-09-30 13:56:21] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:56:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:21] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:21] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.31, #queue-req: 0, 
[2025-09-30 13:56:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:21] Prefill batch. #new-seq: 1, #new-token: 851, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:21] Prefill batch. #new-seq: 1, #new-token: 1533, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:21] Prefill batch. #new-seq: 1, #new-token: 683, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:22] Decode batch. #running-req: 1, #token: 855, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.30, #queue-req: 0, 
[2025-09-30 13:56:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:22] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 13:56:22] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:22] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 13:56:22] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 13:56:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:23] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:23] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.16, #queue-req: 0, 
[2025-09-30 13:56:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:23] Prefill batch. #new-seq: 1, #new-token: 679, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:23] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.40, #queue-req: 0, 
[2025-09-30 13:56:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:23] Prefill batch. #new-seq: 1, #new-token: 1416, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:23] Prefill batch. #new-seq: 1, #new-token: 738, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:24] Decode batch. #running-req: 1, #token: 938, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.60, #queue-req: 0, 
[2025-09-30 13:56:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:24] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:24] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.11, #queue-req: 0, 
[2025-09-30 13:56:24] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:56:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:25] Prefill batch. #new-seq: 1, #new-token: 1489, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:25] Prefill batch. #new-seq: 1, #new-token: 756, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:25] Decode batch. #running-req: 1, #token: 926, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.72, #queue-req: 0, 
[2025-09-30 13:56:25] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 13:56:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:26] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:26] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.65, #queue-req: 0, 
[2025-09-30 13:56:26] Decode batch. #running-req: 1, #token: 336, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 13:56:26] Decode batch. #running-req: 1, #token: 376, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.08, #queue-req: 0, 
[2025-09-30 13:56:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:26] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:26] Prefill batch. #new-seq: 1, #new-token: 752, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:27] Decode batch. #running-req: 1, #token: 848, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.12, #queue-req: 0, 
[2025-09-30 13:56:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:27] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 825, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:27] Decode batch. #running-req: 1, #token: 839, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.16, #queue-req: 0, 
[2025-09-30 13:56:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:27] Prefill batch. #new-seq: 1, #new-token: 1184, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:27] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:28] Decode batch. #running-req: 1, #token: 620, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.66, #queue-req: 0, 
[2025-09-30 13:56:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:28] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 13:56:28] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:28] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 13:56:29] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 13:56:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 980, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:29] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.41, #queue-req: 0, 
[2025-09-30 13:56:29] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 13:56:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:29] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:30] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:30] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.43, #queue-req: 0, 
[2025-09-30 13:56:30] Prefill batch. #new-seq: 1, #new-token: 1185, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:30] Decode batch. #running-req: 1, #token: 1254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 83.47, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 1294, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 13:56:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:31] Prefill batch. #new-seq: 1, #new-token: 1165, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 1221, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.28, #queue-req: 0, 
[2025-09-30 13:56:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:31] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:31] Decode batch. #running-req: 1, #token: 640, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.37, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.50, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.32, #queue-req: 0, 
[2025-09-30 13:56:32] Decode batch. #running-req: 1, #token: 760, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.19, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 800, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.83, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 840, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 880, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 13:56:33] Decode batch. #running-req: 1, #token: 920, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 960, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.49, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 1000, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 13:56:34] Decode batch. #running-req: 1, #token: 1040, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 1080, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 1120, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.00, #queue-req: 0, 
[2025-09-30 13:56:35] Decode batch. #running-req: 1, #token: 1160, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 1200, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 1240, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 13:56:36] Decode batch. #running-req: 1, #token: 1280, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 1320, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.34, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 1360, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 1400, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 13:56:37] Decode batch. #running-req: 1, #token: 1440, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 13:56:38] Decode batch. #running-req: 1, #token: 1480, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 13:56:38] Decode batch. #running-req: 1, #token: 1520, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 13:56:38] Decode batch. #running-req: 1, #token: 1560, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.84, #queue-req: 0, 
[2025-09-30 13:56:39] Decode batch. #running-req: 1, #token: 1600, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.61, #queue-req: 0, 
[2025-09-30 13:56:39] Decode batch. #running-req: 1, #token: 1640, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 13:56:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:39] Prefill batch. #new-seq: 1, #new-token: 1183, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:39] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 817, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.62, #queue-req: 0, 
[2025-09-30 13:56:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:40] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.13, #queue-req: 0, 
[2025-09-30 13:56:40] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:56:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 88.13, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] Decode batch. #running-req: 1, #token: 726, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.37, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 1084, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:41] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 642, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.31, #queue-req: 0, 
[2025-09-30 13:56:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:42] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.96, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:56:42] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 13:56:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.53, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 517, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:44] Prefill batch. #new-seq: 1, #new-token: 950, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:44] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 744, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.09, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 784, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 13:56:44] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.22, #queue-req: 0, 
[2025-09-30 13:56:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:44] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.80, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:56:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:45] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:45] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.36, #queue-req: 0, 
[2025-09-30 13:56:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:45] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:46] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.91, #queue-req: 0, 
[2025-09-30 13:56:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:46] Prefill batch. #new-seq: 1, #new-token: 649, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:46] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:46] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.47, #queue-req: 0, 
[2025-09-30 13:56:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:46] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:56:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:47] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:47] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:47] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.22, #queue-req: 0, 
[2025-09-30 13:56:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 217, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.87, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:48] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:48] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.14, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 13:56:49] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:49] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.11, #queue-req: 0, 
[2025-09-30 13:56:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:50] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.54, #queue-req: 0, 
[2025-09-30 13:56:50] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:56:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:50] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:50] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.75, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 730, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:51] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:51] Decode batch. #running-req: 1, #token: 621, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.17, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 661, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 13:56:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:52] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:56:52] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.54, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:53] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] Decode batch. #running-req: 1, #token: 353, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.85, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.49, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:54] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:54] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.39, #queue-req: 0, 
[2025-09-30 13:56:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.90, #queue-req: 0, 
[2025-09-30 13:56:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:55] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 13:56:55] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.20, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:56] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:56] Decode batch. #running-req: 1, #token: 443, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.01, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:57] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.33, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:57] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:57] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:57] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.70, #queue-req: 0, 
[2025-09-30 13:56:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] Decode batch. #running-req: 1, #token: 591, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.58, #queue-req: 0, 
[2025-09-30 13:56:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:58] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:58] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.57, #queue-req: 0, 
[2025-09-30 13:56:59] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:56:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:56:59] Prefill batch. #new-seq: 1, #new-token: 1500, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:56:59] Decode batch. #running-req: 1, #token: 1851, token usage: 0.03, cuda graph: True, gen throughput (token/s): 67.69, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 1891, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 1931, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 13:57:00] Decode batch. #running-req: 1, #token: 1971, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 13:57:01] Decode batch. #running-req: 1, #token: 2011, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 13:57:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:01] Prefill batch. #new-seq: 1, #new-token: 1500, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:01] Decode batch. #running-req: 1, #token: 1824, token usage: 0.03, cuda graph: True, gen throughput (token/s): 102.99, #queue-req: 0, 
[2025-09-30 13:57:01] Decode batch. #running-req: 1, #token: 1864, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.97, #queue-req: 0, 
[2025-09-30 13:57:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:02] Prefill batch. #new-seq: 1, #new-token: 1226, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 1352, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.95, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 1392, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 13:57:02] Decode batch. #running-req: 1, #token: 1432, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 1472, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 1512, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 1552, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.91, #queue-req: 0, 
[2025-09-30 13:57:03] Decode batch. #running-req: 1, #token: 1592, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.68, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 1632, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 1672, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 13:57:04] Decode batch. #running-req: 1, #token: 1712, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 13:57:05] Decode batch. #running-req: 1, #token: 1752, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 13:57:05] Decode batch. #running-req: 1, #token: 1792, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 13:57:05] Decode batch. #running-req: 1, #token: 1832, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.97, #queue-req: 0, 
[2025-09-30 13:57:06] Decode batch. #running-req: 1, #token: 1872, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:06] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:06] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:06] Decode batch. #running-req: 1, #token: 458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.19, #queue-req: 0, 
[2025-09-30 13:57:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:06] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.49, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.58, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.20, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:07] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:08] Decode batch. #running-req: 1, #token: 464, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.03, #queue-req: 0, 
[2025-09-30 13:57:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:08] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:08] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.61, #queue-req: 0, 
[2025-09-30 13:57:08] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:57:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.53, #queue-req: 0, 
[2025-09-30 13:57:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:09] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:09] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.33, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 13:57:10] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.24, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:10] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 351, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.07, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:11] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.04, #queue-req: 0, 
[2025-09-30 13:57:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:11] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:12] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:12] Decode batch. #running-req: 1, #token: 450, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.21, #queue-req: 0, 
[2025-09-30 13:57:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.73, #queue-req: 0, 
[2025-09-30 13:57:13] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.45, #queue-req: 0, 
[2025-09-30 13:57:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:13] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:13] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.61, #queue-req: 0, 
[2025-09-30 13:57:14] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:14] Decode batch. #running-req: 1, #token: 195, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.89, #queue-req: 0, 
[2025-09-30 13:57:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:14] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:15] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:15] Decode batch. #running-req: 1, #token: 474, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.49, #queue-req: 0, 
[2025-09-30 13:57:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:15] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:15] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 13:57:15] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 568, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 452, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.68, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 13:57:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:16] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:16] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.34, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.99, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:17] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.04, #queue-req: 0, 
[2025-09-30 13:57:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:17] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 13:57:18] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:57:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:18] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:18] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.30, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 13:57:19] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:19] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.58, #queue-req: 0, 
[2025-09-30 13:57:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:20] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.32, #queue-req: 0, 
[2025-09-30 13:57:20] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:57:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:21] Prefill batch. #new-seq: 1, #new-token: 1681, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:21] Decode batch. #running-req: 1, #token: 2025, token usage: 0.03, cuda graph: True, gen throughput (token/s): 69.06, #queue-req: 0, 
[2025-09-30 13:57:21] Decode batch. #running-req: 1, #token: 2065, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.57, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 2105, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.33, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 2145, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 2185, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 13:57:22] Decode batch. #running-req: 1, #token: 2225, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 13:57:23] Decode batch. #running-req: 1, #token: 2265, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 13:57:23] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.10, #queue-req: 0, 
[2025-09-30 13:57:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:23] Prefill batch. #new-seq: 1, #new-token: 1681, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:23] Decode batch. #running-req: 1, #token: 2040, token usage: 0.03, cuda graph: True, gen throughput (token/s): 99.54, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.36, #queue-req: 0, 
[2025-09-30 13:57:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:24] Prefill batch. #new-seq: 1, #new-token: 841, #cached-token: 130, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 1011, token usage: 0.02, cuda graph: True, gen throughput (token/s): 113.87, #queue-req: 0, 
[2025-09-30 13:57:24] Decode batch. #running-req: 1, #token: 1051, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 1091, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 1131, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 13:57:25] Decode batch. #running-req: 1, #token: 1171, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 1211, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 1251, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 13:57:26] Decode batch. #running-req: 1, #token: 1291, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 13:57:27] Decode batch. #running-req: 1, #token: 1331, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.30, #queue-req: 0, 
[2025-09-30 13:57:27] Decode batch. #running-req: 1, #token: 1371, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 13:57:27] Decode batch. #running-req: 1, #token: 1411, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 13:57:28] Decode batch. #running-req: 1, #token: 1451, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 13:57:28] Decode batch. #running-req: 1, #token: 1491, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.01, #queue-req: 0, 
[2025-09-30 13:57:28] Decode batch. #running-req: 1, #token: 1531, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:28] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:29] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.99, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 489, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 13:57:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:29] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:29] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.45, #queue-req: 0, 
[2025-09-30 13:57:30] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.65, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:30] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.69, #queue-req: 0, 
[2025-09-30 13:57:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:30] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 303, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 743, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:31] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:31] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.76, #queue-req: 0, 
[2025-09-30 13:57:31] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.06, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:57:32] Decode batch. #running-req: 1, #token: 336, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:32] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] Decode batch. #running-req: 1, #token: 601, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.74, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:33] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.61, #queue-req: 0, 
[2025-09-30 13:57:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:33] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:34] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:34] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.32, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 258, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:35] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:35] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:35] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.03, #queue-req: 0, 
[2025-09-30 13:57:35] Decode batch. #running-req: 1, #token: 553, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.06, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.73, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 13:57:36] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:36] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:37] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.75, #queue-req: 0, 
[2025-09-30 13:57:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:37] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.03, #queue-req: 0, 
[2025-09-30 13:57:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:37] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.05, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:38] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] Decode batch. #running-req: 1, #token: 109, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.08, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:38] Prefill batch. #new-seq: 1, #new-token: 298, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:39] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:39] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:39] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.75, #queue-req: 0, 
[2025-09-30 13:57:39] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.88, #queue-req: 0, 
[2025-09-30 13:57:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:39] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:39] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 13:57:40] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:40] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:40] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.39, #queue-req: 0, 
[2025-09-30 13:57:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 683, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] Decode batch. #running-req: 1, #token: 571, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.45, #queue-req: 0, 
[2025-09-30 13:57:41] Decode batch. #running-req: 1, #token: 611, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.99, #queue-req: 0, 
[2025-09-30 13:57:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:41] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:41] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 13:57:42] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.89, #queue-req: 0, 
[2025-09-30 13:57:42] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.70, #queue-req: 0, 
[2025-09-30 13:57:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:42] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:42] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 1075, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 858, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.51, #queue-req: 0, 
[2025-09-30 13:57:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:43] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.36, #queue-req: 0, 
[2025-09-30 13:57:43] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:57:44] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.78, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:44] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 761, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] Decode batch. #running-req: 1, #token: 781, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.13, #queue-req: 0, 
[2025-09-30 13:57:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:45] Prefill batch. #new-seq: 1, #new-token: 1271, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:45] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] Decode batch. #running-req: 1, #token: 781, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.05, #queue-req: 0, 
[2025-09-30 13:57:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:45] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:45] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 13:57:46] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 13:57:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:46] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:46] Prefill batch. #new-seq: 1, #new-token: 583, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:46] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.46, #queue-req: 0, 
[2025-09-30 13:57:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 655, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.89, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 1096, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:47] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:47] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.97, #queue-req: 0, 
[2025-09-30 13:57:48] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.76, #queue-req: 0, 
[2025-09-30 13:57:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:48] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:48] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 13:57:48] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 13:57:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:49] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.09, #queue-req: 0, 
[2025-09-30 13:57:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 1034, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:49] Prefill batch. #new-seq: 1, #new-token: 521, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:49] Decode batch. #running-req: 1, #token: 703, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.23, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:50] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.34, #queue-req: 0, 
[2025-09-30 13:57:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:50] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 594, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.88, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 1144, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:51] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 811, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.01, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 851, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 891, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 13:57:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:52] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:52] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 13:57:53] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:53] Decode batch. #running-req: 1, #token: 712, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.00, #queue-req: 0, 
[2025-09-30 13:57:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:53] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 697, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] Decode batch. #running-req: 1, #token: 719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.13, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 1178, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:54] Decode batch. #running-req: 1, #token: 750, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.98, #queue-req: 0, 
[2025-09-30 13:57:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:54] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:55] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:55] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:55] Decode batch. #running-req: 1, #token: 631, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.40, #queue-req: 0, 
[2025-09-30 13:57:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.08, #queue-req: 0, 
[2025-09-30 13:57:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:56] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:56] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 13:57:57] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:57] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:57] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:57] Decode batch. #running-req: 1, #token: 166, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.81, #queue-req: 0, 
[2025-09-30 13:57:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:58] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:58] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:58] Decode batch. #running-req: 1, #token: 168, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.39, #queue-req: 0, 
[2025-09-30 13:57:58] Decode batch. #running-req: 1, #token: 208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0, 
[2025-09-30 13:57:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:58] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:59] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.98, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.42, #queue-req: 0, 
[2025-09-30 13:57:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:57:59] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:57:59] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.94, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 379, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 13:58:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:00] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:00] Decode batch. #running-req: 1, #token: 636, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.44, #queue-req: 0, 
[2025-09-30 13:58:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:01] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:01] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:01] Decode batch. #running-req: 1, #token: 658, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.47, #queue-req: 0, 
[2025-09-30 13:58:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:01] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:01] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.52, #queue-req: 0, 
[2025-09-30 13:58:02] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:58:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:02] Prefill batch. #new-seq: 1, #new-token: 2477, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:02] Decode batch. #running-req: 1, #token: 2857, token usage: 0.04, cuda graph: True, gen throughput (token/s): 65.89, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 2897, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 2937, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 13:58:03] Decode batch. #running-req: 1, #token: 2977, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 3017, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.29, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 3057, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 13:58:04] Decode batch. #running-req: 1, #token: 3097, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 3137, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 3177, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.91, #queue-req: 0, 
[2025-09-30 13:58:05] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.69, #queue-req: 0, 
[2025-09-30 13:58:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:05] Prefill batch. #new-seq: 1, #new-token: 2477, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 2837, token usage: 0.04, cuda graph: True, gen throughput (token/s): 89.43, #queue-req: 0, 
[2025-09-30 13:58:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:06] Prefill batch. #new-seq: 1, #new-token: 928, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 1087, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.81, #queue-req: 0, 
[2025-09-30 13:58:06] Decode batch. #running-req: 1, #token: 1127, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 1167, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 1207, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 13:58:07] Decode batch. #running-req: 1, #token: 1247, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 13:58:08] Decode batch. #running-req: 1, #token: 1287, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 13:58:08] Decode batch. #running-req: 1, #token: 1327, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.28, #queue-req: 0, 
[2025-09-30 13:58:08] Decode batch. #running-req: 1, #token: 1367, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 1407, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.22, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 1447, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 1487, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 13:58:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:09] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 128.99, #queue-req: 0, 
[2025-09-30 13:58:10] Prefill batch. #new-seq: 1, #new-token: 1153, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:10] Prefill batch. #new-seq: 1, #new-token: 683, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:10] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.11, #queue-req: 0, 
[2025-09-30 13:58:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:10] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.75, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:58:11] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 13:58:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:11] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:11] Prefill batch. #new-seq: 1, #new-token: 679, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 773, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.96, #queue-req: 0, 
[2025-09-30 13:58:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:12] Prefill batch. #new-seq: 1, #new-token: 1068, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:12] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:12] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.51, #queue-req: 0, 
[2025-09-30 13:58:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:13] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 13:58:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:13] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:13] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.47, #queue-req: 0, 
[2025-09-30 13:58:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:14] Prefill batch. #new-seq: 1, #new-token: 386, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:14] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.54, #queue-req: 0, 
[2025-09-30 13:58:14] Prefill batch. #new-seq: 1, #new-token: 760, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:14] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.17, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.91, #queue-req: 0, 
[2025-09-30 13:58:15] Decode batch. #running-req: 1, #token: 431, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.83, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 745, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:15] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.86, #queue-req: 0, 
[2025-09-30 13:58:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:16] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 13:58:16] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 13:58:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:17] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:17] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.45, #queue-req: 0, 
[2025-09-30 13:58:17] Decode batch. #running-req: 1, #token: 440, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.14, #queue-req: 0, 
[2025-09-30 13:58:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:18] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:18] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.65, #queue-req: 0, 
[2025-09-30 13:58:18] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:58:18] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:58:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.15, #queue-req: 0, 
[2025-09-30 13:58:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:19] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] Decode batch. #running-req: 1, #token: 522, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.81, #queue-req: 0, 
[2025-09-30 13:58:20] Decode batch. #running-req: 1, #token: 562, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.33, #queue-req: 0, 
[2025-09-30 13:58:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:20] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:20] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:21] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:21] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:21] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.02, #queue-req: 0, 
[2025-09-30 13:58:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:22] Prefill batch. #new-seq: 1, #new-token: 1123, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:22] Decode batch. #running-req: 1, #token: 1492, token usage: 0.02, cuda graph: True, gen throughput (token/s): 60.40, #queue-req: 0, 
[2025-09-30 13:58:22] Decode batch. #running-req: 1, #token: 1532, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.66, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 13:58:23] Decode batch. #running-req: 1, #token: 1652, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 13:58:24] Decode batch. #running-req: 1, #token: 1692, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 13:58:24] Decode batch. #running-req: 1, #token: 1732, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 13:58:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:24] Prefill batch. #new-seq: 1, #new-token: 1123, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:24] Decode batch. #running-req: 1, #token: 1445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.26, #queue-req: 0, 
[2025-09-30 13:58:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:24] Prefill batch. #new-seq: 1, #new-token: 722, #cached-token: 206, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 963, token usage: 0.02, cuda graph: True, gen throughput (token/s): 114.52, #queue-req: 0, 
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 1003, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 13:58:25] Decode batch. #running-req: 1, #token: 1043, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.26, #queue-req: 0, 
[2025-09-30 13:58:26] Decode batch. #running-req: 1, #token: 1083, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 13:58:26] Decode batch. #running-req: 1, #token: 1123, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 13:58:26] Decode batch. #running-req: 1, #token: 1163, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 1203, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 1243, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 1283, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 13:58:27] Decode batch. #running-req: 1, #token: 1323, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 13:58:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 697, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:28] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:28] Decode batch. #running-req: 1, #token: 568, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.61, #queue-req: 0, 
[2025-09-30 13:58:28] Decode batch. #running-req: 1, #token: 608, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.10, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.63, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:29] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.55, #queue-req: 0, 
[2025-09-30 13:58:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:29] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:30] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.61, #queue-req: 0, 
[2025-09-30 13:58:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:30] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:30] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 445, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.03, #queue-req: 0, 
[2025-09-30 13:58:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:31] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 13:58:31] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 13:58:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.65, #queue-req: 0, 
[2025-09-30 13:58:32] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.00, #queue-req: 0, 
[2025-09-30 13:58:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:32] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:32] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.11, #queue-req: 0, 
[2025-09-30 13:58:33] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:33] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 133, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:33] Decode batch. #running-req: 1, #token: 148, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.29, #queue-req: 0, 
[2025-09-30 13:58:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:34] Prefill batch. #new-seq: 1, #new-token: 1340, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:34] Decode batch. #running-req: 1, #token: 1717, token usage: 0.03, cuda graph: True, gen throughput (token/s): 58.71, #queue-req: 0, 
[2025-09-30 13:58:34] Decode batch. #running-req: 1, #token: 1757, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 13:58:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 1340, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:35] Decode batch. #running-req: 1, #token: 1666, token usage: 0.03, cuda graph: True, gen throughput (token/s): 104.87, #queue-req: 0, 
[2025-09-30 13:58:35] Decode batch. #running-req: 1, #token: 1706, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 13:58:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:35] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 239, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.33, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 754, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.26, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 794, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 13:58:36] Decode batch. #running-req: 1, #token: 834, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.67, #queue-req: 0, 
[2025-09-30 13:58:37] Decode batch. #running-req: 1, #token: 874, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 13:58:37] Decode batch. #running-req: 1, #token: 914, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 13:58:37] Decode batch. #running-req: 1, #token: 954, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 994, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 1034, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.34, #queue-req: 0, 
[2025-09-30 13:58:38] Decode batch. #running-req: 1, #token: 1074, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 13:58:39] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 69.88, #queue-req: 0, 
[2025-09-30 13:58:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:39] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:39] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 13:58:40] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 13:58:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:40] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:40] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:40] Decode batch. #running-req: 1, #token: 125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.04, #queue-req: 0, 
[2025-09-30 13:58:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:41] Decode batch. #running-req: 1, #token: 133, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.81, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:41] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 566, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.42, #queue-req: 0, 
[2025-09-30 13:58:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:42] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 205, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.66, #queue-req: 0, 
[2025-09-30 13:58:42] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 13:58:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 937, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] Decode batch. #running-req: 1, #token: 755, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.31, #queue-req: 0, 
[2025-09-30 13:58:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:43] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:43] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.91, #queue-req: 0, 
[2025-09-30 13:58:44] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:44] Prefill batch. #new-seq: 1, #new-token: 1075, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:44] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:44] Decode batch. #running-req: 1, #token: 672, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.64, #queue-req: 0, 
[2025-09-30 13:58:44] Decode batch. #running-req: 1, #token: 712, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.75, #queue-req: 0, 
[2025-09-30 13:58:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:44] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.62, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:58:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:45] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:45] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:45] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.06, #queue-req: 0, 
[2025-09-30 13:58:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 572, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.25, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 861, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:46] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 604, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.83, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 644, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.87, #queue-req: 0, 
[2025-09-30 13:58:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:47] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:47] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.70, #queue-req: 0, 
[2025-09-30 13:58:48] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 13:58:48] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.11, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:48] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:48] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 922, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.36, #queue-req: 0, 
[2025-09-30 13:58:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:49] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 13:58:49] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 13:58:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:50] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:50] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:50] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.79, #queue-req: 0, 
[2025-09-30 13:58:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:50] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] Decode batch. #running-req: 1, #token: 469, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.63, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:51] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:51] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 13:58:51] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 13:58:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:52] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:52] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:52] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.21, #queue-req: 0, 
[2025-09-30 13:58:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:52] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:52] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.22, #queue-req: 0, 
[2025-09-30 13:58:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:53] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:53] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 13:58:53] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 13:58:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:54] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.16, #queue-req: 0, 
[2025-09-30 13:58:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:54] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:55] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.66, #queue-req: 0, 
[2025-09-30 13:58:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:55] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:55] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.62, #queue-req: 0, 
[2025-09-30 13:58:55] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:58:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:56] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 75.07, #queue-req: 0, 
[2025-09-30 13:58:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:56] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:56] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.00, #queue-req: 0, 
[2025-09-30 13:58:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:57] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:57] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.23, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.97, #queue-req: 0, 
[2025-09-30 13:58:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:57] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:57] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 13:58:58] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 1077, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:58] Prefill batch. #new-seq: 1, #new-token: 738, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:58] Decode batch. #running-req: 1, #token: 917, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.45, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 957, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 13:58:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:58:59] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.71, #queue-req: 0, 
[2025-09-30 13:58:59] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 13:59:00] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 13:59:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:00] Prefill batch. #new-seq: 1, #new-token: 1059, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:00] Prefill batch. #new-seq: 1, #new-token: 404, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:00] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.03, #queue-req: 0, 
[2025-09-30 13:59:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:01] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:01] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.60, #queue-req: 0, 
[2025-09-30 13:59:01] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:59:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.90, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] Decode batch. #running-req: 1, #token: 563, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.48, #queue-req: 0, 
[2025-09-30 13:59:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:02] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:02] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.34, #queue-req: 0, 
[2025-09-30 13:59:03] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 13:59:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:03] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:03] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:03] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.35, #queue-req: 0, 
[2025-09-30 13:59:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 391, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] Decode batch. #running-req: 1, #token: 402, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.11, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:04] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:05] Decode batch. #running-req: 1, #token: 397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.88, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 205, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:05] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.97, #queue-req: 0, 
[2025-09-30 13:59:05] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:05] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.31, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:06] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:06] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 280, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:06] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.91, #queue-req: 0, 
[2025-09-30 13:59:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.43, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:07] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.94, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 476, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:08] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:08] Decode batch. #running-req: 1, #token: 561, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.58, #queue-req: 0, 
[2025-09-30 13:59:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:09] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.10, #queue-req: 0, 
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 13:59:09] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:59:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:09] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:10] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:10] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.30, #queue-req: 0, 
[2025-09-30 13:59:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:10] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:10] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.46, #queue-req: 0, 
[2025-09-30 13:59:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:11] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 13:59:11] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:11] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 299, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] Decode batch. #running-req: 1, #token: 397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.28, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:12] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.93, #queue-req: 0, 
[2025-09-30 13:59:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:13] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 13:59:13] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 13:59:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:14] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:14] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:14] Decode batch. #running-req: 1, #token: 491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.77, #queue-req: 0, 
[2025-09-30 13:59:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:14] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:14] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.35, #queue-req: 0, 
[2025-09-30 13:59:15] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 13:59:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:15] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:15] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:15] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 102.65, #queue-req: 0, 
[2025-09-30 13:59:15] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:15] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:16] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.22, #queue-req: 0, 
[2025-09-30 13:59:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:16] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:16] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.45, #queue-req: 0, 
[2025-09-30 13:59:16] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 13:59:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:17] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:17] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.51, #queue-req: 0, 
[2025-09-30 13:59:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:17] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:17] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:17] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:18] Decode batch. #running-req: 1, #token: 418, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.18, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:18] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:18] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.06, #queue-req: 0, 
[2025-09-30 13:59:18] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:59:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:19] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.58, #queue-req: 0, 
[2025-09-30 13:59:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:19] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:19] Decode batch. #running-req: 1, #token: 552, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.54, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 592, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.22, #queue-req: 0, 
[2025-09-30 13:59:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:20] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 13:59:20] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:20] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] Decode batch. #running-req: 1, #token: 385, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.26, #queue-req: 0, 
[2025-09-30 13:59:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:21] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.19, #queue-req: 0, 
[2025-09-30 13:59:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:22] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.39, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 13:59:22] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 13:59:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:23] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:23] Prefill batch. #new-seq: 1, #new-token: 419, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:23] Decode batch. #running-req: 1, #token: 505, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.41, #queue-req: 0, 
[2025-09-30 13:59:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:24] Prefill batch. #new-seq: 1, #new-token: 719, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:24] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.29, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 534, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.69, #queue-req: 0, 
[2025-09-30 13:59:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:24] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:24] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.28, #queue-req: 0, 
[2025-09-30 13:59:25] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 13:59:25] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:25] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:25] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:26] Prefill batch. #new-seq: 1, #new-token: 584, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:26] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:26] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.14, #queue-req: 0, 
[2025-09-30 13:59:26] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.85, #queue-req: 0, 
[2025-09-30 13:59:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:26] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:27] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:27] Decode batch. #running-req: 1, #token: 537, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.65, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 577, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.38, #queue-req: 0, 
[2025-09-30 13:59:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:28] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 13:59:28] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.68, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:29] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.46, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.54, #queue-req: 0, 
[2025-09-30 13:59:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:30] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:30] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.66, #queue-req: 0, 
[2025-09-30 13:59:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:31] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 13:59:31] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:31] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:31] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.89, #queue-req: 0, 
[2025-09-30 13:59:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:32] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:32] Decode batch. #running-req: 1, #token: 863, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.41, #queue-req: 0, 
[2025-09-30 13:59:32] Decode batch. #running-req: 1, #token: 903, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 943, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 983, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.52, #queue-req: 0, 
[2025-09-30 13:59:33] Decode batch. #running-req: 1, #token: 1023, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.37, #queue-req: 0, 
[2025-09-30 13:59:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:34] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 231, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:34] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.51, #queue-req: 0, 
[2025-09-30 13:59:34] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.90, #queue-req: 0, 
[2025-09-30 13:59:35] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.75, #queue-req: 0, 
[2025-09-30 13:59:35] Decode batch. #running-req: 1, #token: 881, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 13:59:35] Decode batch. #running-req: 1, #token: 921, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 961, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.49, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 1001, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.41, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 1041, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 13:59:36] Decode batch. #running-req: 1, #token: 1081, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 1121, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 1161, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 13:59:37] Decode batch. #running-req: 1, #token: 1201, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 13:59:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 999, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:38] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:38] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.51, #queue-req: 0, 
[2025-09-30 13:59:38] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:59:39] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:39] Prefill batch. #new-seq: 1, #new-token: 1095, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:39] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:39] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.38, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.09, #queue-req: 0, 
[2025-09-30 13:59:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:40] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.84, #queue-req: 0, 
[2025-09-30 13:59:40] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.29, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 1220, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:41] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 818, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.59, #queue-req: 0, 
[2025-09-30 13:59:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:42] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 13:59:42] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 13:59:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:43] Prefill batch. #new-seq: 1, #new-token: 3954, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:43] Decode batch. #running-req: 1, #token: 4300, token usage: 0.07, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-09-30 13:59:43] Decode batch. #running-req: 1, #token: 4340, token usage: 0.07, cuda graph: True, gen throughput (token/s): 122.48, #queue-req: 0, 
[2025-09-30 13:59:44] Decode batch. #running-req: 1, #token: 4380, token usage: 0.07, cuda graph: True, gen throughput (token/s): 122.12, #queue-req: 0, 
[2025-09-30 13:59:44] Decode batch. #running-req: 1, #token: 4420, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.93, #queue-req: 0, 
[2025-09-30 13:59:44] Decode batch. #running-req: 1, #token: 4460, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.91, #queue-req: 0, 
[2025-09-30 13:59:45] Decode batch. #running-req: 1, #token: 4500, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.90, #queue-req: 0, 
[2025-09-30 13:59:45] Decode batch. #running-req: 1, #token: 4540, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.83, #queue-req: 0, 
[2025-09-30 13:59:45] Decode batch. #running-req: 1, #token: 4580, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.84, #queue-req: 0, 
[2025-09-30 13:59:46] Decode batch. #running-req: 1, #token: 4620, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.70, #queue-req: 0, 
[2025-09-30 13:59:46] Decode batch. #running-req: 1, #token: 4660, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.39, #queue-req: 0, 
[2025-09-30 13:59:46] Decode batch. #running-req: 1, #token: 4700, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.34, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 4740, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.32, #queue-req: 0, 
[2025-09-30 13:59:47] Decode batch. #running-req: 1, #token: 4780, token usage: 0.07, cuda graph: True, gen throughput (token/s): 121.31, #queue-req: 0, 
[2025-09-30 13:59:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:47] Prefill batch. #new-seq: 1, #new-token: 3954, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:48] Decode batch. #running-req: 1, #token: 4301, token usage: 0.07, cuda graph: True, gen throughput (token/s): 74.18, #queue-req: 0, 
[2025-09-30 13:59:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:48] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 372, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:48] Decode batch. #running-req: 1, #token: 1114, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.49, #queue-req: 0, 
[2025-09-30 13:59:48] Decode batch. #running-req: 1, #token: 1154, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 13:59:48] Decode batch. #running-req: 1, #token: 1194, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 1234, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 1274, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 13:59:49] Decode batch. #running-req: 1, #token: 1314, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.33, #queue-req: 0, 
[2025-09-30 13:59:50] Decode batch. #running-req: 1, #token: 1354, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 13:59:50] Decode batch. #running-req: 1, #token: 1394, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 13:59:50] Decode batch. #running-req: 1, #token: 1434, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 1474, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 1514, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 13:59:51] Decode batch. #running-req: 1, #token: 1554, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.85, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 1594, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.56, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 1634, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 13:59:52] Decode batch. #running-req: 1, #token: 1674, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 13:59:53] Decode batch. #running-req: 1, #token: 1714, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 13:59:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:53] Prefill batch. #new-seq: 1, #new-token: 1186, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:53] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:53] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.42, #queue-req: 0, 
[2025-09-30 13:59:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:53] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:54] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.72, #queue-req: 0, 
[2025-09-30 13:59:54] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 13:59:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:54] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:54] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.65, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.34, #queue-req: 0, 
[2025-09-30 13:59:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:55] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.20, #queue-req: 0, 
[2025-09-30 13:59:55] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 13:59:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:56] Prefill batch. #new-seq: 1, #new-token: 623, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:56] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:56] Decode batch. #running-req: 1, #token: 615, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.39, #queue-req: 0, 
[2025-09-30 13:59:56] Decode batch. #running-req: 1, #token: 655, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.77, #queue-req: 0, 
[2025-09-30 13:59:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:57] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:57] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.22, #queue-req: 0, 
[2025-09-30 13:59:57] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 13:59:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:57] Prefill batch. #new-seq: 1, #new-token: 1122, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:57] Prefill batch. #new-seq: 1, #new-token: 682, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.60, #queue-req: 0, 
[2025-09-30 13:59:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:58] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.39, #queue-req: 0, 
[2025-09-30 13:59:58] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 13:59:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:58] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:59] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 13:59:59] Decode batch. #running-req: 1, #token: 772, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.51, #queue-req: 0, 
[2025-09-30 13:59:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 13:59:59] Prefill batch. #new-seq: 1, #new-token: 1212, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 1587, token usage: 0.02, cuda graph: True, gen throughput (token/s): 51.07, #queue-req: 0, 
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 1627, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:00:00] Decode batch. #running-req: 1, #token: 1667, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:00:01] Decode batch. #running-req: 1, #token: 1707, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:00:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:01] Prefill batch. #new-seq: 1, #new-token: 1212, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:01] Decode batch. #running-req: 1, #token: 1561, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.55, #queue-req: 0, 
[2025-09-30 14:00:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:01] Prefill batch. #new-seq: 1, #new-token: 677, #cached-token: 262, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:01] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 114.75, #queue-req: 0, 
[2025-09-30 14:00:02] Decode batch. #running-req: 1, #token: 1006, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:00:02] Decode batch. #running-req: 1, #token: 1046, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.19, #queue-req: 0, 
[2025-09-30 14:00:02] Decode batch. #running-req: 1, #token: 1086, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:00:02] Decode batch. #running-req: 1, #token: 1126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 1166, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 1206, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:00:03] Decode batch. #running-req: 1, #token: 1246, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 1286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.62, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 1326, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:00:04] Decode batch. #running-req: 1, #token: 1366, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 1406, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 1446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 14:00:05] Decode batch. #running-req: 1, #token: 1486, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:00:06] Decode batch. #running-req: 1, #token: 1526, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:00:06] Decode batch. #running-req: 1, #token: 1566, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.71, #queue-req: 0, 
[2025-09-30 14:00:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:06] Prefill batch. #new-seq: 1, #new-token: 1275, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:06] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 766, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.94, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:00:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:07] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 14:00:07] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:00:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:08] Prefill batch. #new-seq: 1, #new-token: 1360, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1722, token usage: 0.03, cuda graph: True, gen throughput (token/s): 58.21, #queue-req: 0, 
[2025-09-30 14:00:08] Decode batch. #running-req: 1, #token: 1762, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1802, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.30, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1842, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:00:09] Decode batch. #running-req: 1, #token: 1882, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 1922, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 1962, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:00:10] Decode batch. #running-req: 1, #token: 2002, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:00:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:11] Prefill batch. #new-seq: 1, #new-token: 1360, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:11] Decode batch. #running-req: 1, #token: 1687, token usage: 0.03, cuda graph: True, gen throughput (token/s): 102.88, #queue-req: 0, 
[2025-09-30 14:00:11] Decode batch. #running-req: 1, #token: 1727, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:00:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:11] Prefill batch. #new-seq: 1, #new-token: 977, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:11] Decode batch. #running-req: 1, #token: 1121, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.77, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 1161, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 1201, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:00:12] Decode batch. #running-req: 1, #token: 1241, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:00:13] Decode batch. #running-req: 1, #token: 1281, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:00:13] Decode batch. #running-req: 1, #token: 1321, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.29, #queue-req: 0, 
[2025-09-30 14:00:13] Decode batch. #running-req: 1, #token: 1361, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.21, #queue-req: 0, 
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 1401, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 1441, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 1481, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:00:14] Decode batch. #running-req: 1, #token: 1521, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:00:15] Decode batch. #running-req: 1, #token: 1561, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.79, #queue-req: 0, 
[2025-09-30 14:00:15] Decode batch. #running-req: 1, #token: 1601, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:00:15] Decode batch. #running-req: 1, #token: 1641, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 1681, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 1721, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:00:16] Decode batch. #running-req: 1, #token: 1761, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 1170, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:17] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:17] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.20, #queue-req: 0, 
[2025-09-30 14:00:18] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.11, #queue-req: 0, 
[2025-09-30 14:00:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:18] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:18] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 14:00:18] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:00:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:19] Prefill batch. #new-seq: 1, #new-token: 1219, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:19] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:19] Decode batch. #running-req: 1, #token: 891, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.48, #queue-req: 0, 
[2025-09-30 14:00:19] Decode batch. #running-req: 1, #token: 931, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:00:19] Decode batch. #running-req: 1, #token: 971, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:00:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:20] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:20] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.38, #queue-req: 0, 
[2025-09-30 14:00:20] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:00:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:20] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.77, #queue-req: 0, 
[2025-09-30 14:00:20] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:21] Prefill batch. #new-seq: 1, #new-token: 1059, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:21] Prefill batch. #new-seq: 1, #new-token: 419, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:21] Decode batch. #running-req: 1, #token: 598, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.45, #queue-req: 0, 
[2025-09-30 14:00:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:21] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.37, #queue-req: 0, 
[2025-09-30 14:00:22] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:00:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:22] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:23] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 459, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.94, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 499, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.98, #queue-req: 0, 
[2025-09-30 14:00:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:23] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:23] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:00:24] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:00:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:24] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:24] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:24] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.47, #queue-req: 0, 
[2025-09-30 14:00:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:24] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1600, token usage: 0.03, cuda graph: True, gen throughput (token/s): 49.91, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1640, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:00:25] Decode batch. #running-req: 1, #token: 1680, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1720, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1760, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:00:26] Decode batch. #running-req: 1, #token: 1800, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.35, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1840, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.00, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1880, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.00, #queue-req: 0, 
[2025-09-30 14:00:27] Decode batch. #running-req: 1, #token: 1920, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.97, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:00:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:28] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:28] Prefill batch. #new-seq: 1, #new-token: 982, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 93.10, #queue-req: 0, 
[2025-09-30 14:00:28] Decode batch. #running-req: 1, #token: 1152, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 1192, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 1232, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.63, #queue-req: 0, 
[2025-09-30 14:00:29] Decode batch. #running-req: 1, #token: 1272, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.65, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 1312, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.28, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 1352, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 1392, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:00:30] Decode batch. #running-req: 1, #token: 1432, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 1472, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.01, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 1512, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 14:00:31] Decode batch. #running-req: 1, #token: 1552, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.84, #queue-req: 0, 
[2025-09-30 14:00:32] Decode batch. #running-req: 1, #token: 1592, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:00:32] Decode batch. #running-req: 1, #token: 1632, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:00:32] Decode batch. #running-req: 1, #token: 1672, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 1712, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 1752, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.33, #queue-req: 0, 
[2025-09-30 14:00:33] Decode batch. #running-req: 1, #token: 1792, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.31, #queue-req: 0, 
[2025-09-30 14:00:34] Decode batch. #running-req: 1, #token: 1832, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:00:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:34] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:34] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:34] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.92, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 379, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.24, #queue-req: 0, 
[2025-09-30 14:00:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:35] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:00:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:35] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:35] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:35] Decode batch. #running-req: 1, #token: 417, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.77, #queue-req: 0, 
[2025-09-30 14:00:36] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.20, #queue-req: 0, 
[2025-09-30 14:00:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:36] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:36] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:00:36] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:00:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:37] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:37] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:37] Decode batch. #running-req: 1, #token: 537, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.91, #queue-req: 0, 
[2025-09-30 14:00:37] Decode batch. #running-req: 1, #token: 577, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:00:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:37] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.78, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:00:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:38] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:38] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:38] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.70, #queue-req: 0, 
[2025-09-30 14:00:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.31, #queue-req: 0, 
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 331, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:39] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 60.89, #queue-req: 0, 
[2025-09-30 14:00:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:40] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:00:40] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:00:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:40] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:40] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:41] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.26, #queue-req: 0, 
[2025-09-30 14:00:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:41] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:41] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.40, #queue-req: 0, 
[2025-09-30 14:00:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:42] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.70, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:00:42] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:00:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:43] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:43] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:43] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.42, #queue-req: 0, 
[2025-09-30 14:00:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:44] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 343, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 1229, token usage: 0.02, cuda graph: True, gen throughput (token/s): 51.24, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 1269, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:00:44] Decode batch. #running-req: 1, #token: 1309, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.35, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 1349, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 1389, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.32, #queue-req: 0, 
[2025-09-30 14:00:45] Decode batch. #running-req: 1, #token: 1429, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:00:46] Decode batch. #running-req: 1, #token: 1469, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:00:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:46] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 323, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:46] Decode batch. #running-req: 1, #token: 1200, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.26, #queue-req: 0, 
[2025-09-30 14:00:46] Decode batch. #running-req: 1, #token: 1240, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:00:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:46] Prefill batch. #new-seq: 1, #new-token: 1041, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 1180, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.57, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 1220, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:00:47] Decode batch. #running-req: 1, #token: 1260, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:00:48] Decode batch. #running-req: 1, #token: 1300, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.50, #queue-req: 0, 
[2025-09-30 14:00:48] Decode batch. #running-req: 1, #token: 1340, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.32, #queue-req: 0, 
[2025-09-30 14:00:48] Decode batch. #running-req: 1, #token: 1380, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:00:48] Decode batch. #running-req: 1, #token: 1420, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 1460, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 1500, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 14:00:49] Decode batch. #running-req: 1, #token: 1540, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:00:50] Decode batch. #running-req: 1, #token: 1580, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.61, #queue-req: 0, 
[2025-09-30 14:00:50] Decode batch. #running-req: 1, #token: 1620, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:00:50] Decode batch. #running-req: 1, #token: 1660, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 1700, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 1740, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:00:51] Decode batch. #running-req: 1, #token: 1780, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:00:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:52] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 52.59, #queue-req: 0, 
[2025-09-30 14:00:52] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:00:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:52] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:53] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:53] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:53] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 37.07, #queue-req: 0, 
[2025-09-30 14:00:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:53] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:54] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.44, #queue-req: 0, 
[2025-09-30 14:00:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:54] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:54] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.53, #queue-req: 0, 
[2025-09-30 14:00:54] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:00:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:55] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:55] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:55] Decode batch. #running-req: 1, #token: 353, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.92, #queue-req: 0, 
[2025-09-30 14:00:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:55] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.64, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 348, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.30, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:56] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:56] Decode batch. #running-req: 1, #token: 467, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.91, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:57] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.15, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:57] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.16, #queue-req: 0, 
[2025-09-30 14:00:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:57] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:58] Prefill batch. #new-seq: 1, #new-token: 672, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:58] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:58] Decode batch. #running-req: 1, #token: 574, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.53, #queue-req: 0, 
[2025-09-30 14:00:58] Decode batch. #running-req: 1, #token: 614, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:00:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:58] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:59] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 14:00:59] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:00:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:59] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:00:59] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.28, #queue-req: 0, 
[2025-09-30 14:00:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:00:59] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:00] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.62, #queue-req: 0, 
[2025-09-30 14:01:00] Decode batch. #running-req: 1, #token: 479, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.12, #queue-req: 0, 
[2025-09-30 14:01:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:00] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 14:01:01] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:01] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:01] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.79, #queue-req: 0, 
[2025-09-30 14:01:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:02] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:02] Prefill batch. #new-seq: 1, #new-token: 443, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:02] Decode batch. #running-req: 1, #token: 638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.38, #queue-req: 0, 
[2025-09-30 14:01:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:02] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.13, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:03] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:03] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.76, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:03] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:04] Decode batch. #running-req: 1, #token: 511, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.06, #queue-req: 0, 
[2025-09-30 14:01:04] Decode batch. #running-req: 1, #token: 551, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.41, #queue-req: 0, 
[2025-09-30 14:01:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:04] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:05] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:01:05] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:01:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:05] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.21, #queue-req: 0, 
[2025-09-30 14:01:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:06] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:06] Prefill batch. #new-seq: 1, #new-token: 881, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:06] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:06] Decode batch. #running-req: 1, #token: 726, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.34, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 766, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:01:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:07] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 14:01:07] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:01:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:07] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:07] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] Decode batch. #running-req: 1, #token: 636, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.16, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 618, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:08] Decode batch. #running-req: 1, #token: 634, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.65, #queue-req: 0, 
[2025-09-30 14:01:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:09] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:09] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:09] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.12, #queue-req: 0, 
[2025-09-30 14:01:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:09] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:09] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.09, #queue-req: 0, 
[2025-09-30 14:01:10] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:01:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:10] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:10] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:10] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.57, #queue-req: 0, 
[2025-09-30 14:01:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:11] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:11] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:11] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.35, #queue-req: 0, 
[2025-09-30 14:01:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:11] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:11] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:01:11] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:01:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:12] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:12] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:12] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.26, #queue-req: 0, 
[2025-09-30 14:01:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:12] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:12] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.29, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.10, #queue-req: 0, 
[2025-09-30 14:01:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:13] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:13] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.67, #queue-req: 0, 
[2025-09-30 14:01:14] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:01:14] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:01:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:14] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:14] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:15] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:15] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:15] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.81, #queue-req: 0, 
[2025-09-30 14:01:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:15] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:15] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:01:15] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:01:16] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:01:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:16] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:16] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:16] Decode batch. #running-req: 1, #token: 413, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.15, #queue-req: 0, 
[2025-09-30 14:01:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:17] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:17] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.50, #queue-req: 0, 
[2025-09-30 14:01:17] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:18] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:18] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.12, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:18] Prefill batch. #new-seq: 1, #new-token: 443, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 796, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:19] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.05, #queue-req: 0, 
[2025-09-30 14:01:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:19] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:19] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.00, #queue-req: 0, 
[2025-09-30 14:01:19] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:01:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:20] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:20] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:20] Decode batch. #running-req: 1, #token: 429, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.44, #queue-req: 0, 
[2025-09-30 14:01:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:20] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:20] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 603, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.89, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.91, #queue-req: 0, 
[2025-09-30 14:01:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:21] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:01:21] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 416, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 1066, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:22] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:22] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.08, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 860, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.06, #queue-req: 0, 
[2025-09-30 14:01:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:23] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.23, #queue-req: 0, 
[2025-09-30 14:01:23] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:01:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:23] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:24] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:24] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.16, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 720, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:25] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:25] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.66, #queue-req: 0, 
[2025-09-30 14:01:25] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.21, #queue-req: 0, 
[2025-09-30 14:01:25] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.79, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 882, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 14:01:26] Decode batch. #running-req: 1, #token: 922, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:01:27] Decode batch. #running-req: 1, #token: 962, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:01:27] Decode batch. #running-req: 1, #token: 1002, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.40, #queue-req: 0, 
[2025-09-30 14:01:27] Decode batch. #running-req: 1, #token: 1042, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.22, #queue-req: 0, 
[2025-09-30 14:01:28] Decode batch. #running-req: 1, #token: 1082, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:01:28] Decode batch. #running-req: 1, #token: 1122, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.00, #queue-req: 0, 
[2025-09-30 14:01:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:28] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:28] Decode batch. #running-req: 1, #token: 729, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.42, #queue-req: 0, 
[2025-09-30 14:01:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:28] Prefill batch. #new-seq: 1, #new-token: 1005, #cached-token: 133, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:29] Decode batch. #running-req: 1, #token: 1153, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.34, #queue-req: 0, 
[2025-09-30 14:01:29] Decode batch. #running-req: 1, #token: 1193, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:01:29] Decode batch. #running-req: 1, #token: 1233, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:01:30] Decode batch. #running-req: 1, #token: 1273, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:01:30] Decode batch. #running-req: 1, #token: 1313, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.29, #queue-req: 0, 
[2025-09-30 14:01:30] Decode batch. #running-req: 1, #token: 1353, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 14:01:30] Decode batch. #running-req: 1, #token: 1393, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 1433, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 1473, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.96, #queue-req: 0, 
[2025-09-30 14:01:31] Decode batch. #running-req: 1, #token: 1513, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 14:01:32] Decode batch. #running-req: 1, #token: 1553, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.88, #queue-req: 0, 
[2025-09-30 14:01:32] Decode batch. #running-req: 1, #token: 1593, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:01:32] Decode batch. #running-req: 1, #token: 1633, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:01:33] Decode batch. #running-req: 1, #token: 1673, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:01:33] Decode batch. #running-req: 1, #token: 1713, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:01:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:33] Prefill batch. #new-seq: 1, #new-token: 1237, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:34] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:34] Decode batch. #running-req: 1, #token: 781, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.18, #queue-req: 0, 
[2025-09-30 14:01:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:34] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:34] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.45, #queue-req: 0, 
[2025-09-30 14:01:34] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:01:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:34] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:35] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:35] Decode batch. #running-req: 1, #token: 676, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.80, #queue-req: 0, 
[2025-09-30 14:01:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:35] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 659, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:35] Decode batch. #running-req: 1, #token: 681, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.62, #queue-req: 0, 
[2025-09-30 14:01:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:36] Prefill batch. #new-seq: 1, #new-token: 967, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:36] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:36] Decode batch. #running-req: 1, #token: 582, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.76, #queue-req: 0, 
[2025-09-30 14:01:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:36] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.37, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:01:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:37] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:37] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:37] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.68, #queue-req: 0, 
[2025-09-30 14:01:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:38] Prefill batch. #new-seq: 1, #new-token: 847, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:38] Prefill batch. #new-seq: 1, #new-token: 465, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:38] Decode batch. #running-req: 1, #token: 647, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.52, #queue-req: 0, 
[2025-09-30 14:01:38] Decode batch. #running-req: 1, #token: 687, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:39] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:39] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.24, #queue-req: 0, 
[2025-09-30 14:01:39] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:39] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:39] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:39] Decode batch. #running-req: 1, #token: 553, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.57, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 697, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:40] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.15, #queue-req: 0, 
[2025-09-30 14:01:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:40] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 436, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.87, #queue-req: 0, 
[2025-09-30 14:01:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:41] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:41] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.83, #queue-req: 0, 
[2025-09-30 14:01:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:41] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:42] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.09, #queue-req: 0, 
[2025-09-30 14:01:42] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:01:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:43] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.77, #queue-req: 0, 
[2025-09-30 14:01:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 305, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.98, #queue-req: 0, 
[2025-09-30 14:01:43] Decode batch. #running-req: 1, #token: 385, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.11, #queue-req: 0, 
[2025-09-30 14:01:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.64, #queue-req: 0, 
[2025-09-30 14:01:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:44] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:44] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.12, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:01:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:45] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:45] Prefill batch. #new-seq: 1, #new-token: 298, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:45] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.46, #queue-req: 0, 
[2025-09-30 14:01:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 607, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.58, #queue-req: 0, 
[2025-09-30 14:01:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:46] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:46] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 14:01:47] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:01:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:47] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:47] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:47] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.66, #queue-req: 0, 
[2025-09-30 14:01:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.19, #queue-req: 0, 
[2025-09-30 14:01:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:48] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:48] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.50, #queue-req: 0, 
[2025-09-30 14:01:49] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:01:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:49] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:49] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:49] Decode batch. #running-req: 1, #token: 556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.73, #queue-req: 0, 
[2025-09-30 14:01:50] Decode batch. #running-req: 1, #token: 596, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:01:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:50] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:50] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:01:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.28, #queue-req: 0, 
[2025-09-30 14:01:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:51] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:51] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.82, #queue-req: 0, 
[2025-09-30 14:01:51] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:01:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:52] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:52] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.76, #queue-req: 0, 
[2025-09-30 14:01:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:52] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:52] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:53] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:53] Decode batch. #running-req: 1, #token: 498, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.84, #queue-req: 0, 
[2025-09-30 14:01:53] Decode batch. #running-req: 1, #token: 538, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.45, #queue-req: 0, 
[2025-09-30 14:01:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:53] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:53] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 14:01:54] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:01:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:54] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:54] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.83, #queue-req: 0, 
[2025-09-30 14:01:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:54] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:55] Prefill batch. #new-seq: 1, #new-token: 1487, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 1844, token usage: 0.03, cuda graph: True, gen throughput (token/s): 39.74, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 1884, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:01:55] Decode batch. #running-req: 1, #token: 1924, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:01:56] Decode batch. #running-req: 1, #token: 1964, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:01:56] Decode batch. #running-req: 1, #token: 2004, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:01:56] Decode batch. #running-req: 1, #token: 2044, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:01:57] Decode batch. #running-req: 1, #token: 2084, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.37, #queue-req: 0, 
[2025-09-30 14:01:57] Decode batch. #running-req: 1, #token: 2124, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:01:57] Decode batch. #running-req: 1, #token: 2164, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.32, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 2204, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 2244, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:01:58] Decode batch. #running-req: 1, #token: 2284, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:01:59] Decode batch. #running-req: 1, #token: 2324, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.04, #queue-req: 0, 
[2025-09-30 14:01:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:59] Prefill batch. #new-seq: 1, #new-token: 1487, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:01:59] Decode batch. #running-req: 1, #token: 1844, token usage: 0.03, cuda graph: True, gen throughput (token/s): 101.29, #queue-req: 0, 
[2025-09-30 14:01:59] Decode batch. #running-req: 1, #token: 1884, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.97, #queue-req: 0, 
[2025-09-30 14:01:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:01:59] Prefill batch. #new-seq: 1, #new-token: 1051, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:00] Decode batch. #running-req: 1, #token: 1198, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.68, #queue-req: 0, 
[2025-09-30 14:02:00] Decode batch. #running-req: 1, #token: 1238, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:02:00] Decode batch. #running-req: 1, #token: 1278, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 1318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.33, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 1358, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.34, #queue-req: 0, 
[2025-09-30 14:02:01] Decode batch. #running-req: 1, #token: 1398, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.24, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 1438, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 1478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 1518, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:02:02] Decode batch. #running-req: 1, #token: 1558, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.84, #queue-req: 0, 
[2025-09-30 14:02:03] Decode batch. #running-req: 1, #token: 1598, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.56, #queue-req: 0, 
[2025-09-30 14:02:03] Decode batch. #running-req: 1, #token: 1638, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:02:03] Decode batch. #running-req: 1, #token: 1678, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:02:04] Decode batch. #running-req: 1, #token: 1718, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:02:04] Decode batch. #running-req: 1, #token: 1758, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:02:04] Decode batch. #running-req: 1, #token: 1798, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:02:05] Decode batch. #running-req: 1, #token: 1838, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:02:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:06] Decode batch. #running-req: 1, #token: 525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.68, #queue-req: 0, 
[2025-09-30 14:02:06] Decode batch. #running-req: 1, #token: 565, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0, 
[2025-09-30 14:02:06] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.06, #queue-req: 0, 
[2025-09-30 14:02:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:06] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:07] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.80, #queue-req: 0, 
[2025-09-30 14:02:07] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:02:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:07] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:07] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.82, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 418, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 695, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:08] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:08] Decode batch. #running-req: 1, #token: 518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.94, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.31, #queue-req: 0, 
[2025-09-30 14:02:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:09] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.45, #queue-req: 0, 
[2025-09-30 14:02:09] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:10] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:10] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:10] Decode batch. #running-req: 1, #token: 421, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.66, #queue-req: 0, 
[2025-09-30 14:02:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 998, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:11] Decode batch. #running-req: 1, #token: 840, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.12, #queue-req: 0, 
[2025-09-30 14:02:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:11] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:11] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.29, #queue-req: 0, 
[2025-09-30 14:02:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:12] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:12] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.80, #queue-req: 0, 
[2025-09-30 14:02:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:12] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:12] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.08, #queue-req: 0, 
[2025-09-30 14:02:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:13] Prefill batch. #new-seq: 1, #new-token: 1113, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:13] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:13] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.37, #queue-req: 0, 
[2025-09-30 14:02:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:13] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:13] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.32, #queue-req: 0, 
[2025-09-30 14:02:14] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:02:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:14] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:14] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:14] Decode batch. #running-req: 1, #token: 542, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.71, #queue-req: 0, 
[2025-09-30 14:02:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:14] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.25, #queue-req: 0, 
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 533, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:15] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:15] Decode batch. #running-req: 1, #token: 815, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.07, #queue-req: 0, 
[2025-09-30 14:02:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:16] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:16] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.58, #queue-req: 0, 
[2025-09-30 14:02:16] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:02:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:16] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:02:16] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] Decode batch. #running-req: 1, #token: 727, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.97, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 1288, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:17] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:18] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:18] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.49, #queue-req: 0, 
[2025-09-30 14:02:18] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:02:18] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:02:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:18] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:19] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:19] Decode batch. #running-req: 1, #token: 732, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.51, #queue-req: 0, 
[2025-09-30 14:02:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 940, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] Decode batch. #running-req: 1, #token: 469, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.81, #queue-req: 0, 
[2025-09-30 14:02:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:20] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:20] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.48, #queue-req: 0, 
[2025-09-30 14:02:20] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.02, #queue-req: 0, 
[2025-09-30 14:02:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:21] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:21] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:02:22] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:02:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:22] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:22] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:23] Decode batch. #running-req: 1, #token: 554, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.05, #queue-req: 0, 
[2025-09-30 14:02:23] Decode batch. #running-req: 1, #token: 594, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.34, #queue-req: 0, 
[2025-09-30 14:02:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:23] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:23] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.80, #queue-req: 0, 
[2025-09-30 14:02:23] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:02:24] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:02:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:24] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:24] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:24] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 102.34, #queue-req: 0, 
[2025-09-30 14:02:25] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:25] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:25] Decode batch. #running-req: 1, #token: 760, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.80, #queue-req: 0, 
[2025-09-30 14:02:25] Decode batch. #running-req: 1, #token: 800, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.20, #queue-req: 0, 
[2025-09-30 14:02:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:26] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:26] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:02:26] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:02:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:27] Prefill batch. #new-seq: 1, #new-token: 841, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:27] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:27] Decode batch. #running-req: 1, #token: 474, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.85, #queue-req: 0, 
[2025-09-30 14:02:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:27] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:27] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.27, #queue-req: 0, 
[2025-09-30 14:02:27] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:02:28] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:02:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:28] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:28] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:29] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.30, #queue-req: 0, 
[2025-09-30 14:02:29] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 497, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.75, #queue-req: 0, 
[2025-09-30 14:02:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:29] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:29] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:02:30] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:02:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:30] Prefill batch. #new-seq: 1, #new-token: 649, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:30] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 535, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.61, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.03, #queue-req: 0, 
[2025-09-30 14:02:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:31] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:02:31] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:02:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:32] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:32] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:32] Decode batch. #running-req: 1, #token: 489, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.96, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 529, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.65, #queue-req: 0, 
[2025-09-30 14:02:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:33] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.53, #queue-req: 0, 
[2025-09-30 14:02:33] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:02:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:34] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:02:34] Prefill batch. #new-seq: 1, #new-token: 2265, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:34] Decode batch. #running-req: 1, #token: 2645, token usage: 0.04, cuda graph: True, gen throughput (token/s): 47.68, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 2685, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.05, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 2725, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.08, #queue-req: 0, 
[2025-09-30 14:02:35] Decode batch. #running-req: 1, #token: 2765, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:02:36] Decode batch. #running-req: 1, #token: 2805, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:02:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:36] Prefill batch. #new-seq: 1, #new-token: 2265, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:36] Decode batch. #running-req: 1, #token: 2599, token usage: 0.04, cuda graph: True, gen throughput (token/s): 91.04, #queue-req: 0, 
[2025-09-30 14:02:36] Decode batch. #running-req: 1, #token: 2639, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.16, #queue-req: 0, 
[2025-09-30 14:02:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:36] Prefill batch. #new-seq: 1, #new-token: 816, #cached-token: 228, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 1076, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.46, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 1116, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:02:37] Decode batch. #running-req: 1, #token: 1156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:02:38] Decode batch. #running-req: 1, #token: 1196, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:02:38] Decode batch. #running-req: 1, #token: 1236, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:02:38] Decode batch. #running-req: 1, #token: 1276, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:02:39] Decode batch. #running-req: 1, #token: 1316, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.37, #queue-req: 0, 
[2025-09-30 14:02:39] Decode batch. #running-req: 1, #token: 1356, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.23, #queue-req: 0, 
[2025-09-30 14:02:39] Decode batch. #running-req: 1, #token: 1396, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:02:40] Decode batch. #running-req: 1, #token: 1436, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:02:40] Decode batch. #running-req: 1, #token: 1476, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:02:40] Decode batch. #running-req: 1, #token: 1516, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:02:40] Decode batch. #running-req: 1, #token: 1556, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.90, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 1596, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.65, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 1636, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:02:41] Decode batch. #running-req: 1, #token: 1676, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:02:42] Decode batch. #running-req: 1, #token: 1716, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:02:42] Decode batch. #running-req: 1, #token: 1756, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:02:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] Decode batch. #running-req: 1, #token: 383, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.21, #queue-req: 0, 
[2025-09-30 14:02:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:43] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:43] Decode batch. #running-req: 1, #token: 217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.64, #queue-req: 0, 
[2025-09-30 14:02:43] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 14:02:44] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:02:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:44] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:44] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:44] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.73, #queue-req: 0, 
[2025-09-30 14:02:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:45] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:45] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:45] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.29, #queue-req: 0, 
[2025-09-30 14:02:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:45] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:45] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.81, #queue-req: 0, 
[2025-09-30 14:02:46] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:46] Prefill batch. #new-seq: 1, #new-token: 495, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:46] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:46] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.87, #queue-req: 0, 
[2025-09-30 14:02:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:46] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:46] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.39, #queue-req: 0, 
[2025-09-30 14:02:47] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:02:47] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:02:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:47] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:47] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:48] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.08, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 315, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:48] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 450, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.64, #queue-req: 0, 
[2025-09-30 14:02:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.86, #queue-req: 0, 
[2025-09-30 14:02:49] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.57, #queue-req: 0, 
[2025-09-30 14:02:49] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:50] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:50] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:50] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.98, #queue-req: 0, 
[2025-09-30 14:02:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:50] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:51] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 14:02:51] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:02:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:51] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:51] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:51] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.12, #queue-req: 0, 
[2025-09-30 14:02:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:52] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:52] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:52] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.00, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.09, #queue-req: 0, 
[2025-09-30 14:02:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:53] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.90, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:02:53] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:02:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:54] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:54] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:54] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.11, #queue-req: 0, 
[2025-09-30 14:02:55] Prefill batch. #new-seq: 1, #new-token: 1498, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:55] Decode batch. #running-req: 1, #token: 1878, token usage: 0.03, cuda graph: True, gen throughput (token/s): 44.47, #queue-req: 0, 
[2025-09-30 14:02:55] Decode batch. #running-req: 1, #token: 1918, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 1958, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 1998, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:02:56] Decode batch. #running-req: 1, #token: 2038, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 2078, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.43, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 2118, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 2158, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.33, #queue-req: 0, 
[2025-09-30 14:02:57] Decode batch. #running-req: 1, #token: 2198, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:02:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:58] Prefill batch. #new-seq: 1, #new-token: 1498, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:58] Decode batch. #running-req: 1, #token: 1844, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.99, #queue-req: 0, 
[2025-09-30 14:02:58] Decode batch. #running-req: 1, #token: 1884, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.98, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 1924, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:02:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:02:59] Prefill batch. #new-seq: 1, #new-token: 893, #cached-token: 338, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 1262, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.92, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 1302, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.53, #queue-req: 0, 
[2025-09-30 14:02:59] Decode batch. #running-req: 1, #token: 1342, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 1382, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 1422, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:03:00] Decode batch. #running-req: 1, #token: 1462, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 1502, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 1542, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:03:01] Decode batch. #running-req: 1, #token: 1582, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.59, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 1622, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 1662, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:03:02] Decode batch. #running-req: 1, #token: 1702, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.38, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 1742, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 1782, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:03:03] Decode batch. #running-req: 1, #token: 1822, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1862, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1902, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1942, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:03:04] Decode batch. #running-req: 1, #token: 1982, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:03:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:05] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:05] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:05] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.36, #queue-req: 0, 
[2025-09-30 14:03:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:05] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:06] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:03:06] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 14:03:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:06] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:06] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:07] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:07] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.71, #queue-req: 0, 
[2025-09-30 14:03:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:07] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:07] Decode batch. #running-req: 1, #token: 450, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0, 
[2025-09-30 14:03:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:07] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:08] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.38, #queue-req: 0, 
[2025-09-30 14:03:08] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:03:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:08] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:08] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:08] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.44, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:09] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:09] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:09] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.03, #queue-req: 0, 
[2025-09-30 14:03:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:09] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:10] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.48, #queue-req: 0, 
[2025-09-30 14:03:10] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:03:10] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:03:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.57, #queue-req: 0, 
[2025-09-30 14:03:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:11] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:11] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.68, #queue-req: 0, 
[2025-09-30 14:03:12] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:03:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:12] Prefill batch. #new-seq: 1, #new-token: 561, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:12] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:12] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.19, #queue-req: 0, 
[2025-09-30 14:03:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.44, #queue-req: 0, 
[2025-09-30 14:03:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:13] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:13] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.67, #queue-req: 0, 
[2025-09-30 14:03:13] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:14] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.01, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:14] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:15] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.95, #queue-req: 0, 
[2025-09-30 14:03:15] Decode batch. #running-req: 1, #token: 468, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 14:03:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:15] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:16] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:03:16] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:03:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:16] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:16] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:16] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.16, #queue-req: 0, 
[2025-09-30 14:03:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:17] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.36, #queue-req: 0, 
[2025-09-30 14:03:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:17] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:18] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.53, #queue-req: 0, 
[2025-09-30 14:03:18] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:03:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:18] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:18] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.02, #queue-req: 0, 
[2025-09-30 14:03:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:18] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:19] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:19] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.71, #queue-req: 0, 
[2025-09-30 14:03:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 514, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:19] Decode batch. #running-req: 1, #token: 552, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.66, #queue-req: 0, 
[2025-09-30 14:03:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:20] Prefill batch. #new-seq: 1, #new-token: 1091, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:20] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:20] Decode batch. #running-req: 1, #token: 819, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.02, #queue-req: 0, 
[2025-09-30 14:03:20] Decode batch. #running-req: 1, #token: 859, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.03, #queue-req: 0, 
[2025-09-30 14:03:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:21] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:21] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:03:21] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:03:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:22] Prefill batch. #new-seq: 1, #new-token: 1695, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:22] Decode batch. #running-req: 1, #token: 2069, token usage: 0.03, cuda graph: True, gen throughput (token/s): 46.50, #queue-req: 0, 
[2025-09-30 14:03:22] Decode batch. #running-req: 1, #token: 2109, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 2149, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 2189, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:03:23] Decode batch. #running-req: 1, #token: 2229, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 2269, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 2309, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.11, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 2349, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.75, #queue-req: 0, 
[2025-09-30 14:03:24] Decode batch. #running-req: 1, #token: 2389, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.75, #queue-req: 0, 
[2025-09-30 14:03:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Prefill batch. #new-seq: 1, #new-token: 1695, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:25] Prefill batch. #new-seq: 1, #new-token: 1094, #cached-token: 151, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:25] Decode batch. #running-req: 1, #token: 1251, token usage: 0.02, cuda graph: True, gen throughput (token/s): 85.56, #queue-req: 0, 
[2025-09-30 14:03:25] Decode batch. #running-req: 1, #token: 1291, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.58, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 1331, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.30, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 1371, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 1411, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:03:26] Decode batch. #running-req: 1, #token: 1451, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:03:27] Decode batch. #running-req: 1, #token: 1491, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:03:27] Decode batch. #running-req: 1, #token: 1531, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:03:27] Decode batch. #running-req: 1, #token: 1571, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.66, #queue-req: 0, 
[2025-09-30 14:03:28] Decode batch. #running-req: 1, #token: 1611, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:03:28] Decode batch. #running-req: 1, #token: 1651, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:03:28] Decode batch. #running-req: 1, #token: 1691, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 1731, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 1771, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:03:29] Decode batch. #running-req: 1, #token: 1811, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.14, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 1851, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 1891, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:03:30] Decode batch. #running-req: 1, #token: 1931, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 1971, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 2011, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 2051, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.73, #queue-req: 0, 
[2025-09-30 14:03:31] Decode batch. #running-req: 1, #token: 2091, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:03:32] Decode batch. #running-req: 1, #token: 2131, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:03:32] Decode batch. #running-req: 1, #token: 2171, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:03:32] Decode batch. #running-req: 1, #token: 2211, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:03:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:33] Prefill batch. #new-seq: 1, #new-token: 1382, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:33] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:33] Decode batch. #running-req: 1, #token: 927, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.68, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:34] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:34] Decode batch. #running-req: 1, #token: 220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.87, #queue-req: 0, 
[2025-09-30 14:03:34] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:34] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:34] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:35] Decode batch. #running-req: 1, #token: 816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.33, #queue-req: 0, 
[2025-09-30 14:03:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 1003, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] Decode batch. #running-req: 1, #token: 455, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.65, #queue-req: 0, 
[2025-09-30 14:03:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:36] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:36] Decode batch. #running-req: 1, #token: 204, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 14:03:36] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:03:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:37] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:37] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:37] Decode batch. #running-req: 1, #token: 511, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.21, #queue-req: 0, 
[2025-09-30 14:03:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:38] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:38] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.87, #queue-req: 0, 
[2025-09-30 14:03:38] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:03:38] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:03:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:39] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:40] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 29.76, #queue-req: 0, 
[2025-09-30 14:03:40] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:03:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:40] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:40] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 14:03:41] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:03:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:41] Prefill batch. #new-seq: 1, #new-token: 505, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:41] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:42] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.63, #queue-req: 0, 
[2025-09-30 14:03:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:42] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:42] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.66, #queue-req: 0, 
[2025-09-30 14:03:42] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 14:03:43] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:43] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:43] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:43] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.37, #queue-req: 0, 
[2025-09-30 14:03:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:44] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:44] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:44] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.96, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:45] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:45] Decode batch. #running-req: 1, #token: 408, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.33, #queue-req: 0, 
[2025-09-30 14:03:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:46] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:46] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 390, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:46] Decode batch. #running-req: 1, #token: 417, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.17, #queue-req: 0, 
[2025-09-30 14:03:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:47] Prefill batch. #new-seq: 1, #new-token: 1432, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:47] Decode batch. #running-req: 1, #token: 1810, token usage: 0.03, cuda graph: True, gen throughput (token/s): 39.87, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 1850, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 1890, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:03:48] Decode batch. #running-req: 1, #token: 1930, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:03:49] Decode batch. #running-req: 1, #token: 1970, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:03:49] Decode batch. #running-req: 1, #token: 2010, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:03:49] Decode batch. #running-req: 1, #token: 2050, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.72, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 2090, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:03:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:50] Prefill batch. #new-seq: 1, #new-token: 1432, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:50] Decode batch. #running-req: 1, #token: 1791, token usage: 0.03, cuda graph: True, gen throughput (token/s): 102.66, #queue-req: 0, 
[2025-09-30 14:03:51] Decode batch. #running-req: 1, #token: 1831, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.02, #queue-req: 0, 
[2025-09-30 14:03:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:03:51] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 210, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:03:51] Decode batch. #running-req: 1, #token: 1476, token usage: 0.02, cuda graph: True, gen throughput (token/s): 105.70, #queue-req: 0, 
[2025-09-30 14:03:51] Decode batch. #running-req: 1, #token: 1516, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 1556, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.86, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 1596, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.56, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 1636, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:03:52] Decode batch. #running-req: 1, #token: 1676, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:03:53] Decode batch. #running-req: 1, #token: 1716, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:03:53] Decode batch. #running-req: 1, #token: 1756, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:03:53] Decode batch. #running-req: 1, #token: 1796, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:03:54] Decode batch. #running-req: 1, #token: 1836, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.01, #queue-req: 0, 
[2025-09-30 14:03:54] Decode batch. #running-req: 1, #token: 1876, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:03:54] Decode batch. #running-req: 1, #token: 1916, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:03:55] Decode batch. #running-req: 1, #token: 1956, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:03:55] Decode batch. #running-req: 1, #token: 1996, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:03:55] Decode batch. #running-req: 1, #token: 2036, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:03:56] Decode batch. #running-req: 1, #token: 2076, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.43, #queue-req: 0, 
[2025-09-30 14:03:56] Decode batch. #running-req: 1, #token: 2116, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:03:56] Decode batch. #running-req: 1, #token: 2156, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:03:57] Decode batch. #running-req: 1, #token: 2196, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:03:57] Decode batch. #running-req: 1, #token: 2236, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:03:57] Decode batch. #running-req: 1, #token: 2276, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:03:57] Decode batch. #running-req: 1, #token: 2316, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.06, #queue-req: 0, 
[2025-09-30 14:03:58] Decode batch. #running-req: 1, #token: 2356, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:03:58] Decode batch. #running-req: 1, #token: 2396, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:03:58] Decode batch. #running-req: 1, #token: 2436, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:03:59] Decode batch. #running-req: 1, #token: 2476, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:03:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:00] Prefill batch. #new-seq: 1, #new-token: 673, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:00] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:00] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-09-30 14:04:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:00] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:00] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.34, #queue-req: 0, 
[2025-09-30 14:04:00] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:04:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:01] Prefill batch. #new-seq: 1, #new-token: 607, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:01] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:01] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.15, #queue-req: 0, 
[2025-09-30 14:04:01] Decode batch. #running-req: 1, #token: 468, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.13, #queue-req: 0, 
[2025-09-30 14:04:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:01] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:02] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.16, #queue-req: 0, 
[2025-09-30 14:04:02] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:04:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:03] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:03] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:03] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.01, #queue-req: 0, 
[2025-09-30 14:04:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:03] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:03] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:04:03] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:04] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:04] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:04] Decode batch. #running-req: 1, #token: 373, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.40, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:04] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 359, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:05] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.61, #queue-req: 0, 
[2025-09-30 14:04:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:05] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:05] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:05] Decode batch. #running-req: 1, #token: 742, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.09, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 14:04:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:06] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.90, #queue-req: 0, 
[2025-09-30 14:04:06] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:04:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:07] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:07] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:07] Decode batch. #running-req: 1, #token: 630, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.68, #queue-req: 0, 
[2025-09-30 14:04:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:07] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:07] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 612, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:08] Prefill batch. #new-seq: 1, #new-token: 1069, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:08] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:08] Decode batch. #running-req: 1, #token: 702, token usage: 0.01, cuda graph: True, gen throughput (token/s): 26.27, #queue-req: 0, 
[2025-09-30 14:04:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:09] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:04:09] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:04:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:10] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:10] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:11] Prefill batch. #new-seq: 1, #new-token: 1122, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 28.00, #queue-req: 0, 
[2025-09-30 14:04:11] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.74, #queue-req: 0, 
[2025-09-30 14:04:11] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 14:04:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:11] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.77, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 384, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:04:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:12] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:12] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.85, #queue-req: 0, 
[2025-09-30 14:04:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:12] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:13] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.86, #queue-req: 0, 
[2025-09-30 14:04:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:13] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 666, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:14] Decode batch. #running-req: 1, #token: 689, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.53, #queue-req: 0, 
[2025-09-30 14:04:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:14] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:14] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:15] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:15] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.10, #queue-req: 0, 
[2025-09-30 14:04:15] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:04:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:16] Prefill batch. #new-seq: 1, #new-token: 1107, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:16] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.70, #queue-req: 0, 
[2025-09-30 14:04:16] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:16] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:16] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.61, #queue-req: 0, 
[2025-09-30 14:04:16] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:04:17] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:17] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:17] Prefill batch. #new-seq: 1, #new-token: 553, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:17] Decode batch. #running-req: 1, #token: 637, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.22, #queue-req: 0, 
[2025-09-30 14:04:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:18] Prefill batch. #new-seq: 1, #new-token: 767, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:18] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:18] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.23, #queue-req: 0, 
[2025-09-30 14:04:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:18] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:18] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 14:04:19] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:04:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:19] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:19] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:19] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.36, #queue-req: 0, 
[2025-09-30 14:04:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:20] Prefill batch. #new-seq: 1, #new-token: 412, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:20] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:20] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:20] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.63, #queue-req: 0, 
[2025-09-30 14:04:21] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:04:21] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:04:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:21] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:21] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:22] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:22] Prefill batch. #new-seq: 1, #new-token: 508, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:22] Decode batch. #running-req: 1, #token: 674, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.68, #queue-req: 0, 
[2025-09-30 14:04:22] Decode batch. #running-req: 1, #token: 714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.73, #queue-req: 0, 
[2025-09-30 14:04:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:23] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.14, #queue-req: 0, 
[2025-09-30 14:04:23] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:04:23] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:04:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:23] Prefill batch. #new-seq: 1, #new-token: 504, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:24] Decode batch. #running-req: 1, #token: 602, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.95, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:24] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 576, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:24] Decode batch. #running-req: 1, #token: 600, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-09-30 14:04:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 867, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:25] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:25] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.09, #queue-req: 0, 
[2025-09-30 14:04:26] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:04:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:26] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:26] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:26] Decode batch. #running-req: 1, #token: 557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.74, #queue-req: 0, 
[2025-09-30 14:04:27] Decode batch. #running-req: 1, #token: 597, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.14, #queue-req: 0, 
[2025-09-30 14:04:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:27] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:27] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.28, #queue-req: 0, 
[2025-09-30 14:04:27] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:04:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:28] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:28] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:28] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.23, #queue-req: 0, 
[2025-09-30 14:04:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 458, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.55, #queue-req: 0, 
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:29] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:30] Decode batch. #running-req: 1, #token: 566, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.79, #queue-req: 0, 
[2025-09-30 14:04:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:30] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:30] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.05, #queue-req: 0, 
[2025-09-30 14:04:30] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:31] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:31] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:31] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.78, #queue-req: 0, 
[2025-09-30 14:04:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:32] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:32] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:32] Decode batch. #running-req: 1, #token: 481, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.46, #queue-req: 0, 
[2025-09-30 14:04:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:32] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:32] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:04:32] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.15, #queue-req: 0, 
[2025-09-30 14:04:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:33] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:33] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:33] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.19, #queue-req: 0, 
[2025-09-30 14:04:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:34] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:34] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:34] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-09-30 14:04:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:34] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:34] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:04:34] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:04:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:35] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:35] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.77, #queue-req: 0, 
[2025-09-30 14:04:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:35] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:35] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.72, #queue-req: 0, 
[2025-09-30 14:04:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:36] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:36] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:36] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 37.47, #queue-req: 0, 
[2025-09-30 14:04:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:36] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.59, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:37] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:37] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.21, #queue-req: 0, 
[2025-09-30 14:04:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:38] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:38] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:04:38] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.58, #queue-req: 0, 
[2025-09-30 14:04:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:38] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:38] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:38] Decode batch. #running-req: 1, #token: 131, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.61, #queue-req: 0, 
[2025-09-30 14:04:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:39] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:39] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 37.77, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.03, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.53, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:40] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:41] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:41] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:41] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 36.46, #queue-req: 0, 
[2025-09-30 14:04:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:41] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.60, #queue-req: 0, 
[2025-09-30 14:04:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:42] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] Decode batch. #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.74, #queue-req: 0, 
[2025-09-30 14:04:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:42] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:43] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:43] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:43] Decode batch. #running-req: 1, #token: 207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.21, #queue-req: 0, 
[2025-09-30 14:04:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:43] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:43] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.31, #queue-req: 0, 
[2025-09-30 14:04:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:44] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:44] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:44] Decode batch. #running-req: 1, #token: 111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.87, #queue-req: 0, 
[2025-09-30 14:04:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:44] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:44] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 107, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] Decode batch. #running-req: 1, #token: 118, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.60, #queue-req: 0, 
[2025-09-30 14:04:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:45] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.54, #queue-req: 0, 
[2025-09-30 14:04:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:45] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:46] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.68, #queue-req: 0, 
[2025-09-30 14:04:46] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:04:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:46] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:46] Decode batch. #running-req: 1, #token: 108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.61, #queue-req: 0, 
[2025-09-30 14:04:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:46] Prefill batch. #new-seq: 1, #new-token: 481, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 949, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:47] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:48] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.45, #queue-req: 0, 
[2025-09-30 14:04:48] Decode batch. #running-req: 1, #token: 685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.68, #queue-req: 0, 
[2025-09-30 14:04:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:48] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:48] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.19, #queue-req: 0, 
[2025-09-30 14:04:48] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:04:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:49] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:49] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:49] Decode batch. #running-req: 1, #token: 549, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.41, #queue-req: 0, 
[2025-09-30 14:04:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:50] Prefill batch. #new-seq: 1, #new-token: 983, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:50] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 705, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.86, #queue-req: 0, 
[2025-09-30 14:04:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:50] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:50] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 14:04:51] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:04:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:51] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:51] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:51] Decode batch. #running-req: 1, #token: 607, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.30, #queue-req: 0, 
[2025-09-30 14:04:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:52] Prefill batch. #new-seq: 1, #new-token: 891, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:52] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:52] Decode batch. #running-req: 1, #token: 564, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.53, #queue-req: 0, 
[2025-09-30 14:04:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:52] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:52] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.10, #queue-req: 0, 
[2025-09-30 14:04:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:53] Prefill batch. #new-seq: 1, #new-token: 941, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:53] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:53] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.47, #queue-req: 0, 
[2025-09-30 14:04:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:54] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.98, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:04:54] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:04:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:55] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:55] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:55] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.73, #queue-req: 0, 
[2025-09-30 14:04:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:56] Prefill batch. #new-seq: 1, #new-token: 1099, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:56] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.26, #queue-req: 0, 
[2025-09-30 14:04:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:56] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:04:56] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:04:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:57] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:57] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:57] Decode batch. #running-req: 1, #token: 601, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.33, #queue-req: 0, 
[2025-09-30 14:04:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:58] Prefill batch. #new-seq: 1, #new-token: 965, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:58] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:58] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.95, #queue-req: 0, 
[2025-09-30 14:04:58] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.89, #queue-req: 0, 
[2025-09-30 14:04:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:04:59] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:04:59] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:04:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:59] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:04:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:04:59] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:00] Decode batch. #running-req: 1, #token: 535, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.72, #queue-req: 0, 
[2025-09-30 14:05:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:00] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:00] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 512, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:00] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.51, #queue-req: 0, 
[2025-09-30 14:05:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:01] Prefill batch. #new-seq: 1, #new-token: 967, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:01] Prefill batch. #new-seq: 1, #new-token: 531, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:01] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.71, #queue-req: 0, 
[2025-09-30 14:05:02] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.49, #queue-req: 0, 
[2025-09-30 14:05:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:02] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:02] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.14, #queue-req: 0, 
[2025-09-30 14:05:02] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:05:03] Decode batch. #running-req: 1, #token: 375, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:05:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:03] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:03] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:03] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.58, #queue-req: 0, 
[2025-09-30 14:05:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:04] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 599, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:04] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.08, #queue-req: 0, 
[2025-09-30 14:05:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:04] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:05] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 599, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:05] Prefill batch. #new-seq: 1, #new-token: 970, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:05] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 28.37, #queue-req: 0, 
[2025-09-30 14:05:05] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 649, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.43, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 689, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:05:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:06] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:06] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.05, #queue-req: 0, 
[2025-09-30 14:05:07] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:05:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:07] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:07] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.77, #queue-req: 0, 
[2025-09-30 14:05:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:07] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:08] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:08] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:08] Decode batch. #running-req: 1, #token: 488, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.06, #queue-req: 0, 
[2025-09-30 14:05:08] Decode batch. #running-req: 1, #token: 528, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.65, #queue-req: 0, 
[2025-09-30 14:05:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:09] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:09] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:05:09] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:05:09] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:05:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:09] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:09] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:10] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.65, #queue-req: 0, 
[2025-09-30 14:05:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 383, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:11] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:11] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:11] Decode batch. #running-req: 1, #token: 455, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.54, #queue-req: 0, 
[2025-09-30 14:05:11] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.87, #queue-req: 0, 
[2025-09-30 14:05:12] Decode batch. #running-req: 1, #token: 535, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.44, #queue-req: 0, 
[2025-09-30 14:05:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:12] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:12] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:05:12] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:05:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:13] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:13] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:05:13] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:14] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:14] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 543, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.18, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 583, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.10, #queue-req: 0, 
[2025-09-30 14:05:14] Decode batch. #running-req: 1, #token: 623, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.87, #queue-req: 0, 
[2025-09-30 14:05:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:15] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:15] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:05:15] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:05:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.51, #queue-req: 0, 
[2025-09-30 14:05:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:16] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:16] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:05:17] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:05:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:17] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:17] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:18] Decode batch. #running-req: 1, #token: 522, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.58, #queue-req: 0, 
[2025-09-30 14:05:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:18] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:18] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.28, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:19] Prefill batch. #new-seq: 1, #new-token: 425, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:19] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:19] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.81, #queue-req: 0, 
[2025-09-30 14:05:19] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 14:05:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:20] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:20] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.29, #queue-req: 0, 
[2025-09-30 14:05:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:20] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:21] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:21] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:21] Decode batch. #running-req: 1, #token: 460, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.11, #queue-req: 0, 
[2025-09-30 14:05:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:21] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:21] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.46, #queue-req: 0, 
[2025-09-30 14:05:22] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:05:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:22] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:22] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:22] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.44, #queue-req: 0, 
[2025-09-30 14:05:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:23] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.73, #queue-req: 0, 
[2025-09-30 14:05:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:23] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:23] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:05:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:24] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:24] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:24] Decode batch. #running-req: 1, #token: 185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.17, #queue-req: 0, 
[2025-09-30 14:05:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:25] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:25] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:25] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:25] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 34.96, #queue-req: 0, 
[2025-09-30 14:05:25] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:05:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:26] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:26] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:26] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.82, #queue-req: 0, 
[2025-09-30 14:05:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:26] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:26] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.80, #queue-req: 0, 
[2025-09-30 14:05:27] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:05:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:27] Prefill batch. #new-seq: 1, #new-token: 1650, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 1699, token usage: 0.03, cuda graph: True, gen throughput (token/s): 42.70, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 1739, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:05:28] Decode batch. #running-req: 1, #token: 1779, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:05:29] Decode batch. #running-req: 1, #token: 1819, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.07, #queue-req: 0, 
[2025-09-30 14:05:29] Decode batch. #running-req: 1, #token: 1859, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:05:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:29] Prefill batch. #new-seq: 1, #new-token: 1630, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:29] Decode batch. #running-req: 1, #token: 1675, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.66, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 1715, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:05:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:30] Prefill batch. #new-seq: 1, #new-token: 1366, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 1427, token usage: 0.02, cuda graph: True, gen throughput (token/s): 104.67, #queue-req: 0, 
[2025-09-30 14:05:30] Decode batch. #running-req: 1, #token: 1467, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 14:05:31] Decode batch. #running-req: 1, #token: 1507, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:05:31] Decode batch. #running-req: 1, #token: 1547, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:05:31] Decode batch. #running-req: 1, #token: 1587, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.63, #queue-req: 0, 
[2025-09-30 14:05:32] Decode batch. #running-req: 1, #token: 1627, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:05:32] Decode batch. #running-req: 1, #token: 1667, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.58, #queue-req: 0, 
[2025-09-30 14:05:32] Decode batch. #running-req: 1, #token: 1707, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 1747, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 1787, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 1827, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:05:33] Decode batch. #running-req: 1, #token: 1867, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:05:34] Decode batch. #running-req: 1, #token: 1907, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:05:34] Decode batch. #running-req: 1, #token: 1947, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:05:34] Decode batch. #running-req: 1, #token: 1987, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:05:35] Decode batch. #running-req: 1, #token: 2027, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:05:35] Decode batch. #running-req: 1, #token: 2067, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.56, #queue-req: 0, 
[2025-09-30 14:05:35] Decode batch. #running-req: 1, #token: 2107, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 2147, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 2187, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:05:36] Decode batch. #running-req: 1, #token: 2227, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:05:37] Decode batch. #running-req: 1, #token: 2267, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:05:37] Decode batch. #running-req: 1, #token: 2307, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:05:37] Decode batch. #running-req: 1, #token: 2347, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.71, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 2387, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 2427, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:38] Decode batch. #running-req: 1, #token: 2467, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:05:39] Decode batch. #running-req: 1, #token: 2507, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:05:39] Decode batch. #running-req: 1, #token: 2547, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.54, #queue-req: 0, 
[2025-09-30 14:05:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:40] Prefill batch. #new-seq: 1, #new-token: 757, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:40] Prefill batch. #new-seq: 1, #new-token: 688, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:40] Decode batch. #running-req: 1, #token: 859, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.46, #queue-req: 0, 
[2025-09-30 14:05:40] Decode batch. #running-req: 1, #token: 899, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:05:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:40] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:40] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:05:41] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:05:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:41] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:41] Prefill batch. #new-seq: 1, #new-token: 684, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:41] Decode batch. #running-req: 1, #token: 770, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.29, #queue-req: 0, 
[2025-09-30 14:05:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:42] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 757, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:42] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.99, #queue-req: 0, 
[2025-09-30 14:05:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 1018, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:43] Decode batch. #running-req: 1, #token: 528, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.17, #queue-req: 0, 
[2025-09-30 14:05:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:43] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:43] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.59, #queue-req: 0, 
[2025-09-30 14:05:44] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:05:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:44] Prefill batch. #new-seq: 1, #new-token: 573, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:44] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:45] Decode batch. #running-req: 1, #token: 431, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.50, #queue-req: 0, 
[2025-09-30 14:05:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:45] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:45] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:05:45] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:05:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:46] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:46] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:46] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.23, #queue-req: 0, 
[2025-09-30 14:05:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:46] Prefill batch. #new-seq: 1, #new-token: 713, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:46] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 667, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.69, #queue-req: 0, 
[2025-09-30 14:05:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:47] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.92, #queue-req: 0, 
[2025-09-30 14:05:47] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:05:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:48] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:48] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:48] Decode batch. #running-req: 1, #token: 549, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.76, #queue-req: 0, 
[2025-09-30 14:05:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:49] Prefill batch. #new-seq: 1, #new-token: 1108, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:49] Decode batch. #running-req: 1, #token: 1468, token usage: 0.02, cuda graph: True, gen throughput (token/s): 44.82, #queue-req: 0, 
[2025-09-30 14:05:49] Decode batch. #running-req: 1, #token: 1508, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:05:49] Decode batch. #running-req: 1, #token: 1548, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.92, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 1588, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.61, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 1628, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:05:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:50] Prefill batch. #new-seq: 1, #new-token: 1108, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:50] Decode batch. #running-req: 1, #token: 1434, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.67, #queue-req: 0, 
[2025-09-30 14:05:51] Decode batch. #running-req: 1, #token: 1474, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:05:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:05:51] Prefill batch. #new-seq: 1, #new-token: 983, #cached-token: 557, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:05:51] Decode batch. #running-req: 1, #token: 1576, token usage: 0.02, cuda graph: True, gen throughput (token/s): 109.21, #queue-req: 0, 
[2025-09-30 14:05:51] Decode batch. #running-req: 1, #token: 1616, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.61, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 1656, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 1696, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:05:52] Decode batch. #running-req: 1, #token: 1736, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:05:53] Decode batch. #running-req: 1, #token: 1776, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:05:53] Decode batch. #running-req: 1, #token: 1816, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.18, #queue-req: 0, 
[2025-09-30 14:05:53] Decode batch. #running-req: 1, #token: 1856, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.91, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 1896, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 1936, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:05:54] Decode batch. #running-req: 1, #token: 1976, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:05:55] Decode batch. #running-req: 1, #token: 2016, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:05:55] Decode batch. #running-req: 1, #token: 2056, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.70, #queue-req: 0, 
[2025-09-30 14:05:55] Decode batch. #running-req: 1, #token: 2096, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.33, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 2136, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 2176, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 2216, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:05:56] Decode batch. #running-req: 1, #token: 2256, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:05:57] Decode batch. #running-req: 1, #token: 2296, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:05:57] Decode batch. #running-req: 1, #token: 2336, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.87, #queue-req: 0, 
[2025-09-30 14:05:57] Decode batch. #running-req: 1, #token: 2376, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:58] Decode batch. #running-req: 1, #token: 2416, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:05:58] Decode batch. #running-req: 1, #token: 2456, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:05:58] Decode batch. #running-req: 1, #token: 2496, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 2536, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 2576, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.44, #queue-req: 0, 
[2025-09-30 14:05:59] Decode batch. #running-req: 1, #token: 2616, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:06:00] Decode batch. #running-req: 1, #token: 2656, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:06:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:00] Prefill batch. #new-seq: 1, #new-token: 849, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:01] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.81, #queue-req: 0, 
[2025-09-30 14:06:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:01] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 14:06:01] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:06:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:01] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:02] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:06:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:02] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 1007, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 634, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] Decode batch. #running-req: 1, #token: 805, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.44, #queue-req: 0, 
[2025-09-30 14:06:03] Decode batch. #running-req: 1, #token: 845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:06:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:03] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:03] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 14:06:04] Decode batch. #running-req: 1, #token: 410, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:04] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.53, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:04] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:05] Prefill batch. #new-seq: 1, #new-token: 1035, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:05] Prefill batch. #new-seq: 1, #new-token: 405, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:05] Decode batch. #running-req: 1, #token: 583, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.98, #queue-req: 0, 
[2025-09-30 14:06:06] Decode batch. #running-req: 1, #token: 623, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.07, #queue-req: 0, 
[2025-09-30 14:06:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:06] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:06] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.88, #queue-req: 0, 
[2025-09-30 14:06:06] Decode batch. #running-req: 1, #token: 356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:06:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:06] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:06:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:07] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:07] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:07] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.04, #queue-req: 0, 
[2025-09-30 14:06:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 475, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:08] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:08] Decode batch. #running-req: 1, #token: 987, token usage: 0.02, cuda graph: True, gen throughput (token/s): 44.57, #queue-req: 0, 
[2025-09-30 14:06:09] Decode batch. #running-req: 1, #token: 1027, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.41, #queue-req: 0, 
[2025-09-30 14:06:09] Decode batch. #running-req: 1, #token: 1067, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:06:09] Decode batch. #running-req: 1, #token: 1107, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 1147, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 1187, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:06:10] Decode batch. #running-req: 1, #token: 1227, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:06:11] Decode batch. #running-req: 1, #token: 1267, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:06:11] Decode batch. #running-req: 1, #token: 1307, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.48, #queue-req: 0, 
[2025-09-30 14:06:11] Decode batch. #running-req: 1, #token: 1347, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 14:06:11] Decode batch. #running-req: 1, #token: 1387, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 14:06:12] Decode batch. #running-req: 1, #token: 1427, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 14:06:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:12] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:12] Decode batch. #running-req: 1, #token: 979, token usage: 0.02, cuda graph: True, gen throughput (token/s): 115.31, #queue-req: 0, 
[2025-09-30 14:06:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:12] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:06:12] Prefill batch. #new-seq: 1, #new-token: 1581, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:13] Decode batch. #running-req: 1, #token: 1746, token usage: 0.03, cuda graph: True, gen throughput (token/s): 101.19, #queue-req: 0, 
[2025-09-30 14:06:13] Decode batch. #running-req: 1, #token: 1786, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:06:13] Decode batch. #running-req: 1, #token: 1826, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.01, #queue-req: 0, 
[2025-09-30 14:06:14] Decode batch. #running-req: 1, #token: 1866, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:06:14] Decode batch. #running-req: 1, #token: 1906, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:06:14] Decode batch. #running-req: 1, #token: 1946, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:06:15] Decode batch. #running-req: 1, #token: 1986, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:06:15] Decode batch. #running-req: 1, #token: 2026, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:06:15] Decode batch. #running-req: 1, #token: 2066, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.64, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 2106, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 2146, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:06:16] Decode batch. #running-req: 1, #token: 2186, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:06:17] Decode batch. #running-req: 1, #token: 2226, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:06:17] Decode batch. #running-req: 1, #token: 2266, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:06:17] Decode batch. #running-req: 1, #token: 2306, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 2346, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 2386, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 2426, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:06:18] Decode batch. #running-req: 1, #token: 2466, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:06:19] Decode batch. #running-req: 1, #token: 2506, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:06:19] Decode batch. #running-req: 1, #token: 2546, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:06:19] Decode batch. #running-req: 1, #token: 2586, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.27, #queue-req: 0, 
[2025-09-30 14:06:20] Decode batch. #running-req: 1, #token: 2626, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:06:20] Decode batch. #running-req: 1, #token: 2666, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:06:20] Decode batch. #running-req: 1, #token: 2706, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.97, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 2746, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 2786, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.92, #queue-req: 0, 
[2025-09-30 14:06:21] Decode batch. #running-req: 1, #token: 2826, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.82, #queue-req: 0, 
[2025-09-30 14:06:22] Decode batch. #running-req: 1, #token: 2866, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:06:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 899, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:23] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.59, #queue-req: 0, 
[2025-09-30 14:06:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:23] Decode batch. #running-req: 1, #token: 703, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.23, #queue-req: 0, 
[2025-09-30 14:06:23] Decode batch. #running-req: 1, #token: 743, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:06:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:23] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:24] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.09, #queue-req: 0, 
[2025-09-30 14:06:24] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:06:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:24] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:24] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.74, #queue-req: 0, 
[2025-09-30 14:06:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:24] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:25] Prefill batch. #new-seq: 1, #new-token: 1076, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:25] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.80, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 799, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.14, #queue-req: 0, 
[2025-09-30 14:06:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:26] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:06:26] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:06:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:27] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:27] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.27, #queue-req: 0, 
[2025-09-30 14:06:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:27] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:28] Prefill batch. #new-seq: 1, #new-token: 984, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:28] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:28] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.15, #queue-req: 0, 
[2025-09-30 14:06:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:28] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.22, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:06:29] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.07, #queue-req: 0, 
[2025-09-30 14:06:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:30] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:30] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:30] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.75, #queue-req: 0, 
[2025-09-30 14:06:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:31] Prefill batch. #new-seq: 1, #new-token: 719, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:31] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 540, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.00, #queue-req: 0, 
[2025-09-30 14:06:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:31] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:31] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.81, #queue-req: 0, 
[2025-09-30 14:06:32] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:06:32] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:06:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:33] Prefill batch. #new-seq: 1, #new-token: 841, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:33] Prefill batch. #new-seq: 1, #new-token: 531, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:33] Decode batch. #running-req: 1, #token: 732, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.95, #queue-req: 0, 
[2025-09-30 14:06:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:33] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:34] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:06:34] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:06:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:34] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:34] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:35] Prefill batch. #new-seq: 1, #new-token: 771, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:36] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 24.42, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.19, #queue-req: 0, 
[2025-09-30 14:06:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:36] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:06:36] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:06:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:37] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:37] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.72, #queue-req: 0, 
[2025-09-30 14:06:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:37] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:38] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:38] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:38] Decode batch. #running-req: 1, #token: 446, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.70, #queue-req: 0, 
[2025-09-30 14:06:38] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.96, #queue-req: 0, 
[2025-09-30 14:06:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:39] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:39] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:06:39] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:06:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:40] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:40] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.38, #queue-req: 0, 
[2025-09-30 14:06:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:40] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:41] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:41] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:41] Decode batch. #running-req: 1, #token: 459, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.69, #queue-req: 0, 
[2025-09-30 14:06:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:41] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.92, #queue-req: 0, 
[2025-09-30 14:06:41] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:41] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:06:42] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:06:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:42] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:42] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:42] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.54, #queue-req: 0, 
[2025-09-30 14:06:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:43] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:43] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:43] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.69, #queue-req: 0, 
[2025-09-30 14:06:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:43] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:43] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.88, #queue-req: 0, 
[2025-09-30 14:06:44] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:06:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:44] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:44] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:44] Decode batch. #running-req: 1, #token: 375, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.02, #queue-req: 0, 
[2025-09-30 14:06:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:45] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:45] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:45] Decode batch. #running-req: 1, #token: 390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.61, #queue-req: 0, 
[2025-09-30 14:06:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:46] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:46] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:06:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:46] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:46] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.80, #queue-req: 0, 
[2025-09-30 14:06:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:46] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:47] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:47] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:47] Decode batch. #running-req: 1, #token: 772, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.07, #queue-req: 0, 
[2025-09-30 14:06:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:47] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:47] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.68, #queue-req: 0, 
[2025-09-30 14:06:48] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:06:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:48] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:48] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.02, #queue-req: 0, 
[2025-09-30 14:06:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:48] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:49] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:49] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 674, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:50] Prefill batch. #new-seq: 1, #new-token: 1280, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:50] Prefill batch. #new-seq: 1, #new-token: 681, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:50] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 22.82, #queue-req: 0, 
[2025-09-30 14:06:50] Decode batch. #running-req: 1, #token: 893, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:06:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:50] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:50] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:06:51] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:06:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:51] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:51] Prefill batch. #new-seq: 1, #new-token: 677, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:51] Decode batch. #running-req: 1, #token: 772, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-09-30 14:06:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:52] Prefill batch. #new-seq: 1, #new-token: 1269, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:52] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:53] Decode batch. #running-req: 1, #token: 792, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.83, #queue-req: 0, 
[2025-09-30 14:06:53] Decode batch. #running-req: 1, #token: 832, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.95, #queue-req: 0, 
[2025-09-30 14:06:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:53] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:53] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.92, #queue-req: 0, 
[2025-09-30 14:06:54] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:06:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:54] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:54] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:54] Decode batch. #running-req: 1, #token: 671, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.24, #queue-req: 0, 
[2025-09-30 14:06:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:55] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:55] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 662, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:55] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.99, #queue-req: 0, 
[2025-09-30 14:06:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:56] Prefill batch. #new-seq: 1, #new-token: 1230, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:56] Prefill batch. #new-seq: 1, #new-token: 639, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:56] Decode batch. #running-req: 1, #token: 821, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.91, #queue-req: 0, 
[2025-09-30 14:06:57] Decode batch. #running-req: 1, #token: 861, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 14:06:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:57] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:57] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.79, #queue-req: 0, 
[2025-09-30 14:06:57] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:06:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:58] Prefill batch. #new-seq: 1, #new-token: 1327, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:58] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:59] Decode batch. #running-req: 1, #token: 864, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.11, #queue-req: 0, 
[2025-09-30 14:06:59] Decode batch. #running-req: 1, #token: 904, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 14:06:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:06:59] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:06:59] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 14:06:59] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:07:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:00] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:00] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.11, #queue-req: 0, 
[2025-09-30 14:07:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:00] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:01] Prefill batch. #new-seq: 1, #new-token: 1704, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:01] Decode batch. #running-req: 1, #token: 2060, token usage: 0.03, cuda graph: True, gen throughput (token/s): 30.50, #queue-req: 0, 
[2025-09-30 14:07:01] Decode batch. #running-req: 1, #token: 2100, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:07:02] Decode batch. #running-req: 1, #token: 2140, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:07:02] Decode batch. #running-req: 1, #token: 2180, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:07:02] Decode batch. #running-req: 1, #token: 2220, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:07:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:02] Prefill batch. #new-seq: 1, #new-token: 1704, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:03] Decode batch. #running-req: 1, #token: 2062, token usage: 0.03, cuda graph: True, gen throughput (token/s): 98.65, #queue-req: 0, 
[2025-09-30 14:07:03] Decode batch. #running-req: 1, #token: 2102, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.33, #queue-req: 0, 
[2025-09-30 14:07:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:03] Prefill batch. #new-seq: 1, #new-token: 1293, #cached-token: 203, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:04] Decode batch. #running-req: 1, #token: 1509, token usage: 0.02, cuda graph: True, gen throughput (token/s): 104.83, #queue-req: 0, 
[2025-09-30 14:07:04] Decode batch. #running-req: 1, #token: 1549, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 14:07:04] Decode batch. #running-req: 1, #token: 1589, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.60, #queue-req: 0, 
[2025-09-30 14:07:04] Decode batch. #running-req: 1, #token: 1629, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:07:05] Decode batch. #running-req: 1, #token: 1669, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:07:05] Decode batch. #running-req: 1, #token: 1709, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:07:05] Decode batch. #running-req: 1, #token: 1749, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:07:06] Decode batch. #running-req: 1, #token: 1789, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:07:06] Decode batch. #running-req: 1, #token: 1829, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.01, #queue-req: 0, 
[2025-09-30 14:07:06] Decode batch. #running-req: 1, #token: 1869, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:07:07] Decode batch. #running-req: 1, #token: 1909, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:07:07] Decode batch. #running-req: 1, #token: 1949, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:07:07] Decode batch. #running-req: 1, #token: 1989, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:07:08] Decode batch. #running-req: 1, #token: 2029, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:07:08] Decode batch. #running-req: 1, #token: 2069, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.51, #queue-req: 0, 
[2025-09-30 14:07:08] Decode batch. #running-req: 1, #token: 2109, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:07:09] Decode batch. #running-req: 1, #token: 2149, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:07:09] Decode batch. #running-req: 1, #token: 2189, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:07:09] Decode batch. #running-req: 1, #token: 2229, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:07:09] Decode batch. #running-req: 1, #token: 2269, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:07:10] Decode batch. #running-req: 1, #token: 2309, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:07:10] Decode batch. #running-req: 1, #token: 2349, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:07:10] Decode batch. #running-req: 1, #token: 2389, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:07:11] Decode batch. #running-req: 1, #token: 2429, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:07:11] Decode batch. #running-req: 1, #token: 2469, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:07:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:12] Prefill batch. #new-seq: 1, #new-token: 1226, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:12] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:12] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.85, #queue-req: 0, 
[2025-09-30 14:07:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:12] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:13] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:07:13] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:07:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:13] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:13] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:13] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.63, #queue-req: 0, 
[2025-09-30 14:07:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:14] Prefill batch. #new-seq: 1, #new-token: 1221, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:14] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:15] Decode batch. #running-req: 1, #token: 883, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.49, #queue-req: 0, 
[2025-09-30 14:07:15] Decode batch. #running-req: 1, #token: 923, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:07:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:15] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:15] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.23, #queue-req: 0, 
[2025-09-30 14:07:15] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:07:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:16] Prefill batch. #new-seq: 1, #new-token: 1362, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:16] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:16] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:16] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.23, #queue-req: 0, 
[2025-09-30 14:07:17] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:07:17] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:07:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:17] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:17] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:18] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:18] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.46, #queue-req: 0, 
[2025-09-30 14:07:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:18] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 746, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:19] Prefill batch. #new-seq: 1, #new-token: 1384, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.97, #queue-req: 0, 
[2025-09-30 14:07:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:19] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:19] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:19] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.43, #queue-req: 0, 
[2025-09-30 14:07:20] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:07:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:20] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:20] Decode batch. #running-req: 1, #token: 106, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.66, #queue-req: 0, 
[2025-09-30 14:07:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:20] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:21] Prefill batch. #new-seq: 1, #new-token: 1470, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:21] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:21] Decode batch. #running-req: 1, #token: 939, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.45, #queue-req: 0, 
[2025-09-30 14:07:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:21] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:22] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 14:07:22] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:07:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:23] Prefill batch. #new-seq: 1, #new-token: 1354, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:23] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:23] Decode batch. #running-req: 1, #token: 777, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.52, #queue-req: 0, 
[2025-09-30 14:07:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:23] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:23] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.58, #queue-req: 0, 
[2025-09-30 14:07:23] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:07:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:24] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:24] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.43, #queue-req: 0, 
[2025-09-30 14:07:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:24] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:25] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:25] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 175, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:25] Decode batch. #running-req: 1, #token: 781, token usage: 0.01, cuda graph: True, gen throughput (token/s): 29.92, #queue-req: 0, 
[2025-09-30 14:07:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:25] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:25] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.45, #queue-req: 0, 
[2025-09-30 14:07:26] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:07:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:27] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:27] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.95, #queue-req: 0, 
[2025-09-30 14:07:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:27] Prefill batch. #new-seq: 1, #new-token: 3164, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:27] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:27] Decode batch. #running-req: 1, #token: 857, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.46, #queue-req: 0, 
[2025-09-30 14:07:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:28] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:28] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.64, #queue-req: 0, 
[2025-09-30 14:07:28] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:07:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:28] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:28] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.81, #queue-req: 0, 
[2025-09-30 14:07:28] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:29] Prefill batch. #new-seq: 1, #new-token: 1232, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:29] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:29] Decode batch. #running-req: 1, #token: 737, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.65, #queue-req: 0, 
[2025-09-30 14:07:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:29] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.14, #queue-req: 0, 
[2025-09-30 14:07:29] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:29] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:07:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:30] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:30] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:30] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.38, #queue-req: 0, 
[2025-09-30 14:07:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:30] Prefill batch. #new-seq: 1, #new-token: 1079, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:30] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:30] Decode batch. #running-req: 1, #token: 705, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.46, #queue-req: 0, 
[2025-09-30 14:07:31] Decode batch. #running-req: 1, #token: 745, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:07:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:31] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:31] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:07:31] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:07:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:31] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:31] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:32] Decode batch. #running-req: 1, #token: 611, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.77, #queue-req: 0, 
[2025-09-30 14:07:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:32] Prefill batch. #new-seq: 1, #new-token: 1015, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:32] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:32] Decode batch. #running-req: 1, #token: 681, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.07, #queue-req: 0, 
[2025-09-30 14:07:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:32] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:32] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.69, #queue-req: 0, 
[2025-09-30 14:07:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:32] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:33] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:33] Decode batch. #running-req: 1, #token: 582, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.15, #queue-req: 0, 
[2025-09-30 14:07:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:33] Prefill batch. #new-seq: 1, #new-token: 1081, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:33] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:33] Decode batch. #running-req: 1, #token: 790, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.91, #queue-req: 0, 
[2025-09-30 14:07:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:33] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:33] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 14:07:34] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:07:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:34] Prefill batch. #new-seq: 1, #new-token: 1040, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:34] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:34] Decode batch. #running-req: 1, #token: 676, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.03, #queue-req: 0, 
[2025-09-30 14:07:34] Decode batch. #running-req: 1, #token: 716, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.63, #queue-req: 0, 
[2025-09-30 14:07:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:35] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:35] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.73, #queue-req: 0, 
[2025-09-30 14:07:35] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:07:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:35] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:35] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:36] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.89, #queue-req: 0, 
[2025-09-30 14:07:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:36] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:36] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:36] Decode batch. #running-req: 1, #token: 652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.40, #queue-req: 0, 
[2025-09-30 14:07:36] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.68, #queue-req: 0, 
[2025-09-30 14:07:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:36] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:37] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.95, #queue-req: 0, 
[2025-09-30 14:07:37] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:07:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:37] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:37] Prefill batch. #new-seq: 1, #new-token: 464, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:37] Decode batch. #running-req: 1, #token: 557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.84, #queue-req: 0, 
[2025-09-30 14:07:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:37] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:37] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 534, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:38] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:38] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.80, #queue-req: 0, 
[2025-09-30 14:07:38] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:38] Decode batch. #running-req: 1, #token: 577, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.80, #queue-req: 0, 
[2025-09-30 14:07:38] Decode batch. #running-req: 1, #token: 617, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:07:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:38] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:39] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.00, #queue-req: 0, 
[2025-09-30 14:07:39] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:07:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:39] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:39] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:39] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.96, #queue-req: 0, 
[2025-09-30 14:07:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:40] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:40] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:40] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.98, #queue-req: 0, 
[2025-09-30 14:07:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:40] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:40] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.76, #queue-req: 0, 
[2025-09-30 14:07:40] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:07:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:41] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:41] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.29, #queue-req: 0, 
[2025-09-30 14:07:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:41] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:41] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:41] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:41] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 89.12, #queue-req: 0, 
[2025-09-30 14:07:42] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.53, #queue-req: 0, 
[2025-09-30 14:07:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:42] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:42] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.12, #queue-req: 0, 
[2025-09-30 14:07:42] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:07:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:42] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:42] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:43] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.10, #queue-req: 0, 
[2025-09-30 14:07:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:43] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:43] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:43] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.91, #queue-req: 0, 
[2025-09-30 14:07:43] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.32, #queue-req: 0, 
[2025-09-30 14:07:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:43] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:44] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:07:44] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:07:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:44] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:44] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:44] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.60, #queue-req: 0, 
[2025-09-30 14:07:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:44] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:45] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 14:07:45] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:07:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:45] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:45] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.21, #queue-req: 0, 
[2025-09-30 14:07:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:45] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:46] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:46] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.85, #queue-req: 0, 
[2025-09-30 14:07:46] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:46] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.24, #queue-req: 0, 
[2025-09-30 14:07:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:46] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:46] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.70, #queue-req: 0, 
[2025-09-30 14:07:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:46] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:47] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:47] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.03, #queue-req: 0, 
[2025-09-30 14:07:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:47] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:47] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:47] Decode batch. #running-req: 1, #token: 448, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.71, #queue-req: 0, 
[2025-09-30 14:07:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:47] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:47] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.03, #queue-req: 0, 
[2025-09-30 14:07:48] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:07:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:48] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:48] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:48] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.77, #queue-req: 0, 
[2025-09-30 14:07:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:48] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:48] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:48] Decode batch. #running-req: 1, #token: 528, token usage: 0.01, cuda graph: True, gen throughput (token/s): 88.76, #queue-req: 0, 
[2025-09-30 14:07:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:49] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:49] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.59, #queue-req: 0, 
[2025-09-30 14:07:49] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:07:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:49] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:49] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:50] Decode batch. #running-req: 1, #token: 435, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.47, #queue-req: 0, 
[2025-09-30 14:07:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:50] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:50] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.91, #queue-req: 0, 
[2025-09-30 14:07:50] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:07:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:51] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.47, #queue-req: 0, 
[2025-09-30 14:07:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:51] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:51] Prefill batch. #new-seq: 1, #new-token: 1237, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:51] Decode batch. #running-req: 1, #token: 1590, token usage: 0.02, cuda graph: True, gen throughput (token/s): 79.43, #queue-req: 0, 
[2025-09-30 14:07:51] Decode batch. #running-req: 1, #token: 1630, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:07:52] Decode batch. #running-req: 1, #token: 1670, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:07:52] Decode batch. #running-req: 1, #token: 1710, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:07:52] Decode batch. #running-req: 1, #token: 1750, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:07:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:52] Prefill batch. #new-seq: 1, #new-token: 1237, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:53] Decode batch. #running-req: 1, #token: 1586, token usage: 0.02, cuda graph: True, gen throughput (token/s): 105.38, #queue-req: 0, 
[2025-09-30 14:07:53] Decode batch. #running-req: 1, #token: 1626, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:07:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:53] Prefill batch. #new-seq: 1, #new-token: 551, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:53] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:53] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 89.40, #queue-req: 0, 
[2025-09-30 14:07:54] Decode batch. #running-req: 1, #token: 526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.74, #queue-req: 0, 
[2025-09-30 14:07:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:54] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:54] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.52, #queue-req: 0, 
[2025-09-30 14:07:54] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:07:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:54] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:55] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:55] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:55] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.51, #queue-req: 0, 
[2025-09-30 14:07:55] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:07:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:55] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.28, #queue-req: 0, 
[2025-09-30 14:07:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:56] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:56] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:56] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.16, #queue-req: 0, 
[2025-09-30 14:07:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 348, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:56] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:56] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:56] Decode batch. #running-req: 1, #token: 674, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.03, #queue-req: 0, 
[2025-09-30 14:07:57] Decode batch. #running-req: 1, #token: 714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 14:07:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:57] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:57] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.49, #queue-req: 0, 
[2025-09-30 14:07:57] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:07:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:57] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:57] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:58] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.29, #queue-req: 0, 
[2025-09-30 14:07:58] Prefill batch. #new-seq: 1, #new-token: 924, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:58] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:58] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.52, #queue-req: 0, 
[2025-09-30 14:07:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:58] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:58] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.82, #queue-req: 0, 
[2025-09-30 14:07:59] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:07:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:59] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:59] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:07:59] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.21, #queue-req: 0, 
[2025-09-30 14:07:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:07:59] Prefill batch. #new-seq: 1, #new-token: 897, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:00] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:00] Decode batch. #running-req: 1, #token: 649, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.16, #queue-req: 0, 
[2025-09-30 14:08:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:00] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:00] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:08:00] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:08:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:00] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:00] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:01] Prefill batch. #new-seq: 1, #new-token: 892, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:01] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:01] Decode batch. #running-req: 1, #token: 596, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.34, #queue-req: 0, 
[2025-09-30 14:08:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:01] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:01] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.48, #queue-req: 0, 
[2025-09-30 14:08:01] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:08:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:02] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:02] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 98.30, #queue-req: 0, 
[2025-09-30 14:08:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:02] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:02] Prefill batch. #new-seq: 1, #new-token: 875, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:02] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:02] Decode batch. #running-req: 1, #token: 631, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.41, #queue-req: 0, 
[2025-09-30 14:08:03] Decode batch. #running-req: 1, #token: 671, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.81, #queue-req: 0, 
[2025-09-30 14:08:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:03] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:03] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.24, #queue-req: 0, 
[2025-09-30 14:08:03] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:08:04] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:08:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:04] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:04] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:04] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.91, #queue-req: 0, 
[2025-09-30 14:08:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:04] Prefill batch. #new-seq: 1, #new-token: 800, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:04] Prefill batch. #new-seq: 1, #new-token: 431, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:05] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.85, #queue-req: 0, 
[2025-09-30 14:08:05] Decode batch. #running-req: 1, #token: 656, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.83, #queue-req: 0, 
[2025-09-30 14:08:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:05] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:05] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:08:05] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:08:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:06] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:06] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:06] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.90, #queue-req: 0, 
[2025-09-30 14:08:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:06] Prefill batch. #new-seq: 1, #new-token: 920, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:06] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:06] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.25, #queue-req: 0, 
[2025-09-30 14:08:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:07] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.93, #queue-req: 0, 
[2025-09-30 14:08:07] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:07] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:08:07] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:08:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:07] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:07] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:08] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:08] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.42, #queue-req: 0, 
[2025-09-30 14:08:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:08] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 644, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:08] Prefill batch. #new-seq: 1, #new-token: 1298, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:08] Prefill batch. #new-seq: 1, #new-token: 726, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:08] Decode batch. #running-req: 1, #token: 896, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.53, #queue-req: 0, 
[2025-09-30 14:08:09] Decode batch. #running-req: 1, #token: 936, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:08:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:09] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:09] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 14:08:09] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:08:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:10] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:10] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.61, #queue-req: 0, 
[2025-09-30 14:08:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:10] Prefill batch. #new-seq: 1, #new-token: 722, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:10] Decode batch. #running-req: 1, #token: 828, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.03, #queue-req: 0, 
[2025-09-30 14:08:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:10] Prefill batch. #new-seq: 1, #new-token: 1344, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:10] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:11] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.32, #queue-req: 0, 
[2025-09-30 14:08:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:11] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:11] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.63, #queue-req: 0, 
[2025-09-30 14:08:11] Decode batch. #running-req: 1, #token: 375, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.09, #queue-req: 0, 
[2025-09-30 14:08:11] Decode batch. #running-req: 1, #token: 415, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.94, #queue-req: 0, 
[2025-09-30 14:08:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:12] Prefill batch. #new-seq: 1, #new-token: 1261, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:12] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:12] Decode batch. #running-req: 1, #token: 840, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.71, #queue-req: 0, 
[2025-09-30 14:08:12] Decode batch. #running-req: 1, #token: 880, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 14:08:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:12] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:13] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.31, #queue-req: 0, 
[2025-09-30 14:08:13] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:08:13] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.12, #queue-req: 0, 
[2025-09-30 14:08:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:13] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:14] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:14] Decode batch. #running-req: 1, #token: 729, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.00, #queue-req: 0, 
[2025-09-30 14:08:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:14] Prefill batch. #new-seq: 1, #new-token: 1197, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:14] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 178, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:14] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.24, #queue-req: 0, 
[2025-09-30 14:08:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:14] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:15] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.54, #queue-req: 0, 
[2025-09-30 14:08:15] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:08:15] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:08:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:15] Prefill batch. #new-seq: 1, #new-token: 3117, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:16] Decode batch. #running-req: 1, #token: 3484, token usage: 0.05, cuda graph: True, gen throughput (token/s): 66.10, #queue-req: 0, 
[2025-09-30 14:08:16] Decode batch. #running-req: 1, #token: 3524, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:08:16] Decode batch. #running-req: 1, #token: 3564, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:08:17] Decode batch. #running-req: 1, #token: 3604, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:08:17] Decode batch. #running-req: 1, #token: 3644, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.60, #queue-req: 0, 
[2025-09-30 14:08:17] Decode batch. #running-req: 1, #token: 3684, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:08:18] Decode batch. #running-req: 1, #token: 3724, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.60, #queue-req: 0, 
[2025-09-30 14:08:18] Decode batch. #running-req: 1, #token: 3764, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.66, #queue-req: 0, 
[2025-09-30 14:08:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:18] Prefill batch. #new-seq: 1, #new-token: 3117, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:18] Decode batch. #running-req: 1, #token: 3475, token usage: 0.05, cuda graph: True, gen throughput (token/s): 81.86, #queue-req: 0, 
[2025-09-30 14:08:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:19] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:19] Decode batch. #running-req: 1, #token: 573, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.31, #queue-req: 0, 
[2025-09-30 14:08:19] Decode batch. #running-req: 1, #token: 613, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.67, #queue-req: 0, 
[2025-09-30 14:08:19] Decode batch. #running-req: 1, #token: 653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.56, #queue-req: 0, 
[2025-09-30 14:08:20] Decode batch. #running-req: 1, #token: 693, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.42, #queue-req: 0, 
[2025-09-30 14:08:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:20] Prefill batch. #new-seq: 1, #new-token: 1043, #cached-token: 93, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:20] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:20] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.36, #queue-req: 0, 
[2025-09-30 14:08:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:20] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:21] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.92, #queue-req: 0, 
[2025-09-30 14:08:21] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:08:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:21] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:21] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:21] Decode batch. #running-req: 1, #token: 579, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.77, #queue-req: 0, 
[2025-09-30 14:08:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:22] Prefill batch. #new-seq: 1, #new-token: 773, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:22] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:22] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.02, #queue-req: 0, 
[2025-09-30 14:08:22] Decode batch. #running-req: 1, #token: 497, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.94, #queue-req: 0, 
[2025-09-30 14:08:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:22] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:22] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.52, #queue-req: 0, 
[2025-09-30 14:08:23] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:08:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:23] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:23] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:23] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.72, #queue-req: 0, 
[2025-09-30 14:08:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:23] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:23] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 345, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:24] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.82, #queue-req: 0, 
[2025-09-30 14:08:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:24] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:24] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:24] Decode batch. #running-req: 1, #token: 426, token usage: 0.01, cuda graph: True, gen throughput (token/s): 88.58, #queue-req: 0, 
[2025-09-30 14:08:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:24] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:24] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:08:25] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:08:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:25] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:25] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:25] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 87.78, #queue-req: 0, 
[2025-09-30 14:08:25] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:25] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:26] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:26] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.40, #queue-req: 0, 
[2025-09-30 14:08:26] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:08:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:26] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:26] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:26] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.36, #queue-req: 0, 
[2025-09-30 14:08:27] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0, 
[2025-09-30 14:08:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:27] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:27] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.20, #queue-req: 0, 
[2025-09-30 14:08:27] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:08:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:27] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:28] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:28] Decode batch. #running-req: 1, #token: 212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 108.15, #queue-req: 0, 
[2025-09-30 14:08:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:28] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 191, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:28] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:28] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:28] Decode batch. #running-req: 1, #token: 729, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.80, #queue-req: 0, 
[2025-09-30 14:08:29] Decode batch. #running-req: 1, #token: 769, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:08:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:29] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:29] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:08:29] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:08:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:29] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:30] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:30] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.08, #queue-req: 0, 
[2025-09-30 14:08:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:30] Prefill batch. #new-seq: 1, #new-token: 907, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:30] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:30] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.07, #queue-req: 0, 
[2025-09-30 14:08:31] Decode batch. #running-req: 1, #token: 579, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.15, #queue-req: 0, 
[2025-09-30 14:08:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:31] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:31] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:08:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:31] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:31] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:31] Decode batch. #running-req: 1, #token: 425, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.32, #queue-req: 0, 
[2025-09-30 14:08:32] Decode batch. #running-req: 1, #token: 465, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.17, #queue-req: 0, 
[2025-09-30 14:08:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:32] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:32] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:08:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:32] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:32] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 85.44, #queue-req: 0, 
[2025-09-30 14:08:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:32] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:33] Decode batch. #running-req: 1, #token: 559, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.33, #queue-req: 0, 
[2025-09-30 14:08:33] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 14:08:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:33] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:33] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:08:34] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:08:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:34] Prefill batch. #new-seq: 1, #new-token: 2643, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:34] Decode batch. #running-req: 1, #token: 3016, token usage: 0.05, cuda graph: True, gen throughput (token/s): 65.11, #queue-req: 0, 
[2025-09-30 14:08:35] Decode batch. #running-req: 1, #token: 3056, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 14:08:35] Decode batch. #running-req: 1, #token: 3096, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:08:35] Decode batch. #running-req: 1, #token: 3136, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:08:36] Decode batch. #running-req: 1, #token: 3176, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:08:36] Decode batch. #running-req: 1, #token: 3216, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:08:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:36] Prefill batch. #new-seq: 1, #new-token: 2643, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:36] Decode batch. #running-req: 1, #token: 2998, token usage: 0.05, cuda graph: True, gen throughput (token/s): 87.37, #queue-req: 0, 
[2025-09-30 14:08:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:36] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:37] Decode batch. #running-req: 1, #token: 563, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.02, #queue-req: 0, 
[2025-09-30 14:08:37] Decode batch. #running-req: 1, #token: 603, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.75, #queue-req: 0, 
[2025-09-30 14:08:37] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.62, #queue-req: 0, 
[2025-09-30 14:08:38] Decode batch. #running-req: 1, #token: 683, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.48, #queue-req: 0, 
[2025-09-30 14:08:38] Decode batch. #running-req: 1, #token: 723, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.30, #queue-req: 0, 
[2025-09-30 14:08:38] Decode batch. #running-req: 1, #token: 763, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.24, #queue-req: 0, 
[2025-09-30 14:08:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:38] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:38] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:39] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.45, #queue-req: 0, 
[2025-09-30 14:08:39] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:39] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.49, #queue-req: 0, 
[2025-09-30 14:08:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:39] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:39] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.37, #queue-req: 0, 
[2025-09-30 14:08:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:39] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:40] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:40] Decode batch. #running-req: 1, #token: 210, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.88, #queue-req: 0, 
[2025-09-30 14:08:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:40] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:40] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:40] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.98, #queue-req: 0, 
[2025-09-30 14:08:41] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:08:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:41] Prefill batch. #new-seq: 1, #new-token: 634, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:41] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:41] Decode batch. #running-req: 1, #token: 763, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.61, #queue-req: 0, 
[2025-09-30 14:08:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:41] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:41] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.06, #queue-req: 0, 
[2025-09-30 14:08:42] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:08:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:42] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:42] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:42] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.72, #queue-req: 0, 
[2025-09-30 14:08:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:42] Prefill batch. #new-seq: 1, #new-token: 1093, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:42] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:43] Decode batch. #running-req: 1, #token: 728, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.98, #queue-req: 0, 
[2025-09-30 14:08:43] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 14:08:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:43] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:43] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.38, #queue-req: 0, 
[2025-09-30 14:08:44] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:08:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:44] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:44] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:44] Decode batch. #running-req: 1, #token: 583, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.33, #queue-req: 0, 
[2025-09-30 14:08:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:44] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:44] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 572, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:44] Decode batch. #running-req: 1, #token: 586, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.68, #queue-req: 0, 
[2025-09-30 14:08:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:45] Prefill batch. #new-seq: 1, #new-token: 1048, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:45] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:45] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.03, #queue-req: 0, 
[2025-09-30 14:08:45] Decode batch. #running-req: 1, #token: 775, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:08:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:45] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:46] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:08:46] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:08:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:46] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:46] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:46] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.31, #queue-req: 0, 
[2025-09-30 14:08:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:47] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:47] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 85.05, #queue-req: 0, 
[2025-09-30 14:08:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 618, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:47] Prefill batch. #new-seq: 1, #new-token: 1066, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:47] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:47] Decode batch. #running-req: 1, #token: 696, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.45, #queue-req: 0, 
[2025-09-30 14:08:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:47] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:48] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:08:48] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:08:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:48] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:48] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:48] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.95, #queue-req: 0, 
[2025-09-30 14:08:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:49] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:49] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:49] Decode batch. #running-req: 1, #token: 403, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.01, #queue-req: 0, 
[2025-09-30 14:08:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:49] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:49] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.05, #queue-req: 0, 
[2025-09-30 14:08:50] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:08:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:50] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:50] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.45, #queue-req: 0, 
[2025-09-30 14:08:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:50] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:50] Prefill batch. #new-seq: 1, #new-token: 443, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:51] Decode batch. #running-req: 1, #token: 638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.25, #queue-req: 0, 
[2025-09-30 14:08:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:51] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:51] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.42, #queue-req: 0, 
[2025-09-30 14:08:51] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:08:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:51] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.12, #queue-req: 0, 
[2025-09-30 14:08:52] Prefill batch. #new-seq: 1, #new-token: 925, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:52] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:52] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.89, #queue-req: 0, 
[2025-09-30 14:08:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:52] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:52] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.53, #queue-req: 0, 
[2025-09-30 14:08:53] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 14:08:53] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:08:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:53] Prefill batch. #new-seq: 1, #new-token: 1189, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:53] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:53] Decode batch. #running-req: 1, #token: 911, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.47, #queue-req: 0, 
[2025-09-30 14:08:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:53] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:54] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 14:08:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:54] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:54] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:54] Decode batch. #running-req: 1, #token: 787, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.29, #queue-req: 0, 
[2025-09-30 14:08:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:54] Prefill batch. #new-seq: 1, #new-token: 1312, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:54] Prefill batch. #new-seq: 1, #new-token: 608, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:55] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.08, #queue-req: 0, 
[2025-09-30 14:08:55] Decode batch. #running-req: 1, #token: 829, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:08:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:55] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:55] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:08:56] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:08:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:56] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:56] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:56] Decode batch. #running-req: 1, #token: 688, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.55, #queue-req: 0, 
[2025-09-30 14:08:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:56] Prefill batch. #new-seq: 1, #new-token: 1117, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:56] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:57] Decode batch. #running-req: 1, #token: 772, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.50, #queue-req: 0, 
[2025-09-30 14:08:57] Decode batch. #running-req: 1, #token: 812, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:08:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:57] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:57] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.41, #queue-req: 0, 
[2025-09-30 14:08:58] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:08:58] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:08:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:58] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:58] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.63, #queue-req: 0, 
[2025-09-30 14:08:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:58] Prefill batch. #new-seq: 1, #new-token: 511, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:59] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.36, #queue-req: 0, 
[2025-09-30 14:08:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:59] Prefill batch. #new-seq: 1, #new-token: 983, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:59] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:08:59] Decode batch. #running-req: 1, #token: 670, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.33, #queue-req: 0, 
[2025-09-30 14:08:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:08:59] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:00] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.01, #queue-req: 0, 
[2025-09-30 14:09:00] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:09:00] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:09:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:00] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:00] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:01] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.25, #queue-req: 0, 
[2025-09-30 14:09:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:01] Prefill batch. #new-seq: 1, #new-token: 907, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:01] Prefill batch. #new-seq: 1, #new-token: 436, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:01] Decode batch. #running-req: 1, #token: 618, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.18, #queue-req: 0, 
[2025-09-30 14:09:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:01] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:01] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.77, #queue-req: 0, 
[2025-09-30 14:09:02] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:09:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:02] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:02] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.43, #queue-req: 0, 
[2025-09-30 14:09:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:02] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:03] Prefill batch. #new-seq: 1, #new-token: 756, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:03] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:03] Decode batch. #running-req: 1, #token: 509, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.62, #queue-req: 0, 
[2025-09-30 14:09:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:03] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:03] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.89, #queue-req: 0, 
[2025-09-30 14:09:03] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:09:04] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:09:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:04] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:04] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:04] Decode batch. #running-req: 1, #token: 413, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.68, #queue-req: 0, 
[2025-09-30 14:09:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:04] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:05] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 394, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:05] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:05] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:05] Decode batch. #running-req: 1, #token: 422, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.22, #queue-req: 0, 
[2025-09-30 14:09:05] Decode batch. #running-req: 1, #token: 462, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.09, #queue-req: 0, 
[2025-09-30 14:09:05] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.99, #queue-req: 0, 
[2025-09-30 14:09:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:06] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:06] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.33, #queue-req: 0, 
[2025-09-30 14:09:06] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:09:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:06] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:06] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:07] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.52, #queue-req: 0, 
[2025-09-30 14:09:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:07] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:07] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:07] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:07] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 75.56, #queue-req: 0, 
[2025-09-30 14:09:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:07] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:07] Prefill batch. #new-seq: 1, #new-token: 425, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:08] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.91, #queue-req: 0, 
[2025-09-30 14:09:08] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.09, #queue-req: 0, 
[2025-09-30 14:09:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:08] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:08] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:09:08] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:09:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:09] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:09] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:09] Decode batch. #running-req: 1, #token: 478, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.89, #queue-req: 0, 
[2025-09-30 14:09:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:09] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:09] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:09] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.29, #queue-req: 0, 
[2025-09-30 14:09:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:10] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:10] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 14:09:10] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:09:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:10] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:10] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:11] Decode batch. #running-req: 1, #token: 164, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.37, #queue-req: 0, 
[2025-09-30 14:09:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:11] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:11] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:11] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.40, #queue-req: 0, 
[2025-09-30 14:09:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:11] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:11] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.58, #queue-req: 0, 
[2025-09-30 14:09:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:12] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:12] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:12] Decode batch. #running-req: 1, #token: 526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.61, #queue-req: 0, 
[2025-09-30 14:09:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:12] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:12] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.00, #queue-req: 0, 
[2025-09-30 14:09:13] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:09:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:13] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:13] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:13] Decode batch. #running-req: 1, #token: 433, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.52, #queue-req: 0, 
[2025-09-30 14:09:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:13] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:13] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:14] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.29, #queue-req: 0, 
[2025-09-30 14:09:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:14] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:14] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.39, #queue-req: 0, 
[2025-09-30 14:09:14] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:09:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:14] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:15] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:15] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.51, #queue-req: 0, 
[2025-09-30 14:09:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:15] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:15] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:15] Decode batch. #running-req: 1, #token: 438, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.81, #queue-req: 0, 
[2025-09-30 14:09:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:16] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:16] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 14:09:16] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:09:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:16] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:16] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 87.13, #queue-req: 0, 
[2025-09-30 14:09:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:16] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:17] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:17] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:17] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.95, #queue-req: 0, 
[2025-09-30 14:09:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:17] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:17] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.13, #queue-req: 0, 
[2025-09-30 14:09:18] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:09:18] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:09:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:18] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:18] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:18] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:18] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.04, #queue-req: 0, 
[2025-09-30 14:09:19] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 14:09:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:19] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:19] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:19] Decode batch. #running-req: 1, #token: 177, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.05, #queue-req: 0, 
[2025-09-30 14:09:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:19] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:20] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:20] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.57, #queue-req: 0, 
[2025-09-30 14:09:20] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:20] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.76, #queue-req: 0, 
[2025-09-30 14:09:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:20] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:20] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:20] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.40, #queue-req: 0, 
[2025-09-30 14:09:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:21] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:21] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 215, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:21] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.84, #queue-req: 0, 
[2025-09-30 14:09:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:21] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:21] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:22] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:22] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.37, #queue-req: 0, 
[2025-09-30 14:09:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:22] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:22] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.35, #queue-req: 0, 
[2025-09-30 14:09:22] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:22] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:22] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:23] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.86, #queue-req: 0, 
[2025-09-30 14:09:23] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.46, #queue-req: 0, 
[2025-09-30 14:09:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:23] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:23] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 14:09:23] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:09:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:24] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:24] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:24] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:24] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:24] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.22, #queue-req: 0, 
[2025-09-30 14:09:24] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.27, #queue-req: 0, 
[2025-09-30 14:09:25] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.17, #queue-req: 0, 
[2025-09-30 14:09:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:25] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:25] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.52, #queue-req: 0, 
[2025-09-30 14:09:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:25] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:25] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:26] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:26] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:26] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.76, #queue-req: 0, 
[2025-09-30 14:09:26] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.63, #queue-req: 0, 
[2025-09-30 14:09:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:26] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:26] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.58, #queue-req: 0, 
[2025-09-30 14:09:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:27] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:27] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.12, #queue-req: 0, 
[2025-09-30 14:09:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:27] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:27] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:27] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:27] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.50, #queue-req: 0, 
[2025-09-30 14:09:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:28] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:28] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:09:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:28] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:28] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:28] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 85.02, #queue-req: 0, 
[2025-09-30 14:09:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:28] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:28] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 14:09:29] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:09:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:29] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:29] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:29] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.45, #queue-req: 0, 
[2025-09-30 14:09:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:30] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:30] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.89, #queue-req: 0, 
[2025-09-30 14:09:30] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 14:09:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:30] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:30] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.23, #queue-req: 0, 
[2025-09-30 14:09:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:30] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:31] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:31] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:31] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.48, #queue-req: 0, 
[2025-09-30 14:09:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:31] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:31] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:09:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:32] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:32] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.69, #queue-req: 0, 
[2025-09-30 14:09:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:32] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:32] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 155, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:32] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.91, #queue-req: 0, 
[2025-09-30 14:09:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:33] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:33] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:09:33] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.77, #queue-req: 0, 
[2025-09-30 14:09:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:33] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:33] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:33] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.34, #queue-req: 0, 
[2025-09-30 14:09:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:33] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:34] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:09:34] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:09:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:34] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:34] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:34] Decode batch. #running-req: 1, #token: 684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.50, #queue-req: 0, 
[2025-09-30 14:09:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:35] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:35] Decode batch. #running-req: 1, #token: 1036, token usage: 0.02, cuda graph: True, gen throughput (token/s): 59.64, #queue-req: 0, 
[2025-09-30 14:09:35] Decode batch. #running-req: 1, #token: 1076, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:09:36] Decode batch. #running-req: 1, #token: 1116, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:09:36] Decode batch. #running-req: 1, #token: 1156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:09:36] Decode batch. #running-req: 1, #token: 1196, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:09:37] Decode batch. #running-req: 1, #token: 1236, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:09:37] Decode batch. #running-req: 1, #token: 1276, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:09:37] Decode batch. #running-req: 1, #token: 1316, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 14:09:37] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 14:09:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:37] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:38] Decode batch. #running-req: 1, #token: 1024, token usage: 0.02, cuda graph: True, gen throughput (token/s): 113.96, #queue-req: 0, 
[2025-09-30 14:09:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:38] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 139, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:38] Decode batch. #running-req: 1, #token: 766, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.51, #queue-req: 0, 
[2025-09-30 14:09:38] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.73, #queue-req: 0, 
[2025-09-30 14:09:39] Decode batch. #running-req: 1, #token: 846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.65, #queue-req: 0, 
[2025-09-30 14:09:39] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:09:39] Decode batch. #running-req: 1, #token: 926, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:09:40] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:09:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:40] Prefill batch. #new-seq: 1, #new-token: 1367, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:40] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:40] Decode batch. #running-req: 1, #token: 971, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.59, #queue-req: 0, 
[2025-09-30 14:09:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:40] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:41] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:09:41] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:09:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:41] Prefill batch. #new-seq: 1, #new-token: 1501, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:41] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:42] Decode batch. #running-req: 1, #token: 913, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.23, #queue-req: 0, 
[2025-09-30 14:09:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:42] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:42] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.10, #queue-req: 0, 
[2025-09-30 14:09:42] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:09:43] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:09:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:43] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:43] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:43] Decode batch. #running-req: 1, #token: 815, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.31, #queue-req: 0, 
[2025-09-30 14:09:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:43] Prefill batch. #new-seq: 1, #new-token: 1318, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:43] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:44] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.64, #queue-req: 0, 
[2025-09-30 14:09:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:44] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:44] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.31, #queue-req: 0, 
[2025-09-30 14:09:44] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:09:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:45] Prefill batch. #new-seq: 1, #new-token: 1157, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:45] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:45] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.47, #queue-req: 0, 
[2025-09-30 14:09:45] Decode batch. #running-req: 1, #token: 849, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:09:46] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:09:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:46] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:46] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 14:09:46] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:09:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:46] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:47] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:47] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.38, #queue-req: 0, 
[2025-09-30 14:09:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:47] Prefill batch. #new-seq: 1, #new-token: 1040, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:47] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 209, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:47] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.13, #queue-req: 0, 
[2025-09-30 14:09:48] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.06, #queue-req: 0, 
[2025-09-30 14:09:48] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:09:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:48] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:48] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:09:49] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:09:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:49] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:49] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:49] Decode batch. #running-req: 1, #token: 462, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.37, #queue-req: 0, 
[2025-09-30 14:09:50] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.86, #queue-req: 0, 
[2025-09-30 14:09:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:50] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:50] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.03, #queue-req: 0, 
[2025-09-30 14:09:50] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:09:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:50] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:50] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:51] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.32, #queue-req: 0, 
[2025-09-30 14:09:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:51] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:51] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:51] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.77, #queue-req: 0, 
[2025-09-30 14:09:52] Decode batch. #running-req: 1, #token: 526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.58, #queue-req: 0, 
[2025-09-30 14:09:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:52] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.08, #queue-req: 0, 
[2025-09-30 14:09:52] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:52] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:52] Prefill batch. #new-seq: 1, #new-token: 352, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:52] Decode batch. #running-req: 1, #token: 519, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.41, #queue-req: 0, 
[2025-09-30 14:09:53] Decode batch. #running-req: 1, #token: 559, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.18, #queue-req: 0, 
[2025-09-30 14:09:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:53] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:53] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.49, #queue-req: 0, 
[2025-09-30 14:09:53] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:09:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:53] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:53] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:54] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.25, #queue-req: 0, 
[2025-09-30 14:09:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:54] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:54] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:54] Decode batch. #running-req: 1, #token: 561, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.12, #queue-req: 0, 
[2025-09-30 14:09:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:55] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:55] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.46, #queue-req: 0, 
[2025-09-30 14:09:55] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:09:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:55] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.30, #queue-req: 0, 
[2025-09-30 14:09:56] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:56] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:56] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:56] Decode batch. #running-req: 1, #token: 558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.46, #queue-req: 0, 
[2025-09-30 14:09:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:56] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:56] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.09, #queue-req: 0, 
[2025-09-30 14:09:57] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:09:57] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:09:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:57] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:57] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:57] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 108.90, #queue-req: 0, 
[2025-09-30 14:09:58] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.61, #queue-req: 0, 
[2025-09-30 14:09:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:58] Prefill batch. #new-seq: 1, #new-token: 1163, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:58] Prefill batch. #new-seq: 1, #new-token: 790, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:58] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:59] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.06, #queue-req: 0, 
[2025-09-30 14:09:59] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:09:59] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:09:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:59] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:09:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:09:59] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:00] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.51, #queue-req: 0, 
[2025-09-30 14:10:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:00] Prefill batch. #new-seq: 1, #new-token: 2177, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:00] Decode batch. #running-req: 1, #token: 2543, token usage: 0.04, cuda graph: True, gen throughput (token/s): 49.78, #queue-req: 0, 
[2025-09-30 14:10:01] Decode batch. #running-req: 1, #token: 2583, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.26, #queue-req: 0, 
[2025-09-30 14:10:01] Decode batch. #running-req: 1, #token: 2623, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:10:01] Decode batch. #running-req: 1, #token: 2663, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:10:02] Decode batch. #running-req: 1, #token: 2703, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:10:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:02] Prefill batch. #new-seq: 1, #new-token: 2177, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:02] Decode batch. #running-req: 1, #token: 2505, token usage: 0.04, cuda graph: True, gen throughput (token/s): 92.50, #queue-req: 0, 
[2025-09-30 14:10:02] Decode batch. #running-req: 1, #token: 2545, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:10:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:03] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:03] Decode batch. #running-req: 1, #token: 630, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.56, #queue-req: 0, 
[2025-09-30 14:10:03] Decode batch. #running-req: 1, #token: 670, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.52, #queue-req: 0, 
[2025-09-30 14:10:03] Decode batch. #running-req: 1, #token: 710, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.41, #queue-req: 0, 
[2025-09-30 14:10:04] Decode batch. #running-req: 1, #token: 750, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.30, #queue-req: 0, 
[2025-09-30 14:10:04] Decode batch. #running-req: 1, #token: 790, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.97, #queue-req: 0, 
[2025-09-30 14:10:04] Decode batch. #running-req: 1, #token: 830, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.71, #queue-req: 0, 
[2025-09-30 14:10:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:05] Prefill batch. #new-seq: 1, #new-token: 1570, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:05] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.29, #queue-req: 0, 
[2025-09-30 14:10:05] Prefill batch. #new-seq: 1, #new-token: 786, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:05] Decode batch. #running-req: 1, #token: 990, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.63, #queue-req: 0, 
[2025-09-30 14:10:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:05] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:06] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:10:06] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:10:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:06] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:06] Prefill batch. #new-seq: 1, #new-token: 782, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:06] Decode batch. #running-req: 1, #token: 877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.76, #queue-req: 0, 
[2025-09-30 14:10:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:07] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:07] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 854, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:07] Prefill batch. #new-seq: 1, #new-token: 1437, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:07] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:07] Decode batch. #running-req: 1, #token: 825, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.25, #queue-req: 0, 
[2025-09-30 14:10:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:07] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:08] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.07, #queue-req: 0, 
[2025-09-30 14:10:08] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:10:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:08] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:08] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:08] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.44, #queue-req: 0, 
[2025-09-30 14:10:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:09] Prefill batch. #new-seq: 1, #new-token: 1520, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:09] Prefill batch. #new-seq: 1, #new-token: 867, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:09] Decode batch. #running-req: 1, #token: 1053, token usage: 0.02, cuda graph: True, gen throughput (token/s): 48.43, #queue-req: 0, 
[2025-09-30 14:10:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:09] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:09] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.52, #queue-req: 0, 
[2025-09-30 14:10:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:10] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:10] Decode batch. #running-req: 1, #token: 109, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.61, #queue-req: 0, 
[2025-09-30 14:10:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:10] Prefill batch. #new-seq: 1, #new-token: 862, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:10] Prefill batch. #new-seq: 1, #new-token: 1060, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:10] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:10] Decode batch. #running-req: 1, #token: 404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.82, #queue-req: 0, 
[2025-09-30 14:10:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:11] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:11] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.08, #queue-req: 0, 
[2025-09-30 14:10:11] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:10:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:11] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:11] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:11] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.15, #queue-req: 0, 
[2025-09-30 14:10:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:12] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 267, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:12] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.06, #queue-req: 0, 
[2025-09-30 14:10:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:12] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:12] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:13] Decode batch. #running-req: 1, #token: 543, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.29, #queue-req: 0, 
[2025-09-30 14:10:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:13] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:13] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:10:13] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 14:10:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:14] Prefill batch. #new-seq: 1, #new-token: 1027, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:14] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:14] Decode batch. #running-req: 1, #token: 863, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.64, #queue-req: 0, 
[2025-09-30 14:10:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:14] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:14] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:10:15] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:10:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:15] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:15] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.72, #queue-req: 0, 
[2025-09-30 14:10:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:15] Prefill batch. #new-seq: 1, #new-token: 683, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:16] Prefill batch. #new-seq: 1, #new-token: 1180, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:16] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:16] Decode batch. #running-req: 1, #token: 684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.03, #queue-req: 0, 
[2025-09-30 14:10:16] Decode batch. #running-req: 1, #token: 724, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:10:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:16] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:17] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.80, #queue-req: 0, 
[2025-09-30 14:10:17] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:10:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:17] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:17] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.78, #queue-req: 0, 
[2025-09-30 14:10:17] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:18] Prefill batch. #new-seq: 1, #new-token: 930, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:18] Prefill batch. #new-seq: 1, #new-token: 436, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:18] Decode batch. #running-req: 1, #token: 612, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.36, #queue-req: 0, 
[2025-09-30 14:10:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:18] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:18] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 14:10:19] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:10:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:19] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:19] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.36, #queue-req: 0, 
[2025-09-30 14:10:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:19] Prefill batch. #new-seq: 1, #new-token: 916, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:20] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:20] Decode batch. #running-req: 1, #token: 721, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.06, #queue-req: 0, 
[2025-09-30 14:10:20] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:10:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:20] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:20] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:10:21] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:10:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:21] Prefill batch. #new-seq: 1, #new-token: 975, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:21] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:21] Decode batch. #running-req: 1, #token: 670, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.69, #queue-req: 0, 
[2025-09-30 14:10:22] Decode batch. #running-req: 1, #token: 710, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:10:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:22] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:22] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.82, #queue-req: 0, 
[2025-09-30 14:10:22] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:10:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:23] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:23] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:23] Prefill batch. #new-seq: 1, #new-token: 884, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:23] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.03, #queue-req: 0, 
[2025-09-30 14:10:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:23] Prefill batch. #new-seq: 1, #new-token: 396, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:24] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:24] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.01, #queue-req: 0, 
[2025-09-30 14:10:24] Decode batch. #running-req: 1, #token: 440, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.85, #queue-req: 0, 
[2025-09-30 14:10:24] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.67, #queue-req: 0, 
[2025-09-30 14:10:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:24] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:25] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:25] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.72, #queue-req: 0, 
[2025-09-30 14:10:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:25] Prefill batch. #new-seq: 1, #new-token: 2795, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:26] Decode batch. #running-req: 1, #token: 3171, token usage: 0.05, cuda graph: True, gen throughput (token/s): 54.35, #queue-req: 0, 
[2025-09-30 14:10:26] Decode batch. #running-req: 1, #token: 3211, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:10:26] Decode batch. #running-req: 1, #token: 3251, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.74, #queue-req: 0, 
[2025-09-30 14:10:26] Decode batch. #running-req: 1, #token: 3291, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:10:27] Decode batch. #running-req: 1, #token: 3331, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.71, #queue-req: 0, 
[2025-09-30 14:10:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:27] Prefill batch. #new-seq: 1, #new-token: 2795, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:27] Decode batch. #running-req: 1, #token: 3144, token usage: 0.05, cuda graph: True, gen throughput (token/s): 85.41, #queue-req: 0, 
[2025-09-30 14:10:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:28] Prefill batch. #new-seq: 1, #new-token: 401, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:28] Decode batch. #running-req: 1, #token: 579, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.10, #queue-req: 0, 
[2025-09-30 14:10:28] Decode batch. #running-req: 1, #token: 619, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.64, #queue-req: 0, 
[2025-09-30 14:10:28] Decode batch. #running-req: 1, #token: 659, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.58, #queue-req: 0, 
[2025-09-30 14:10:29] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.38, #queue-req: 0, 
[2025-09-30 14:10:29] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.24, #queue-req: 0, 
[2025-09-30 14:10:29] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:10:29] Decode batch. #running-req: 1, #token: 819, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:10:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:30] Prefill batch. #new-seq: 1, #new-token: 955, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:30] Prefill batch. #new-seq: 1, #new-token: 561, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:30] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:30] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.46, #queue-req: 0, 
[2025-09-30 14:10:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:30] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:31] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.38, #queue-req: 0, 
[2025-09-30 14:10:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:31] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:31] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:31] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:31] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.57, #queue-req: 0, 
[2025-09-30 14:10:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:31] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:32] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.28, #queue-req: 0, 
[2025-09-30 14:10:32] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:10:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:32] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:32] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.92, #queue-req: 0, 
[2025-09-30 14:10:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:32] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:33] Decode batch. #running-req: 1, #token: 686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.59, #queue-req: 0, 
[2025-09-30 14:10:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:33] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:33] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:33] Prefill batch. #new-seq: 1, #new-token: 1663, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:34] Decode batch. #running-req: 1, #token: 2021, token usage: 0.03, cuda graph: True, gen throughput (token/s): 38.93, #queue-req: 0, 
[2025-09-30 14:10:34] Decode batch. #running-req: 1, #token: 2061, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.58, #queue-req: 0, 
[2025-09-30 14:10:34] Decode batch. #running-req: 1, #token: 2101, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:10:35] Decode batch. #running-req: 1, #token: 2141, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:10:35] Decode batch. #running-req: 1, #token: 2181, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 14:10:35] Decode batch. #running-req: 1, #token: 2221, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:10:35] Decode batch. #running-req: 1, #token: 2261, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:10:36] Decode batch. #running-req: 1, #token: 2301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:10:36] Decode batch. #running-req: 1, #token: 2341, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.74, #queue-req: 0, 
[2025-09-30 14:10:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:36] Prefill batch. #new-seq: 1, #new-token: 1663, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:36] Decode batch. #running-req: 1, #token: 2023, token usage: 0.03, cuda graph: True, gen throughput (token/s): 99.77, #queue-req: 0, 
[2025-09-30 14:10:37] Decode batch. #running-req: 1, #token: 2063, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.64, #queue-req: 0, 
[2025-09-30 14:10:37] Decode batch. #running-req: 1, #token: 2103, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.34, #queue-req: 0, 
[2025-09-30 14:10:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:37] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:37] Decode batch. #running-req: 1, #token: 719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.05, #queue-req: 0, 
[2025-09-30 14:10:38] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.19, #queue-req: 0, 
[2025-09-30 14:10:38] Decode batch. #running-req: 1, #token: 799, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.81, #queue-req: 0, 
[2025-09-30 14:10:38] Decode batch. #running-req: 1, #token: 839, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.67, #queue-req: 0, 
[2025-09-30 14:10:39] Decode batch. #running-req: 1, #token: 879, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:10:39] Decode batch. #running-req: 1, #token: 919, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.56, #queue-req: 0, 
[2025-09-30 14:10:39] Decode batch. #running-req: 1, #token: 959, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:10:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:40] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:40] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:40] Decode batch. #running-req: 1, #token: 684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.16, #queue-req: 0, 
[2025-09-30 14:10:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:40] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:40] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:10:41] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:10:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:41] Prefill batch. #new-seq: 1, #new-token: 1161, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:41] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:41] Decode batch. #running-req: 1, #token: 831, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.39, #queue-req: 0, 
[2025-09-30 14:10:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:41] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:41] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:10:42] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:10:42] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:10:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:42] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:42] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.76, #queue-req: 0, 
[2025-09-30 14:10:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:43] Prefill batch. #new-seq: 1, #new-token: 1191, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:43] Prefill batch. #new-seq: 1, #new-token: 538, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:43] Decode batch. #running-req: 1, #token: 724, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.07, #queue-req: 0, 
[2025-09-30 14:10:44] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:10:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:44] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:44] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:10:44] Decode batch. #running-req: 1, #token: 326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:10:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:44] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:44] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:45] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.44, #queue-req: 0, 
[2025-09-30 14:10:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:45] Prefill batch. #new-seq: 1, #new-token: 1077, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:45] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:45] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:45] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.17, #queue-req: 0, 
[2025-09-30 14:10:46] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:10:46] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:10:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:46] Prefill batch. #new-seq: 1, #new-token: 802, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:47] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:47] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.05, #queue-req: 0, 
[2025-09-30 14:10:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:47] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:47] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:10:47] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:10:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:47] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:48] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:48] Prefill batch. #new-seq: 1, #new-token: 1338, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:48] Decode batch. #running-req: 1, #token: 1679, token usage: 0.03, cuda graph: True, gen throughput (token/s): 44.00, #queue-req: 0, 
[2025-09-30 14:10:49] Decode batch. #running-req: 1, #token: 1719, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:10:49] Decode batch. #running-req: 1, #token: 1759, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:10:49] Decode batch. #running-req: 1, #token: 1799, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.37, #queue-req: 0, 
[2025-09-30 14:10:50] Decode batch. #running-req: 1, #token: 1839, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:10:50] Decode batch. #running-req: 1, #token: 1879, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:10:50] Decode batch. #running-req: 1, #token: 1919, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:10:50] Decode batch. #running-req: 1, #token: 1959, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:10:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:51] Prefill batch. #new-seq: 1, #new-token: 1338, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:51] Decode batch. #running-req: 1, #token: 1663, token usage: 0.03, cuda graph: True, gen throughput (token/s): 103.91, #queue-req: 0, 
[2025-09-30 14:10:51] Decode batch. #running-req: 1, #token: 1703, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.30, #queue-req: 0, 
[2025-09-30 14:10:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:51] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:51] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.74, #queue-req: 0, 
[2025-09-30 14:10:52] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.10, #queue-req: 0, 
[2025-09-30 14:10:52] Decode batch. #running-req: 1, #token: 818, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:10:52] Decode batch. #running-req: 1, #token: 858, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.59, #queue-req: 0, 
[2025-09-30 14:10:53] Decode batch. #running-req: 1, #token: 898, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.59, #queue-req: 0, 
[2025-09-30 14:10:53] Decode batch. #running-req: 1, #token: 938, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:10:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:54] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:54] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:54] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.10, #queue-req: 0, 
[2025-09-30 14:10:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:54] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:54] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 14:10:54] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:10:55] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:10:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:55] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:55] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:55] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:56] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:56] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.62, #queue-req: 0, 
[2025-09-30 14:10:56] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.65, #queue-req: 0, 
[2025-09-30 14:10:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:56] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:56] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:10:56] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:10:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:57] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:57] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:57] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.85, #queue-req: 0, 
[2025-09-30 14:10:57] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:57] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:58] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:58] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:58] Decode batch. #running-req: 1, #token: 396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.39, #queue-req: 0, 
[2025-09-30 14:10:58] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.04, #queue-req: 0, 
[2025-09-30 14:10:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:58] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:58] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.32, #queue-req: 0, 
[2025-09-30 14:10:59] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:10:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:59] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:10:59] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:10:59] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.37, #queue-req: 0, 
[2025-09-30 14:10:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:00] Prefill batch. #new-seq: 1, #new-token: 436, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:00] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:00] Decode batch. #running-req: 1, #token: 421, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.82, #queue-req: 0, 
[2025-09-30 14:11:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:00] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:00] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.27, #queue-req: 0, 
[2025-09-30 14:11:01] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:11:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:01] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:01] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:01] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.32, #queue-req: 0, 
[2025-09-30 14:11:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:02] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:02] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:02] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.15, #queue-req: 0, 
[2025-09-30 14:11:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:02] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:02] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:11:02] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:11:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:03] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:03] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:03] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.34, #queue-req: 0, 
[2025-09-30 14:11:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:03] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 210, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:03] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.74, #queue-req: 0, 
[2025-09-30 14:11:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:04] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:04] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:04] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.94, #queue-req: 0, 
[2025-09-30 14:11:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:04] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:04] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.91, #queue-req: 0, 
[2025-09-30 14:11:05] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:11:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:05] Prefill batch. #new-seq: 1, #new-token: 560, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:05] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:05] Decode batch. #running-req: 1, #token: 548, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.13, #queue-req: 0, 
[2025-09-30 14:11:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:06] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:06] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.73, #queue-req: 0, 
[2025-09-30 14:11:06] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.62, #queue-req: 0, 
[2025-09-30 14:11:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:06] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:06] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:06] Decode batch. #running-req: 1, #token: 396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.66, #queue-req: 0, 
[2025-09-30 14:11:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:07] Prefill batch. #new-seq: 1, #new-token: 852, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:07] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:07] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.21, #queue-req: 0, 
[2025-09-30 14:11:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:07] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:08] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:11:08] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:11:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:08] Prefill batch. #new-seq: 1, #new-token: 1173, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:08] Prefill batch. #new-seq: 1, #new-token: 634, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:08] Decode batch. #running-req: 1, #token: 834, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.58, #queue-req: 0, 
[2025-09-30 14:11:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:08] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:09] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:11:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:09] Prefill batch. #new-seq: 1, #new-token: 8, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:09] Decode batch. #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.26, #queue-req: 0, 
[2025-09-30 14:11:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:09] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:10] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 703, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:10] Decode batch. #running-req: 1, #token: 712, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.68, #queue-req: 0, 
[2025-09-30 14:11:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:10] Prefill batch. #new-seq: 1, #new-token: 1215, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:10] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:11] Decode batch. #running-req: 1, #token: 773, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.92, #queue-req: 0, 
[2025-09-30 14:11:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:11] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:11] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.89, #queue-req: 0, 
[2025-09-30 14:11:11] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:11:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:12] Prefill batch. #new-seq: 1, #new-token: 983, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:12] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:12] Decode batch. #running-req: 1, #token: 591, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.02, #queue-req: 0, 
[2025-09-30 14:11:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:12] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:12] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 14:11:13] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:11:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:13] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:13] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:13] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.47, #queue-req: 0, 
[2025-09-30 14:11:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:14] Prefill batch. #new-seq: 1, #new-token: 958, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:14] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:14] Decode batch. #running-req: 1, #token: 744, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.49, #queue-req: 0, 
[2025-09-30 14:11:14] Decode batch. #running-req: 1, #token: 784, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.20, #queue-req: 0, 
[2025-09-30 14:11:14] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:11:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:14] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:15] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:11:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:15] Prefill batch. #new-seq: 1, #new-token: 1008, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:15] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:16] Decode batch. #running-req: 1, #token: 734, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.68, #queue-req: 0, 
[2025-09-30 14:11:16] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.29, #queue-req: 0, 
[2025-09-30 14:11:16] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 14:11:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:16] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:16] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 14:11:17] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:11:17] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:11:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:17] Prefill batch. #new-seq: 1, #new-token: 1097, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:17] Prefill batch. #new-seq: 1, #new-token: 649, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:17] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.84, #queue-req: 0, 
[2025-09-30 14:11:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:17] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:18] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:11:18] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:11:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:18] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:18] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:18] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.00, #queue-req: 0, 
[2025-09-30 14:11:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:19] Prefill batch. #new-seq: 1, #new-token: 1296, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:19] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:19] Decode batch. #running-req: 1, #token: 849, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.22, #queue-req: 0, 
[2025-09-30 14:11:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:19] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:20] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.36, #queue-req: 0, 
[2025-09-30 14:11:20] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:11:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:20] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:20] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.05, #queue-req: 0, 
[2025-09-30 14:11:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:20] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:21] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:21] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 721, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:21] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.95, #queue-req: 0, 
[2025-09-30 14:11:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:22] Prefill batch. #new-seq: 1, #new-token: 1295, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:22] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:22] Decode batch. #running-req: 1, #token: 832, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.97, #queue-req: 0, 
[2025-09-30 14:11:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:22] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:22] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.53, #queue-req: 0, 
[2025-09-30 14:11:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:22] Prefill batch. #new-seq: 1, #new-token: 1211, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:23] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:23] Decode batch. #running-req: 1, #token: 743, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.15, #queue-req: 0, 
[2025-09-30 14:11:23] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:11:23] Decode batch. #running-req: 1, #token: 823, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:11:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:23] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:24] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:11:24] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:11:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:24] Prefill batch. #new-seq: 1, #new-token: 904, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:25] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:25] Decode batch. #running-req: 1, #token: 519, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.62, #queue-req: 0, 
[2025-09-30 14:11:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:25] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:25] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.63, #queue-req: 0, 
[2025-09-30 14:11:25] Decode batch. #running-req: 1, #token: 402, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.05, #queue-req: 0, 
[2025-09-30 14:11:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:26] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:26] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:26] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.90, #queue-req: 0, 
[2025-09-30 14:11:26] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:11:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:26] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:27] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.56, #queue-req: 0, 
[2025-09-30 14:11:27] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:11:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:27] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:27] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:27] Decode batch. #running-req: 1, #token: 579, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.30, #queue-req: 0, 
[2025-09-30 14:11:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:28] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 572, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:28] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.46, #queue-req: 0, 
[2025-09-30 14:11:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:28] Prefill batch. #new-seq: 1, #new-token: 1097, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:29] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:29] Decode batch. #running-req: 1, #token: 790, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.32, #queue-req: 0, 
[2025-09-30 14:11:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:29] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:29] Decode batch. #running-req: 1, #token: 657, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.35, #queue-req: 0, 
[2025-09-30 14:11:29] Decode batch. #running-req: 1, #token: 697, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.44, #queue-req: 0, 
[2025-09-30 14:11:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:30] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:30] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.04, #queue-req: 0, 
[2025-09-30 14:11:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:30] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:30] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.54, #queue-req: 0, 
[2025-09-30 14:11:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:31] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:31] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 664, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:31] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.97, #queue-req: 0, 
[2025-09-30 14:11:31] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.33, #queue-req: 0, 
[2025-09-30 14:11:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:32] Prefill batch. #new-seq: 1, #new-token: 933, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:32] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:32] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.41, #queue-req: 0, 
[2025-09-30 14:11:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:32] Decode batch. #running-req: 1, #token: 217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.66, #queue-req: 0, 
[2025-09-30 14:11:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:33] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:33] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.33, #queue-req: 0, 
[2025-09-30 14:11:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:33] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:33] Prefill batch. #new-seq: 1, #new-token: 576, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:33] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:33] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.42, #queue-req: 0, 
[2025-09-30 14:11:34] Decode batch. #running-req: 1, #token: 456, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.26, #queue-req: 0, 
[2025-09-30 14:11:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:34] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:34] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.56, #queue-req: 0, 
[2025-09-30 14:11:34] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:11:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:35] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:35] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:35] Decode batch. #running-req: 1, #token: 486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.09, #queue-req: 0, 
[2025-09-30 14:11:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:35] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:35] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.80, #queue-req: 0, 
[2025-09-30 14:11:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:36] Prefill batch. #new-seq: 1, #new-token: 1102, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:36] Prefill batch. #new-seq: 1, #new-token: 809, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:36] Decode batch. #running-req: 1, #token: 974, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.85, #queue-req: 0, 
[2025-09-30 14:11:36] Decode batch. #running-req: 1, #token: 1014, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:11:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:36] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:37] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.03, #queue-req: 0, 
[2025-09-30 14:11:37] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:11:37] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:11:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:37] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.08, #queue-req: 0, 
[2025-09-30 14:11:38] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:38] Prefill batch. #new-seq: 1, #new-token: 806, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:38] Decode batch. #running-req: 1, #token: 907, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.97, #queue-req: 0, 
[2025-09-30 14:11:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:39] Prefill batch. #new-seq: 1, #new-token: 1444, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:39] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:39] Decode batch. #running-req: 1, #token: 821, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.13, #queue-req: 0, 
[2025-09-30 14:11:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:39] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:39] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:11:40] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:11:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:40] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:40] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.59, #queue-req: 0, 
[2025-09-30 14:11:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:40] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:41] Prefill batch. #new-seq: 1, #new-token: 1159, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:41] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:41] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.54, #queue-req: 0, 
[2025-09-30 14:11:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:41] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:41] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.25, #queue-req: 0, 
[2025-09-30 14:11:41] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:11:42] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:11:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:42] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:42] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.16, #queue-req: 0, 
[2025-09-30 14:11:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:42] Prefill batch. #new-seq: 1, #new-token: 521, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:43] Prefill batch. #new-seq: 1, #new-token: 1020, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:43] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:43] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.14, #queue-req: 0, 
[2025-09-30 14:11:43] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:11:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:44] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:44] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.31, #queue-req: 0, 
[2025-09-30 14:11:44] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:11:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:45] Prefill batch. #new-seq: 1, #new-token: 1047, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:45] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:45] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-09-30 14:11:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:45] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 209, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:45] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.72, #queue-req: 0, 
[2025-09-30 14:11:46] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:11:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:46] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 91, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:46] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.45, #queue-req: 0, 
[2025-09-30 14:11:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:46] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:46] Decode batch. #running-req: 1, #token: 698, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.45, #queue-req: 0, 
[2025-09-30 14:11:47] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.58, #queue-req: 0, 
[2025-09-30 14:11:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:47] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:47] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.81, #queue-req: 0, 
[2025-09-30 14:11:47] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:11:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:47] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:48] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:48] Decode batch. #running-req: 1, #token: 538, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.31, #queue-req: 0, 
[2025-09-30 14:11:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:48] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:48] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:48] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.19, #queue-req: 0, 
[2025-09-30 14:11:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:48] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:49] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:11:49] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:11:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:50] Prefill batch. #new-seq: 1, #new-token: 835, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:50] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:50] Decode batch. #running-req: 1, #token: 648, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.32, #queue-req: 0, 
[2025-09-30 14:11:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:50] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:50] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 14:11:51] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:11:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:51] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:51] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:51] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.26, #queue-req: 0, 
[2025-09-30 14:11:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:51] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:52] Decode batch. #running-req: 1, #token: 108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.96, #queue-req: 0, 
[2025-09-30 14:11:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:52] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 519, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:52] Prefill batch. #new-seq: 1, #new-token: 879, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:52] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:52] Decode batch. #running-req: 1, #token: 601, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.29, #queue-req: 0, 
[2025-09-30 14:11:53] Decode batch. #running-req: 1, #token: 641, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:11:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:53] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:53] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.74, #queue-req: 0, 
[2025-09-30 14:11:53] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:11:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:54] Prefill batch. #new-seq: 1, #new-token: 879, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:54] Prefill batch. #new-seq: 1, #new-token: 453, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:54] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.06, #queue-req: 0, 
[2025-09-30 14:11:54] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.90, #queue-req: 0, 
[2025-09-30 14:11:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:54] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:55] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.13, #queue-req: 0, 
[2025-09-30 14:11:55] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:11:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:56] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:56] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.50, #queue-req: 0, 
[2025-09-30 14:11:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:56] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:56] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:56] Decode batch. #running-req: 1, #token: 596, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.27, #queue-req: 0, 
[2025-09-30 14:11:57] Decode batch. #running-req: 1, #token: 636, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 14:11:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:57] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:57] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.86, #queue-req: 0, 
[2025-09-30 14:11:57] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:11:58] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:11:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:58] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:58] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:58] Decode batch. #running-req: 1, #token: 509, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.70, #queue-req: 0, 
[2025-09-30 14:11:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:59] Prefill batch. #new-seq: 1, #new-token: 922, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:59] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:59] Decode batch. #running-req: 1, #token: 713, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.39, #queue-req: 0, 
[2025-09-30 14:11:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:11:59] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:11:59] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.99, #queue-req: 0, 
[2025-09-30 14:12:00] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.65, #queue-req: 0, 
[2025-09-30 14:12:00] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:12:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:00] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:00] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:00] Decode batch. #running-req: 1, #token: 608, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.99, #queue-req: 0, 
[2025-09-30 14:12:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:01] Prefill batch. #new-seq: 1, #new-token: 1071, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:01] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:01] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.51, #queue-req: 0, 
[2025-09-30 14:12:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:02] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:02] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.77, #queue-req: 0, 
[2025-09-30 14:12:02] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:12:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:02] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:02] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.54, #queue-req: 0, 
[2025-09-30 14:12:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:02] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:03] Decode batch. #running-req: 1, #token: 664, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.59, #queue-req: 0, 
[2025-09-30 14:12:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:03] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 629, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:03] Decode batch. #running-req: 1, #token: 641, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.98, #queue-req: 0, 
[2025-09-30 14:12:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:04] Prefill batch. #new-seq: 1, #new-token: 1018, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:04] Prefill batch. #new-seq: 1, #new-token: 463, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:04] Decode batch. #running-req: 1, #token: 646, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.41, #queue-req: 0, 
[2025-09-30 14:12:04] Decode batch. #running-req: 1, #token: 686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.83, #queue-req: 0, 
[2025-09-30 14:12:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:05] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:05] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:12:05] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:12:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:06] Prefill batch. #new-seq: 1, #new-token: 749, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:06] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:06] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:06] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.32, #queue-req: 0, 
[2025-09-30 14:12:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:06] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:06] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.03, #queue-req: 0, 
[2025-09-30 14:12:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:06] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:07] Prefill batch. #new-seq: 1, #new-token: 2261, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:07] Decode batch. #running-req: 1, #token: 2294, token usage: 0.04, cuda graph: True, gen throughput (token/s): 47.04, #queue-req: 0, 
[2025-09-30 14:12:07] Decode batch. #running-req: 1, #token: 2334, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.81, #queue-req: 0, 
[2025-09-30 14:12:08] Decode batch. #running-req: 1, #token: 2374, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:12:08] Decode batch. #running-req: 1, #token: 2414, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:12:08] Decode batch. #running-req: 1, #token: 2454, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:12:09] Decode batch. #running-req: 1, #token: 2494, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:12:09] Decode batch. #running-req: 1, #token: 2534, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.49, #queue-req: 0, 
[2025-09-30 14:12:09] Decode batch. #running-req: 1, #token: 2574, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.47, #queue-req: 0, 
[2025-09-30 14:12:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:09] Prefill batch. #new-seq: 1, #new-token: 2241, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:10] Decode batch. #running-req: 1, #token: 2308, token usage: 0.04, cuda graph: True, gen throughput (token/s): 93.20, #queue-req: 0, 
[2025-09-30 14:12:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:10] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:10] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.37, #queue-req: 0, 
[2025-09-30 14:12:10] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.52, #queue-req: 0, 
[2025-09-30 14:12:11] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.38, #queue-req: 0, 
[2025-09-30 14:12:11] Decode batch. #running-req: 1, #token: 748, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.26, #queue-req: 0, 
[2025-09-30 14:12:11] Decode batch. #running-req: 1, #token: 788, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:12:12] Decode batch. #running-req: 1, #token: 828, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.73, #queue-req: 0, 
[2025-09-30 14:12:12] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:12:12] Decode batch. #running-req: 1, #token: 908, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:12:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:13] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:13] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:13] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.35, #queue-req: 0, 
[2025-09-30 14:12:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:13] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:13] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.15, #queue-req: 0, 
[2025-09-30 14:12:14] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:12:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:14] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.31, #queue-req: 0, 
[2025-09-30 14:12:14] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:15] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:15] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 486, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:15] Decode batch. #running-req: 1, #token: 498, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.09, #queue-req: 0, 
[2025-09-30 14:12:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:15] Prefill batch. #new-seq: 1, #new-token: 1073, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:15] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:16] Decode batch. #running-req: 1, #token: 850, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.63, #queue-req: 0, 
[2025-09-30 14:12:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:16] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:16] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.64, #queue-req: 0, 
[2025-09-30 14:12:16] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:12:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:17] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:17] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.66, #queue-req: 0, 
[2025-09-30 14:12:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:17] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:17] Prefill batch. #new-seq: 1, #new-token: 1289, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:17] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:18] Decode batch. #running-req: 1, #token: 826, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.79, #queue-req: 0, 
[2025-09-30 14:12:18] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:12:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:18] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:18] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:12:19] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:12:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:19] Prefill batch. #new-seq: 1, #new-token: 1241, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:19] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:19] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.09, #queue-req: 0, 
[2025-09-30 14:12:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:20] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:20] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:12:20] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:12:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:20] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:21] Decode batch. #running-req: 1, #token: 693, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.06, #queue-req: 0, 
[2025-09-30 14:12:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:21] Prefill batch. #new-seq: 1, #new-token: 1275, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:21] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:22] Decode batch. #running-req: 1, #token: 863, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.77, #queue-req: 0, 
[2025-09-30 14:12:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:22] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:22] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.71, #queue-req: 0, 
[2025-09-30 14:12:22] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:12:22] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:12:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:23] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:23] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:23] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.91, #queue-req: 0, 
[2025-09-30 14:12:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:24] Prefill batch. #new-seq: 1, #new-token: 1301, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:24] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:24] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.02, #queue-req: 0, 
[2025-09-30 14:12:24] Decode batch. #running-req: 1, #token: 864, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:12:25] Decode batch. #running-req: 1, #token: 904, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:12:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:25] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:25] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 14:12:25] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:12:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:25] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:25] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:26] Prefill batch. #new-seq: 1, #new-token: 1244, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:26] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 35.80, #queue-req: 0, 
[2025-09-30 14:12:26] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:27] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.04, #queue-req: 0, 
[2025-09-30 14:12:27] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:12:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:27] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:27] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.68, #queue-req: 0, 
[2025-09-30 14:12:28] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:12:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:28] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:28] Prefill batch. #new-seq: 1, #new-token: 606, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:28] Decode batch. #running-req: 1, #token: 697, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.81, #queue-req: 0, 
[2025-09-30 14:12:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:29] Prefill batch. #new-seq: 1, #new-token: 1222, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:29] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:29] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:29] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.79, #queue-req: 0, 
[2025-09-30 14:12:29] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:12:30] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:12:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:30] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:30] Prefill batch. #new-seq: 1, #new-token: 612, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:31] Prefill batch. #new-seq: 1, #new-token: 1252, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:31] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:31] Decode batch. #running-req: 1, #token: 814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.26, #queue-req: 0, 
[2025-09-30 14:12:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:31] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:31] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.29, #queue-req: 0, 
[2025-09-30 14:12:31] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:12:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:32] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.84, #queue-req: 0, 
[2025-09-30 14:12:32] Prefill batch. #new-seq: 1, #new-token: 638, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:33] Prefill batch. #new-seq: 1, #new-token: 1291, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:33] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:33] Decode batch. #running-req: 1, #token: 833, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.56, #queue-req: 0, 
[2025-09-30 14:12:33] Decode batch. #running-req: 1, #token: 873, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.95, #queue-req: 0, 
[2025-09-30 14:12:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:33] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:34] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.82, #queue-req: 0, 
[2025-09-30 14:12:34] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:12:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:34] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:34] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:34] Decode batch. #running-req: 1, #token: 737, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.55, #queue-req: 0, 
[2025-09-30 14:12:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:35] Prefill batch. #new-seq: 1, #new-token: 948, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:35] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:35] Decode batch. #running-req: 1, #token: 489, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.39, #queue-req: 0, 
[2025-09-30 14:12:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:35] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:36] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 14:12:36] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:12:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:36] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:36] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.91, #queue-req: 0, 
[2025-09-30 14:12:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:36] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:37] Prefill batch. #new-seq: 1, #new-token: 702, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:37] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:37] Decode batch. #running-req: 1, #token: 580, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.96, #queue-req: 0, 
[2025-09-30 14:12:38] Decode batch. #running-req: 1, #token: 620, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:12:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:38] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:38] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:12:38] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:12:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:39] Prefill batch. #new-seq: 1, #new-token: 1020, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:39] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:39] Decode batch. #running-req: 1, #token: 805, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.76, #queue-req: 0, 
[2025-09-30 14:12:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:39] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:39] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.54, #queue-req: 0, 
[2025-09-30 14:12:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:12:40] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:40] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:41] Prefill batch. #new-seq: 1, #new-token: 934, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:41] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:41] Decode batch. #running-req: 1, #token: 496, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.37, #queue-req: 0, 
[2025-09-30 14:12:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:41] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:41] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.09, #queue-req: 0, 
[2025-09-30 14:12:42] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:12:42] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:12:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:42] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:42] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:43] Decode batch. #running-req: 1, #token: 673, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.58, #queue-req: 0, 
[2025-09-30 14:12:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:43] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:43] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.16, #queue-req: 0, 
[2025-09-30 14:12:43] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.65, #queue-req: 0, 
[2025-09-30 14:12:44] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:12:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:44] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:44] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:44] Decode batch. #running-req: 1, #token: 562, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.14, #queue-req: 0, 
[2025-09-30 14:12:44] Decode batch. #running-req: 1, #token: 602, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.77, #queue-req: 0, 
[2025-09-30 14:12:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:45] Prefill batch. #new-seq: 1, #new-token: 850, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:45] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:45] Decode batch. #running-req: 1, #token: 562, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.18, #queue-req: 0, 
[2025-09-30 14:12:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:46] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:46] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.53, #queue-req: 0, 
[2025-09-30 14:12:46] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:12:46] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:12:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:47] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:47] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:47] Decode batch. #running-req: 1, #token: 640, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.15, #queue-req: 0, 
[2025-09-30 14:12:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:47] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:48] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.96, #queue-req: 0, 
[2025-09-30 14:12:48] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:12:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:48] Prefill batch. #new-seq: 1, #new-token: 1779, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:49] Prefill batch. #new-seq: 1, #new-token: 1342, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:49] Decode batch. #running-req: 1, #token: 1527, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.05, #queue-req: 0, 
[2025-09-30 14:12:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:49] Prefill batch. #new-seq: 1, #new-token: 962, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:49] Decode batch. #running-req: 1, #token: 1164, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.03, #queue-req: 0, 
[2025-09-30 14:12:50] Decode batch. #running-req: 1, #token: 1204, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:12:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:50] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.65, #queue-req: 0, 
[2025-09-30 14:12:50] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:50] Prefill batch. #new-seq: 1, #new-token: 1337, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:50] Decode batch. #running-req: 1, #token: 1429, token usage: 0.02, cuda graph: True, gen throughput (token/s): 90.87, #queue-req: 0, 
[2025-09-30 14:12:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:51] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 1407, token usage: 0.02, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:51] Prefill batch. #new-seq: 1, #new-token: 1748, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:52] Prefill batch. #new-seq: 1, #new-token: 412, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:52] Decode batch. #running-req: 1, #token: 580, token usage: 0.01, cuda graph: True, gen throughput (token/s): 28.82, #queue-req: 0, 
[2025-09-30 14:12:52] Decode batch. #running-req: 1, #token: 620, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:12:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:52] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:52] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.33, #queue-req: 0, 
[2025-09-30 14:12:53] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0, 
[2025-09-30 14:12:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:53] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:53] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.98, #queue-req: 0, 
[2025-09-30 14:12:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:53] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:53] Decode batch. #running-req: 1, #token: 520, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.45, #queue-req: 0, 
[2025-09-30 14:12:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:54] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:54] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:54] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.12, #queue-req: 0, 
[2025-09-30 14:12:55] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.63, #queue-req: 0, 
[2025-09-30 14:12:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:55] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:55] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:12:55] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:12:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:56] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:56] Decode batch. #running-req: 1, #token: 916, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.43, #queue-req: 0, 
[2025-09-30 14:12:56] Decode batch. #running-req: 1, #token: 956, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:12:57] Decode batch. #running-req: 1, #token: 996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:12:57] Decode batch. #running-req: 1, #token: 1036, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 14:12:57] Decode batch. #running-req: 1, #token: 1076, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:12:58] Decode batch. #running-req: 1, #token: 1116, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:12:58] Decode batch. #running-req: 1, #token: 1156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:12:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:58] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:58] Decode batch. #running-req: 1, #token: 875, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.11, #queue-req: 0, 
[2025-09-30 14:12:59] Decode batch. #running-req: 1, #token: 915, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 14:12:59] Decode batch. #running-req: 1, #token: 955, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.47, #queue-req: 0, 
[2025-09-30 14:12:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:12:59] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:12:59] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.25, #queue-req: 0, 
[2025-09-30 14:13:00] Decode batch. #running-req: 1, #token: 770, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.21, #queue-req: 0, 
[2025-09-30 14:13:00] Decode batch. #running-req: 1, #token: 810, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.80, #queue-req: 0, 
[2025-09-30 14:13:00] Decode batch. #running-req: 1, #token: 850, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 14:13:00] Decode batch. #running-req: 1, #token: 890, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.61, #queue-req: 0, 
[2025-09-30 14:13:01] Decode batch. #running-req: 1, #token: 930, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:13:01] Decode batch. #running-req: 1, #token: 970, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:13:01] Decode batch. #running-req: 1, #token: 1010, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:13:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:02] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:02] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:02] Decode batch. #running-req: 1, #token: 464, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.24, #queue-req: 0, 
[2025-09-30 14:13:02] Decode batch. #running-req: 1, #token: 504, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.91, #queue-req: 0, 
[2025-09-30 14:13:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:02] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:03] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:13:03] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:13:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:03] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:03] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:03] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.90, #queue-req: 0, 
[2025-09-30 14:13:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:04] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:04] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.35, #queue-req: 0, 
[2025-09-30 14:13:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 366, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:05] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:05] Decode batch. #running-req: 1, #token: 1497, token usage: 0.02, cuda graph: True, gen throughput (token/s): 47.47, #queue-req: 0, 
[2025-09-30 14:13:05] Decode batch. #running-req: 1, #token: 1537, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.01, #queue-req: 0, 
[2025-09-30 14:13:06] Decode batch. #running-req: 1, #token: 1577, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.60, #queue-req: 0, 
[2025-09-30 14:13:06] Decode batch. #running-req: 1, #token: 1617, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:13:06] Decode batch. #running-req: 1, #token: 1657, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:13:07] Decode batch. #running-req: 1, #token: 1697, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:13:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:07] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:07] Decode batch. #running-req: 1, #token: 1506, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.91, #queue-req: 0, 
[2025-09-30 14:13:07] Decode batch. #running-req: 1, #token: 1546, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:13:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:07] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:08] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.12, #queue-req: 0, 
[2025-09-30 14:13:08] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.27, #queue-req: 0, 
[2025-09-30 14:13:08] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:13:09] Decode batch. #running-req: 1, #token: 819, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.71, #queue-req: 0, 
[2025-09-30 14:13:09] Decode batch. #running-req: 1, #token: 859, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:13:09] Decode batch. #running-req: 1, #token: 899, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:13:10] Decode batch. #running-req: 1, #token: 939, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.41, #queue-req: 0, 
[2025-09-30 14:13:10] Decode batch. #running-req: 1, #token: 979, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:13:10] Decode batch. #running-req: 1, #token: 1019, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 14:13:10] Decode batch. #running-req: 1, #token: 1059, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.00, #queue-req: 0, 
[2025-09-30 14:13:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:11] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:11] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:11] Decode batch. #running-req: 1, #token: 547, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.05, #queue-req: 0, 
[2025-09-30 14:13:12] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.16, #queue-req: 0, 
[2025-09-30 14:13:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:12] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:12] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 14:13:12] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:13:12] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:13:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:13] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:13] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:13] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.84, #queue-req: 0, 
[2025-09-30 14:13:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:14] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:14] Prefill batch. #new-seq: 1, #new-token: 469, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:14] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.06, #queue-req: 0, 
[2025-09-30 14:13:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:14] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.58, #queue-req: 0, 
[2025-09-30 14:13:14] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:15] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:13:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:15] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:15] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.28, #queue-req: 0, 
[2025-09-30 14:13:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:15] Prefill batch. #new-seq: 1, #new-token: 465, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:16] Prefill batch. #new-seq: 1, #new-token: 878, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:16] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:16] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.17, #queue-req: 0, 
[2025-09-30 14:13:16] Decode batch. #running-req: 1, #token: 625, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.90, #queue-req: 0, 
[2025-09-30 14:13:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:16] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:17] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.90, #queue-req: 0, 
[2025-09-30 14:13:17] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:13:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:18] Prefill batch. #new-seq: 1, #new-token: 884, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:18] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:18] Decode batch. #running-req: 1, #token: 667, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.06, #queue-req: 0, 
[2025-09-30 14:13:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:18] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:18] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.74, #queue-req: 0, 
[2025-09-30 14:13:19] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:13:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:19] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:19] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.73, #queue-req: 0, 
[2025-09-30 14:13:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:19] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:20] Prefill batch. #new-seq: 1, #new-token: 743, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:20] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:20] Decode batch. #running-req: 1, #token: 444, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.98, #queue-req: 0, 
[2025-09-30 14:13:20] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.98, #queue-req: 0, 
[2025-09-30 14:13:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:20] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:21] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:13:21] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:13:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:21] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:21] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:21] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.55, #queue-req: 0, 
[2025-09-30 14:13:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:22] Prefill batch. #new-seq: 1, #new-token: 868, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:22] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:22] Decode batch. #running-req: 1, #token: 796, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.73, #queue-req: 0, 
[2025-09-30 14:13:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:23] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:23] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:13:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:23] Prefill batch. #new-seq: 1, #new-token: 1059, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:23] Prefill batch. #new-seq: 1, #new-token: 464, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:23] Decode batch. #running-req: 1, #token: 634, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.86, #queue-req: 0, 
[2025-09-30 14:13:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:23] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:24] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.64, #queue-req: 0, 
[2025-09-30 14:13:24] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:13:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:24] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:24] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.99, #queue-req: 0, 
[2025-09-30 14:13:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:24] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:25] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:25] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.47, #queue-req: 0, 
[2025-09-30 14:13:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:25] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 533, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:26] Prefill batch. #new-seq: 1, #new-token: 1498, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:26] Decode batch. #running-req: 1, #token: 1848, token usage: 0.03, cuda graph: True, gen throughput (token/s): 45.10, #queue-req: 0, 
[2025-09-30 14:13:26] Decode batch. #running-req: 1, #token: 1888, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:13:27] Decode batch. #running-req: 1, #token: 1928, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:13:27] Decode batch. #running-req: 1, #token: 1968, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:13:27] Decode batch. #running-req: 1, #token: 2008, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:13:27] Decode batch. #running-req: 1, #token: 2048, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:13:28] Decode batch. #running-req: 1, #token: 2088, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:13:28] Decode batch. #running-req: 1, #token: 2128, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:13:28] Decode batch. #running-req: 1, #token: 2168, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:13:29] Decode batch. #running-req: 1, #token: 2208, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:13:29] Decode batch. #running-req: 1, #token: 2248, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:13:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:29] Prefill batch. #new-seq: 1, #new-token: 1498, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:29] Decode batch. #running-req: 1, #token: 1832, token usage: 0.03, cuda graph: True, gen throughput (token/s): 101.27, #queue-req: 0, 
[2025-09-30 14:13:30] Decode batch. #running-req: 1, #token: 1872, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:13:30] Decode batch. #running-req: 1, #token: 1912, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:13:30] Decode batch. #running-req: 1, #token: 1952, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:13:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:31] Prefill batch. #new-seq: 1, #new-token: 828, #cached-token: 140, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:31] Decode batch. #running-req: 1, #token: 994, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.56, #queue-req: 0, 
[2025-09-30 14:13:31] Decode batch. #running-req: 1, #token: 1034, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 14:13:31] Decode batch. #running-req: 1, #token: 1074, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:13:32] Decode batch. #running-req: 1, #token: 1114, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:13:32] Decode batch. #running-req: 1, #token: 1154, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 14:13:32] Decode batch. #running-req: 1, #token: 1194, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:13:33] Decode batch. #running-req: 1, #token: 1234, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:13:33] Decode batch. #running-req: 1, #token: 1274, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:13:33] Decode batch. #running-req: 1, #token: 1314, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 14:13:34] Decode batch. #running-req: 1, #token: 1354, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:13:34] Decode batch. #running-req: 1, #token: 1394, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 14:13:34] Decode batch. #running-req: 1, #token: 1434, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:13:34] Decode batch. #running-req: 1, #token: 1474, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:13:35] Decode batch. #running-req: 1, #token: 1514, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:13:35] Decode batch. #running-req: 1, #token: 1554, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.88, #queue-req: 0, 
[2025-09-30 14:13:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:36] Prefill batch. #new-seq: 1, #new-token: 1049, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:36] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:36] Decode batch. #running-req: 1, #token: 779, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.02, #queue-req: 0, 
[2025-09-30 14:13:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:36] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:36] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0, 
[2025-09-30 14:13:37] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:13:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:37] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:37] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:37] Decode batch. #running-req: 1, #token: 660, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.01, #queue-req: 0, 
[2025-09-30 14:13:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:38] Prefill batch. #new-seq: 1, #new-token: 943, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:38] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:38] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.59, #queue-req: 0, 
[2025-09-30 14:13:38] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.99, #queue-req: 0, 
[2025-09-30 14:13:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:38] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:39] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.22, #queue-req: 0, 
[2025-09-30 14:13:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:39] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:39] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:39] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.47, #queue-req: 0, 
[2025-09-30 14:13:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:39] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:40] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.41, #queue-req: 0, 
[2025-09-30 14:13:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 428, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:40] Prefill batch. #new-seq: 1, #new-token: 875, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:40] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:40] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.70, #queue-req: 0, 
[2025-09-30 14:13:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:41] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:41] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.28, #queue-req: 0, 
[2025-09-30 14:13:41] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:13:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:41] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:41] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:41] Decode batch. #running-req: 1, #token: 605, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.81, #queue-req: 0, 
[2025-09-30 14:13:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:42] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:42] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 590, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:42] Decode batch. #running-req: 1, #token: 614, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.07, #queue-req: 0, 
[2025-09-30 14:13:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:43] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:43] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:43] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:43] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.06, #queue-req: 0, 
[2025-09-30 14:13:43] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:13:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:44] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:44] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.96, #queue-req: 0, 
[2025-09-30 14:13:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:44] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:45] Prefill batch. #new-seq: 1, #new-token: 897, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:45] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:45] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.30, #queue-req: 0, 
[2025-09-30 14:13:45] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:13:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:45] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:45] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:13:46] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:13:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:46] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:46] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:46] Decode batch. #running-req: 1, #token: 737, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.73, #queue-req: 0, 
[2025-09-30 14:13:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:47] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 715, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:47] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.47, #queue-req: 0, 
[2025-09-30 14:13:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:48] Prefill batch. #new-seq: 1, #new-token: 1664, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:48] Decode batch. #running-req: 1, #token: 2043, token usage: 0.03, cuda graph: True, gen throughput (token/s): 44.52, #queue-req: 0, 
[2025-09-30 14:13:48] Decode batch. #running-req: 1, #token: 2083, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.40, #queue-req: 0, 
[2025-09-30 14:13:49] Decode batch. #running-req: 1, #token: 2123, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:13:49] Decode batch. #running-req: 1, #token: 2163, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:13:49] Decode batch. #running-req: 1, #token: 2203, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:13:49] Decode batch. #running-req: 1, #token: 2243, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:13:50] Decode batch. #running-req: 1, #token: 2283, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:13:50] Decode batch. #running-req: 1, #token: 2323, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.98, #queue-req: 0, 
[2025-09-30 14:13:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:50] Prefill batch. #new-seq: 1, #new-token: 1664, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:51] Decode batch. #running-req: 1, #token: 1996, token usage: 0.03, cuda graph: True, gen throughput (token/s): 99.06, #queue-req: 0, 
[2025-09-30 14:13:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:51] Prefill batch. #new-seq: 1, #new-token: 939, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:51] Decode batch. #running-req: 1, #token: 1079, token usage: 0.02, cuda graph: True, gen throughput (token/s): 109.76, #queue-req: 0, 
[2025-09-30 14:13:51] Decode batch. #running-req: 1, #token: 1119, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:13:52] Decode batch. #running-req: 1, #token: 1159, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:13:52] Decode batch. #running-req: 1, #token: 1199, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:13:52] Decode batch. #running-req: 1, #token: 1239, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:13:52] Decode batch. #running-req: 1, #token: 1279, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.65, #queue-req: 0, 
[2025-09-30 14:13:53] Decode batch. #running-req: 1, #token: 1319, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:13:53] Decode batch. #running-req: 1, #token: 1359, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:13:53] Decode batch. #running-req: 1, #token: 1399, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:13:54] Decode batch. #running-req: 1, #token: 1439, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:13:54] Decode batch. #running-req: 1, #token: 1479, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:13:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:55] Prefill batch. #new-seq: 1, #new-token: 1046, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:55] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:55] Decode batch. #running-req: 1, #token: 598, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.55, #queue-req: 0, 
[2025-09-30 14:13:55] Decode batch. #running-req: 1, #token: 638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.88, #queue-req: 0, 
[2025-09-30 14:13:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:55] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:56] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.43, #queue-req: 0, 
[2025-09-30 14:13:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:56] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:56] Decode batch. #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.18, #queue-req: 0, 
[2025-09-30 14:13:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:56] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:57] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:57] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:57] Decode batch. #running-req: 1, #token: 757, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.96, #queue-req: 0, 
[2025-09-30 14:13:57] Decode batch. #running-req: 1, #token: 797, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 14:13:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:58] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:58] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.10, #queue-req: 0, 
[2025-09-30 14:13:58] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:13:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:59] Prefill batch. #new-seq: 1, #new-token: 1124, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:59] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:59] Decode batch. #running-req: 1, #token: 726, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.71, #queue-req: 0, 
[2025-09-30 14:13:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:13:59] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:13:59] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.36, #queue-req: 0, 
[2025-09-30 14:14:00] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:14:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:00] Prefill batch. #new-seq: 1, #new-token: 1136, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:00] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:00] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.80, #queue-req: 0, 
[2025-09-30 14:14:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:00] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:00] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:14:01] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:14:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:01] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:01] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:02] Prefill batch. #new-seq: 1, #new-token: 882, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:02] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:02] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.08, #queue-req: 0, 
[2025-09-30 14:14:02] Decode batch. #running-req: 1, #token: 517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.80, #queue-req: 0, 
[2025-09-30 14:14:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:02] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:02] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.73, #queue-req: 0, 
[2025-09-30 14:14:03] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:14:03] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:14:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:04] Prefill batch. #new-seq: 1, #new-token: 891, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:04] Prefill batch. #new-seq: 1, #new-token: 611, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:04] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.52, #queue-req: 0, 
[2025-09-30 14:14:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:04] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:04] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.47, #queue-req: 0, 
[2025-09-30 14:14:05] Decode batch. #running-req: 1, #token: 356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:14:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:05] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:05] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.52, #queue-req: 0, 
[2025-09-30 14:14:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:05] Prefill batch. #new-seq: 1, #new-token: 607, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:06] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:06] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 679, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:06] Decode batch. #running-req: 1, #token: 685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.95, #queue-req: 0, 
[2025-09-30 14:14:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:07] Prefill batch. #new-seq: 1, #new-token: 1230, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:07] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:07] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.19, #queue-req: 0, 
[2025-09-30 14:14:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:07] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:07] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.20, #queue-req: 0, 
[2025-09-30 14:14:08] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:14:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:08] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:08] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.86, #queue-req: 0, 
[2025-09-30 14:14:08] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:09] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:09] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 693, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:09] Decode batch. #running-req: 1, #token: 705, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.52, #queue-req: 0, 
[2025-09-30 14:14:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:09] Prefill batch. #new-seq: 1, #new-token: 1164, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:10] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:10] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.18, #queue-req: 0, 
[2025-09-30 14:14:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:10] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:10] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 14:14:10] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:14:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:10] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:11] Prefill batch. #new-seq: 1, #new-token: 544, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:11] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.64, #queue-req: 0, 
[2025-09-30 14:14:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:12] Prefill batch. #new-seq: 1, #new-token: 1087, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:12] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:12] Decode batch. #running-req: 1, #token: 743, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.92, #queue-req: 0, 
[2025-09-30 14:14:12] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:14:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:12] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:13] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.69, #queue-req: 0, 
[2025-09-30 14:14:13] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:14:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:14] Prefill batch. #new-seq: 1, #new-token: 1134, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:14] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:14] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.91, #queue-req: 0, 
[2025-09-30 14:14:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:14] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:14] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.04, #queue-req: 0, 
[2025-09-30 14:14:15] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:14:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:15] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:15] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.38, #queue-req: 0, 
[2025-09-30 14:14:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:15] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:16] Prefill batch. #new-seq: 1, #new-token: 1318, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:16] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:16] Decode batch. #running-req: 1, #token: 900, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.94, #queue-req: 0, 
[2025-09-30 14:14:16] Decode batch. #running-req: 1, #token: 940, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:14:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:17] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:17] Decode batch. #running-req: 1, #token: 418, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.13, #queue-req: 0, 
[2025-09-30 14:14:17] Decode batch. #running-req: 1, #token: 458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.91, #queue-req: 0, 
[2025-09-30 14:14:17] Decode batch. #running-req: 1, #token: 498, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.68, #queue-req: 0, 
[2025-09-30 14:14:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:18] Prefill batch. #new-seq: 1, #new-token: 1361, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:18] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:18] Decode batch. #running-req: 1, #token: 832, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.61, #queue-req: 0, 
[2025-09-30 14:14:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:18] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:19] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:14:19] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 14:14:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:19] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:19] Prefill batch. #new-seq: 1, #new-token: 631, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:20] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:20] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.74, #queue-req: 0, 
[2025-09-30 14:14:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:20] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 706, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:21] Prefill batch. #new-seq: 1, #new-token: 1220, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:21] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:21] Decode batch. #running-req: 1, #token: 767, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.72, #queue-req: 0, 
[2025-09-30 14:14:21] Decode batch. #running-req: 1, #token: 807, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.09, #queue-req: 0, 
[2025-09-30 14:14:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:21] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:22] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 14:14:22] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:14:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:22] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:22] Decode batch. #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.61, #queue-req: 0, 
[2025-09-30 14:14:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:22] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:23] Prefill batch. #new-seq: 1, #new-token: 1060, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:23] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:24] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.34, #queue-req: 0, 
[2025-09-30 14:14:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:24] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:24] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:14:24] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:14:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:24] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.15, #queue-req: 0, 
[2025-09-30 14:14:24] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:25] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:25] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.35, #queue-req: 0, 
[2025-09-30 14:14:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:26] Prefill batch. #new-seq: 1, #new-token: 1059, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:26] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:26] Decode batch. #running-req: 1, #token: 792, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.26, #queue-req: 0, 
[2025-09-30 14:14:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:26] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:26] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:14:27] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:14:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:27] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:27] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:27] Decode batch. #running-req: 1, #token: 676, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.62, #queue-req: 0, 
[2025-09-30 14:14:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:28] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 659, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:28] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-09-30 14:14:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:29] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:29] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:29] Decode batch. #running-req: 1, #token: 686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.39, #queue-req: 0, 
[2025-09-30 14:14:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:29] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:29] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:14:30] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:14:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:30] Prefill batch. #new-seq: 1, #new-token: 997, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:31] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:31] Decode batch. #running-req: 1, #token: 671, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.19, #queue-req: 0, 
[2025-09-30 14:14:31] Decode batch. #running-req: 1, #token: 711, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:14:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:31] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:31] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:14:31] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:14:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:32] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:32] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.34, #queue-req: 0, 
[2025-09-30 14:14:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:33] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:33] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:33] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.45, #queue-req: 0, 
[2025-09-30 14:14:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:33] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:33] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:14:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:34] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:34] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:34] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.79, #queue-req: 0, 
[2025-09-30 14:14:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:34] Prefill batch. #new-seq: 1, #new-token: 688, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:35] Prefill batch. #new-seq: 1, #new-token: 491, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:35] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.95, #queue-req: 0, 
[2025-09-30 14:14:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:35] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:35] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.17, #queue-req: 0, 
[2025-09-30 14:14:35] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.07, #queue-req: 0, 
[2025-09-30 14:14:36] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.90, #queue-req: 0, 
[2025-09-30 14:14:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:36] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:36] Decode batch. #running-req: 1, #token: 115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.59, #queue-req: 0, 
[2025-09-30 14:14:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:36] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:37] Prefill batch. #new-seq: 1, #new-token: 921, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:37] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:37] Decode batch. #running-req: 1, #token: 602, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.77, #queue-req: 0, 
[2025-09-30 14:14:38] Decode batch. #running-req: 1, #token: 642, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.99, #queue-req: 0, 
[2025-09-30 14:14:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:38] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:38] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.81, #queue-req: 0, 
[2025-09-30 14:14:38] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:14:39] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:14:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:39] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:39] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:39] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.31, #queue-req: 0, 
[2025-09-30 14:14:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:40] Prefill batch. #new-seq: 1, #new-token: 675, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:40] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:40] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.40, #queue-req: 0, 
[2025-09-30 14:14:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:40] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:41] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:14:41] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:14:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:42] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:42] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.13, #queue-req: 0, 
[2025-09-30 14:14:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:42] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:42] Decode batch. #running-req: 1, #token: 544, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.60, #queue-req: 0, 
[2025-09-30 14:14:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:42] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:42] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 14:14:43] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:14:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:43] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:43] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:43] Decode batch. #running-req: 1, #token: 425, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.31, #queue-req: 0, 
[2025-09-30 14:14:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:44] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:44] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:44] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.09, #queue-req: 0, 
[2025-09-30 14:14:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:44] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:45] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:14:45] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:14:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:46] Prefill batch. #new-seq: 1, #new-token: 2188, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:46] Decode batch. #running-req: 1, #token: 2537, token usage: 0.04, cuda graph: True, gen throughput (token/s): 38.62, #queue-req: 0, 
[2025-09-30 14:14:46] Decode batch. #running-req: 1, #token: 2577, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.28, #queue-req: 0, 
[2025-09-30 14:14:47] Decode batch. #running-req: 1, #token: 2617, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:14:47] Decode batch. #running-req: 1, #token: 2657, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.01, #queue-req: 0, 
[2025-09-30 14:14:47] Decode batch. #running-req: 1, #token: 2697, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:14:48] Decode batch. #running-req: 1, #token: 2737, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:14:48] Decode batch. #running-req: 1, #token: 2777, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 14:14:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:48] Prefill batch. #new-seq: 1, #new-token: 2188, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:48] Decode batch. #running-req: 1, #token: 2533, token usage: 0.04, cuda graph: True, gen throughput (token/s): 92.21, #queue-req: 0, 
[2025-09-30 14:14:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:49] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:49] Decode batch. #running-req: 1, #token: 798, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.49, #queue-req: 0, 
[2025-09-30 14:14:49] Decode batch. #running-req: 1, #token: 838, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.61, #queue-req: 0, 
[2025-09-30 14:14:49] Decode batch. #running-req: 1, #token: 878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.68, #queue-req: 0, 
[2025-09-30 14:14:50] Decode batch. #running-req: 1, #token: 918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:14:50] Decode batch. #running-req: 1, #token: 958, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:14:50] Decode batch. #running-req: 1, #token: 998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 14:14:51] Decode batch. #running-req: 1, #token: 1038, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.17, #queue-req: 0, 
[2025-09-30 14:14:51] Decode batch. #running-req: 1, #token: 1078, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:14:51] Decode batch. #running-req: 1, #token: 1118, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:14:51] Decode batch. #running-req: 1, #token: 1158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:14:52] Decode batch. #running-req: 1, #token: 1198, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:14:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:53] Prefill batch. #new-seq: 1, #new-token: 527, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:53] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:53] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.77, #queue-req: 0, 
[2025-09-30 14:14:53] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0, 
[2025-09-30 14:14:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:53] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:53] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 14:14:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:53] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:53] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:54] Decode batch. #running-req: 1, #token: 450, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.13, #queue-req: 0, 
[2025-09-30 14:14:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:54] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:54] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0, 
[2025-09-30 14:14:54] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:14:55] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:14:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:55] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:55] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:55] Decode batch. #running-req: 1, #token: 514, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.40, #queue-req: 0, 
[2025-09-30 14:14:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:55] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:56] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.33, #queue-req: 0, 
[2025-09-30 14:14:56] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:14:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:56] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:56] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:56] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.52, #queue-req: 0, 
[2025-09-30 14:14:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:57] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:57] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:57] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.83, #queue-req: 0, 
[2025-09-30 14:14:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:57] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:58] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.59, #queue-req: 0, 
[2025-09-30 14:14:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:58] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:58] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:58] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.23, #queue-req: 0, 
[2025-09-30 14:14:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:58] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:59] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.53, #queue-req: 0, 
[2025-09-30 14:14:59] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:14:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:59] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:59] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:59] Decode batch. #running-req: 1, #token: 384, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.94, #queue-req: 0, 
[2025-09-30 14:14:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:14:59] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:14:59] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.80, #queue-req: 0, 
[2025-09-30 14:15:00] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:15:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:00] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:01] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:01] Decode batch. #running-req: 1, #token: 395, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.08, #queue-req: 0, 
[2025-09-30 14:15:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:01] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:01] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:15:01] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:15:02] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:15:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:02] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:02] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:02] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.52, #queue-req: 0, 
[2025-09-30 14:15:03] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:03] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:03] Decode batch. #running-req: 1, #token: 432, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.94, #queue-req: 0, 
[2025-09-30 14:15:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:03] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:03] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:15:03] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:15:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:04] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:04] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:04] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.80, #queue-req: 0, 
[2025-09-30 14:15:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:05] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:05] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:15:05] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:15:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:05] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:05] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:05] Decode batch. #running-req: 1, #token: 397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.89, #queue-req: 0, 
[2025-09-30 14:15:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:06] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:06] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:06] Decode batch. #running-req: 1, #token: 556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.77, #queue-req: 0, 
[2025-09-30 14:15:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:06] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:06] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.23, #queue-req: 0, 
[2025-09-30 14:15:07] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:15:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:07] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:07] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:08] Decode batch. #running-req: 1, #token: 501, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.07, #queue-req: 0, 
[2025-09-30 14:15:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:08] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:08] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.43, #queue-req: 0, 
[2025-09-30 14:15:08] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:15:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:09] Prefill batch. #new-seq: 1, #new-token: 641, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:09] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:09] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.60, #queue-req: 0, 
[2025-09-30 14:15:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:09] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:09] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.20, #queue-req: 0, 
[2025-09-30 14:15:10] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:15:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:10] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:10] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.15, #queue-req: 0, 
[2025-09-30 14:15:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:10] Prefill batch. #new-seq: 1, #new-token: 326, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:11] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:11] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:11] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.26, #queue-req: 0, 
[2025-09-30 14:15:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:11] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:11] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.23, #queue-req: 0, 
[2025-09-30 14:15:12] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:15:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:12] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:12] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.20, #queue-req: 0, 
[2025-09-30 14:15:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:12] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:13] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.61, #queue-req: 0, 
[2025-09-30 14:15:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 246, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:13] Prefill batch. #new-seq: 1, #new-token: 2301, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:14] Decode batch. #running-req: 1, #token: 2655, token usage: 0.04, cuda graph: True, gen throughput (token/s): 46.28, #queue-req: 0, 
[2025-09-30 14:15:14] Decode batch. #running-req: 1, #token: 2695, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.96, #queue-req: 0, 
[2025-09-30 14:15:14] Decode batch. #running-req: 1, #token: 2735, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.92, #queue-req: 0, 
[2025-09-30 14:15:15] Decode batch. #running-req: 1, #token: 2775, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.96, #queue-req: 0, 
[2025-09-30 14:15:15] Decode batch. #running-req: 1, #token: 2815, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.88, #queue-req: 0, 
[2025-09-30 14:15:15] Decode batch. #running-req: 1, #token: 2855, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:15:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:15] Prefill batch. #new-seq: 1, #new-token: 2301, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:16] Decode batch. #running-req: 1, #token: 2657, token usage: 0.04, cuda graph: True, gen throughput (token/s): 91.47, #queue-req: 0, 
[2025-09-30 14:15:16] Decode batch. #running-req: 1, #token: 2697, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:15:16] Decode batch. #running-req: 1, #token: 2737, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.01, #queue-req: 0, 
[2025-09-30 14:15:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:16] Prefill batch. #new-seq: 1, #new-token: 634, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:17] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.19, #queue-req: 0, 
[2025-09-30 14:15:17] Decode batch. #running-req: 1, #token: 818, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.71, #queue-req: 0, 
[2025-09-30 14:15:17] Decode batch. #running-req: 1, #token: 858, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 14:15:17] Decode batch. #running-req: 1, #token: 898, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.61, #queue-req: 0, 
[2025-09-30 14:15:18] Decode batch. #running-req: 1, #token: 938, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:15:18] Decode batch. #running-req: 1, #token: 978, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.40, #queue-req: 0, 
[2025-09-30 14:15:18] Decode batch. #running-req: 1, #token: 1018, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 14:15:19] Decode batch. #running-req: 1, #token: 1058, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 14:15:19] Decode batch. #running-req: 1, #token: 1098, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:15:19] Decode batch. #running-req: 1, #token: 1138, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:15:20] Decode batch. #running-req: 1, #token: 1178, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:15:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:20] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:20] Prefill batch. #new-seq: 1, #new-token: 484, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:20] Decode batch. #running-req: 1, #token: 661, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.03, #queue-req: 0, 
[2025-09-30 14:15:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:21] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:21] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.53, #queue-req: 0, 
[2025-09-30 14:15:21] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:15:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:22] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:22] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.32, #queue-req: 0, 
[2025-09-30 14:15:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:22] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:22] Prefill batch. #new-seq: 1, #new-token: 1086, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:22] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:23] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.70, #queue-req: 0, 
[2025-09-30 14:15:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:23] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:23] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.78, #queue-req: 0, 
[2025-09-30 14:15:23] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:15:23] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:15:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:24] Prefill batch. #new-seq: 1, #new-token: 1186, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:24] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:24] Decode batch. #running-req: 1, #token: 784, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.25, #queue-req: 0, 
[2025-09-30 14:15:25] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:15:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:25] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:25] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.00, #queue-req: 0, 
[2025-09-30 14:15:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:25] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:25] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.75, #queue-req: 0, 
[2025-09-30 14:15:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:25] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:26] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:26] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 651, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:26] Decode batch. #running-req: 1, #token: 656, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.40, #queue-req: 0, 
[2025-09-30 14:15:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:27] Prefill batch. #new-seq: 1, #new-token: 1182, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:27] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:27] Decode batch. #running-req: 1, #token: 804, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.31, #queue-req: 0, 
[2025-09-30 14:15:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:27] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:27] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.06, #queue-req: 0, 
[2025-09-30 14:15:28] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:15:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:28] Prefill batch. #new-seq: 1, #new-token: 1282, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:28] Prefill batch. #new-seq: 1, #new-token: 684, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:28] Decode batch. #running-req: 1, #token: 849, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.99, #queue-req: 0, 
[2025-09-30 14:15:29] Decode batch. #running-req: 1, #token: 889, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:15:29] Decode batch. #running-req: 1, #token: 929, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:15:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:29] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:29] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.67, #queue-req: 0, 
[2025-09-30 14:15:30] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:15:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:30] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:15:30] Prefill batch. #new-seq: 1, #new-token: 1282, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:30] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:30] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:30] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.88, #queue-req: 0, 
[2025-09-30 14:15:31] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:15:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:31] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:31] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:31] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.52, #queue-req: 0, 
[2025-09-30 14:15:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:32] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:32] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 672, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:32] Decode batch. #running-req: 1, #token: 686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.06, #queue-req: 0, 
[2025-09-30 14:15:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:32] Prefill batch. #new-seq: 1, #new-token: 1136, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:33] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:33] Decode batch. #running-req: 1, #token: 731, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.46, #queue-req: 0, 
[2025-09-30 14:15:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:33] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:33] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:15:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:34] Prefill batch. #new-seq: 1, #new-token: 1262, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:34] Prefill batch. #new-seq: 1, #new-token: 722, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:34] Decode batch. #running-req: 1, #token: 893, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.00, #queue-req: 0, 
[2025-09-30 14:15:34] Decode batch. #running-req: 1, #token: 933, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:15:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:34] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:34] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.20, #queue-req: 0, 
[2025-09-30 14:15:35] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:15:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:35] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:35] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.09, #queue-req: 0, 
[2025-09-30 14:15:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:35] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:36] Prefill batch. #new-seq: 1, #new-token: 1270, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:36] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 37.12, #queue-req: 0, 
[2025-09-30 14:15:36] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:36] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:36] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.91, #queue-req: 0, 
[2025-09-30 14:15:37] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:15:37] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:15:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:37] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:37] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:37] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.03, #queue-req: 0, 
[2025-09-30 14:15:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:38] Prefill batch. #new-seq: 1, #new-token: 780, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:38] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:38] Decode batch. #running-req: 1, #token: 417, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.58, #queue-req: 0, 
[2025-09-30 14:15:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:39] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:39] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.37, #queue-req: 0, 
[2025-09-30 14:15:39] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:15:39] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:15:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:40] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:40] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:40] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.53, #queue-req: 0, 
[2025-09-30 14:15:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:40] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:41] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.04, #queue-req: 0, 
[2025-09-30 14:15:41] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:15:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:41] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:41] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.56, #queue-req: 0, 
[2025-09-30 14:15:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:41] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:42] Prefill batch. #new-seq: 1, #new-token: 1208, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:42] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:42] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.45, #queue-req: 0, 
[2025-09-30 14:15:43] Decode batch. #running-req: 1, #token: 893, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:15:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:43] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:43] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.66, #queue-req: 0, 
[2025-09-30 14:15:43] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:15:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:43] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:44] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:44] Decode batch. #running-req: 1, #token: 752, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.62, #queue-req: 0, 
[2025-09-30 14:15:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:44] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:44] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 748, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:44] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.10, #queue-req: 0, 
[2025-09-30 14:15:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:45] Prefill batch. #new-seq: 1, #new-token: 1124, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:45] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:45] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.38, #queue-req: 0, 
[2025-09-30 14:15:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:46] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:46] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.03, #queue-req: 0, 
[2025-09-30 14:15:46] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:15:46] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:15:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:46] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:46] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:47] Prefill batch. #new-seq: 1, #new-token: 1021, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:47] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:47] Decode batch. #running-req: 1, #token: 742, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.66, #queue-req: 0, 
[2025-09-30 14:15:48] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:15:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:48] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:48] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.24, #queue-req: 0, 
[2025-09-30 14:15:48] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:15:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:49] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:49] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:49] Decode batch. #running-req: 1, #token: 649, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.44, #queue-req: 0, 
[2025-09-30 14:15:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:50] Prefill batch. #new-seq: 1, #new-token: 1056, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:50] Prefill batch. #new-seq: 1, #new-token: 482, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:50] Decode batch. #running-req: 1, #token: 663, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.67, #queue-req: 0, 
[2025-09-30 14:15:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:50] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:50] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.65, #queue-req: 0, 
[2025-09-30 14:15:50] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:15:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:51] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:51] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.55, #queue-req: 0, 
[2025-09-30 14:15:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:51] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:52] Prefill batch. #new-seq: 1, #new-token: 919, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:52] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:52] Decode batch. #running-req: 1, #token: 667, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.00, #queue-req: 0, 
[2025-09-30 14:15:52] Decode batch. #running-req: 1, #token: 707, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:15:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:53] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:53] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.00, #queue-req: 0, 
[2025-09-30 14:15:53] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:15:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:54] Prefill batch. #new-seq: 1, #new-token: 729, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:54] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.73, #queue-req: 0, 
[2025-09-30 14:15:54] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:54] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:54] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.48, #queue-req: 0, 
[2025-09-30 14:15:54] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:15:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:55] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:55] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:55] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.20, #queue-req: 0, 
[2025-09-30 14:15:55] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.27, #queue-req: 0, 
[2025-09-30 14:15:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:56] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:15:56] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:15:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:56] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:56] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:56] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.15, #queue-req: 0, 
[2025-09-30 14:15:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:57] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:57] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 287, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:57] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-09-30 14:15:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:58] Prefill batch. #new-seq: 1, #new-token: 1040, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:58] Prefill batch. #new-seq: 1, #new-token: 826, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:58] Decode batch. #running-req: 1, #token: 1005, token usage: 0.02, cuda graph: True, gen throughput (token/s): 46.78, #queue-req: 0, 
[2025-09-30 14:15:58] Decode batch. #running-req: 1, #token: 1045, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.52, #queue-req: 0, 
[2025-09-30 14:15:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:15:59] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:15:59] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.26, #queue-req: 0, 
[2025-09-30 14:15:59] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:15:59] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:16:00] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.07, #queue-req: 0, 
[2025-09-30 14:16:00] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.92, #queue-req: 0, 
[2025-09-30 14:16:00] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.76, #queue-req: 0, 
[2025-09-30 14:16:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:01] Prefill batch. #new-seq: 1, #new-token: 821, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:01] Decode batch. #running-req: 1, #token: 911, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.20, #queue-req: 0, 
[2025-09-30 14:16:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:01] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:02] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 891, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:02] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:03] Decode batch. #running-req: 1, #token: 2596, token usage: 0.04, cuda graph: True, gen throughput (token/s): 21.17, #queue-req: 0, 
[2025-09-30 14:16:03] Decode batch. #running-req: 1, #token: 2636, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.97, #queue-req: 0, 
[2025-09-30 14:16:03] Decode batch. #running-req: 1, #token: 2676, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.01, #queue-req: 0, 
[2025-09-30 14:16:04] Decode batch. #running-req: 1, #token: 2716, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.95, #queue-req: 0, 
[2025-09-30 14:16:04] Decode batch. #running-req: 1, #token: 2756, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.92, #queue-req: 0, 
[2025-09-30 14:16:04] Decode batch. #running-req: 1, #token: 2796, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.92, #queue-req: 0, 
[2025-09-30 14:16:04] Decode batch. #running-req: 1, #token: 2836, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.68, #queue-req: 0, 
[2025-09-30 14:16:05] Decode batch. #running-req: 1, #token: 2876, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 14:16:05] Decode batch. #running-req: 1, #token: 2916, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:16:05] Decode batch. #running-req: 1, #token: 2956, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:16:06] Decode batch. #running-req: 1, #token: 2996, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:16:06] Decode batch. #running-req: 1, #token: 3036, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:16:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:06] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:07] Decode batch. #running-req: 1, #token: 2568, token usage: 0.04, cuda graph: True, gen throughput (token/s): 92.07, #queue-req: 0, 
[2025-09-30 14:16:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:07] Prefill batch. #new-seq: 1, #new-token: 813, #cached-token: 189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:07] Decode batch. #running-req: 1, #token: 1032, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.45, #queue-req: 0, 
[2025-09-30 14:16:07] Decode batch. #running-req: 1, #token: 1072, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:16:07] Decode batch. #running-req: 1, #token: 1112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:16:08] Decode batch. #running-req: 1, #token: 1152, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 14:16:08] Decode batch. #running-req: 1, #token: 1192, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:16:08] Decode batch. #running-req: 1, #token: 1232, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:16:09] Decode batch. #running-req: 1, #token: 1272, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:16:09] Decode batch. #running-req: 1, #token: 1312, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.32, #queue-req: 0, 
[2025-09-30 14:16:09] Decode batch. #running-req: 1, #token: 1352, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:16:10] Decode batch. #running-req: 1, #token: 1392, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:16:10] Decode batch. #running-req: 1, #token: 1432, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:16:10] Decode batch. #running-req: 1, #token: 1472, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:16:11] Decode batch. #running-req: 1, #token: 1512, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:16:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:11] Prefill batch. #new-seq: 1, #new-token: 1592, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:11] Prefill batch. #new-seq: 1, #new-token: 774, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:11] Decode batch. #running-req: 1, #token: 965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 43.73, #queue-req: 0, 
[2025-09-30 14:16:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:12] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:12] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:16:12] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.58, #queue-req: 0, 
[2025-09-30 14:16:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:12] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:12] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:13] Decode batch. #running-req: 1, #token: 856, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.00, #queue-req: 0, 
[2025-09-30 14:16:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:13] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 838, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:13] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.90, #queue-req: 0, 
[2025-09-30 14:16:14] Prefill batch. #new-seq: 1, #new-token: 869, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:14] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:14] Decode batch. #running-req: 1, #token: 213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.28, #queue-req: 0, 
[2025-09-30 14:16:15] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:16:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:15] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:15] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.91, #queue-req: 0, 
[2025-09-30 14:16:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:15] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:16] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:16] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:16] Decode batch. #running-req: 1, #token: 368, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.34, #queue-req: 0, 
[2025-09-30 14:16:16] Decode batch. #running-req: 1, #token: 408, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.33, #queue-req: 0, 
[2025-09-30 14:16:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:16] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:17] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.74, #queue-req: 0, 
[2025-09-30 14:16:17] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:16:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:18] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:18] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:18] Decode batch. #running-req: 1, #token: 433, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.36, #queue-req: 0, 
[2025-09-30 14:16:18] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.87, #queue-req: 0, 
[2025-09-30 14:16:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:18] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:18] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.50, #queue-req: 0, 
[2025-09-30 14:16:19] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:16:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:19] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:19] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:20] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.14, #queue-req: 0, 
[2025-09-30 14:16:20] Decode batch. #running-req: 1, #token: 586, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:16:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:20] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:20] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.59, #queue-req: 0, 
[2025-09-30 14:16:20] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:16:21] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:16:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:21] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:21] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:22] Prefill batch. #new-seq: 1, #new-token: 783, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:22] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 35.32, #queue-req: 0, 
[2025-09-30 14:16:22] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:22] Decode batch. #running-req: 1, #token: 619, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.49, #queue-req: 0, 
[2025-09-30 14:16:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:22] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:23] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 14:16:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:23] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:16:23] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:23] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:24] Prefill batch. #new-seq: 1, #new-token: 887, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:24] Prefill batch. #new-seq: 1, #new-token: 477, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:24] Decode batch. #running-req: 1, #token: 649, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.69, #queue-req: 0, 
[2025-09-30 14:16:24] Decode batch. #running-req: 1, #token: 689, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 14:16:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:25] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:25] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.36, #queue-req: 0, 
[2025-09-30 14:16:25] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:16:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:25] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:26] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:26] Decode batch. #running-req: 1, #token: 551, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.62, #queue-req: 0, 
[2025-09-30 14:16:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:26] Prefill batch. #new-seq: 1, #new-token: 715, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:26] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:26] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.44, #queue-req: 0, 
[2025-09-30 14:16:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:27] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.40, #queue-req: 0, 
[2025-09-30 14:16:27] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:16:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:27] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:27] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.16, #queue-req: 0, 
[2025-09-30 14:16:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:27] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:28] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:28] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:28] Decode batch. #running-req: 1, #token: 450, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.09, #queue-req: 0, 
[2025-09-30 14:16:29] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.76, #queue-req: 0, 
[2025-09-30 14:16:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:29] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:29] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.31, #queue-req: 0, 
[2025-09-30 14:16:29] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:16:30] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:16:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:30] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:30] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:31] Decode batch. #running-req: 1, #token: 465, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.80, #queue-req: 0, 
[2025-09-30 14:16:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:31] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:31] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.98, #queue-req: 0, 
[2025-09-30 14:16:31] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:16:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:32] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:32] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:32] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.66, #queue-req: 0, 
[2025-09-30 14:16:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:32] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:32] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:16:33] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:16:33] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:16:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:34] Prefill batch. #new-seq: 1, #new-token: 2022, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:34] Decode batch. #running-req: 1, #token: 2398, token usage: 0.04, cuda graph: True, gen throughput (token/s): 43.75, #queue-req: 0, 
[2025-09-30 14:16:34] Decode batch. #running-req: 1, #token: 2438, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.57, #queue-req: 0, 
[2025-09-30 14:16:35] Decode batch. #running-req: 1, #token: 2478, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:16:35] Decode batch. #running-req: 1, #token: 2518, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:16:35] Decode batch. #running-req: 1, #token: 2558, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.55, #queue-req: 0, 
[2025-09-30 14:16:36] Decode batch. #running-req: 1, #token: 2598, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:16:36] Decode batch. #running-req: 1, #token: 2638, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.13, #queue-req: 0, 
[2025-09-30 14:16:36] Decode batch. #running-req: 1, #token: 2678, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:16:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:36] Prefill batch. #new-seq: 1, #new-token: 2022, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:37] Decode batch. #running-req: 1, #token: 2376, token usage: 0.04, cuda graph: True, gen throughput (token/s): 95.08, #queue-req: 0, 
[2025-09-30 14:16:37] Decode batch. #running-req: 1, #token: 2416, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:16:37] Decode batch. #running-req: 1, #token: 2456, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:16:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:37] Prefill batch. #new-seq: 1, #new-token: 813, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:38] Decode batch. #running-req: 1, #token: 980, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.57, #queue-req: 0, 
[2025-09-30 14:16:38] Decode batch. #running-req: 1, #token: 1020, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:16:38] Decode batch. #running-req: 1, #token: 1060, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:16:38] Decode batch. #running-req: 1, #token: 1100, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:16:39] Decode batch. #running-req: 1, #token: 1140, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:16:39] Decode batch. #running-req: 1, #token: 1180, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:16:39] Decode batch. #running-req: 1, #token: 1220, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:16:40] Decode batch. #running-req: 1, #token: 1260, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:16:40] Decode batch. #running-req: 1, #token: 1300, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.40, #queue-req: 0, 
[2025-09-30 14:16:40] Decode batch. #running-req: 1, #token: 1340, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:16:41] Decode batch. #running-req: 1, #token: 1380, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:16:41] Decode batch. #running-req: 1, #token: 1420, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:16:41] Decode batch. #running-req: 1, #token: 1460, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:16:42] Decode batch. #running-req: 1, #token: 1500, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:16:42] Decode batch. #running-req: 1, #token: 1540, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.98, #queue-req: 0, 
[2025-09-30 14:16:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:43] Prefill batch. #new-seq: 1, #new-token: 534, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:43] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:43] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.27, #queue-req: 0, 
[2025-09-30 14:16:43] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:16:43] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.94, #queue-req: 0, 
[2025-09-30 14:16:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:43] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:44] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 14:16:44] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:16:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:44] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:44] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:44] Decode batch. #running-req: 1, #token: 405, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.60, #queue-req: 0, 
[2025-09-30 14:16:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:45] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:45] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 383, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:45] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.39, #queue-req: 0, 
[2025-09-30 14:16:46] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:46] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:46] Decode batch. #running-req: 1, #token: 655, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.85, #queue-req: 0, 
[2025-09-30 14:16:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:46] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:46] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:16:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:47] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:47] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.20, #queue-req: 0, 
[2025-09-30 14:16:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:47] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:47] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.05, #queue-req: 0, 
[2025-09-30 14:16:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:48] Prefill batch. #new-seq: 1, #new-token: 1020, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:48] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:48] Decode batch. #running-req: 1, #token: 769, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.02, #queue-req: 0, 
[2025-09-30 14:16:48] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 14:16:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:48] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:49] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.59, #queue-req: 0, 
[2025-09-30 14:16:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:49] Prefill batch. #new-seq: 1, #new-token: 1069, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:49] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:49] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.59, #queue-req: 0, 
[2025-09-30 14:16:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:49] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:49] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.19, #queue-req: 0, 
[2025-09-30 14:16:50] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:16:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:50] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:50] Prefill batch. #new-seq: 1, #new-token: 495, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:50] Decode batch. #running-req: 1, #token: 583, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.97, #queue-req: 0, 
[2025-09-30 14:16:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:51] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 566, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:51] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.95, #queue-req: 0, 
[2025-09-30 14:16:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:52] Prefill batch. #new-seq: 1, #new-token: 869, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:52] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:52] Decode batch. #running-req: 1, #token: 568, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.74, #queue-req: 0, 
[2025-09-30 14:16:52] Decode batch. #running-req: 1, #token: 608, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.87, #queue-req: 0, 
[2025-09-30 14:16:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:52] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:53] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:16:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:53] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:53] Prefill batch. #new-seq: 1, #new-token: 561, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:53] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.80, #queue-req: 0, 
[2025-09-30 14:16:53] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:16:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:54] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:54] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:16:54] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:16:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:55] Prefill batch. #new-seq: 1, #new-token: 1092, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:55] Prefill batch. #new-seq: 1, #new-token: 535, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:55] Decode batch. #running-req: 1, #token: 727, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.87, #queue-req: 0, 
[2025-09-30 14:16:55] Decode batch. #running-req: 1, #token: 767, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:16:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:55] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:56] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:16:56] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:16:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:57] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:57] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:57] Prefill batch. #new-seq: 1, #new-token: 3201, #cached-token: 0, token usage: 0.06, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:57] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:57] Decode batch. #running-req: 1, #token: 342, token usage: 0.01, cuda graph: True, gen throughput (token/s): 27.51, #queue-req: 0, 
[2025-09-30 14:16:58] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.31, #queue-req: 0, 
[2025-09-30 14:16:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:58] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:58] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 14:16:58] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:16:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:58] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:59] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.70, #queue-req: 0, 
[2025-09-30 14:16:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:59] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.63, #queue-req: 0, 
[2025-09-30 14:16:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 233, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:59] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:16:59] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:16:59] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.15, #queue-req: 0, 
[2025-09-30 14:17:00] Decode batch. #running-req: 1, #token: 404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.30, #queue-req: 0, 
[2025-09-30 14:17:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:00] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:00] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.01, #queue-req: 0, 
[2025-09-30 14:17:00] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:17:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:00] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:01] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:01] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.15, #queue-req: 0, 
[2025-09-30 14:17:01] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:01] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:01] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.44, #queue-req: 0, 
[2025-09-30 14:17:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:01] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:01] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.85, #queue-req: 0, 
[2025-09-30 14:17:02] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:17:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:02] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:02] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:02] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.69, #queue-req: 0, 
[2025-09-30 14:17:02] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.41, #queue-req: 0, 
[2025-09-30 14:17:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:03] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:03] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:17:03] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:17:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:03] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:03] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:03] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.38, #queue-req: 0, 
[2025-09-30 14:17:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:04] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:04] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.17, #queue-req: 0, 
[2025-09-30 14:17:04] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:17:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:04] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.95, #queue-req: 0, 
[2025-09-30 14:17:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:05] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:05] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:05] Decode batch. #running-req: 1, #token: 1215, token usage: 0.02, cuda graph: True, gen throughput (token/s): 99.20, #queue-req: 0, 
[2025-09-30 14:17:05] Decode batch. #running-req: 1, #token: 1255, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.66, #queue-req: 0, 
[2025-09-30 14:17:05] Decode batch. #running-req: 1, #token: 1295, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 14:17:06] Decode batch. #running-req: 1, #token: 1335, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 14:17:06] Decode batch. #running-req: 1, #token: 1375, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:17:06] Decode batch. #running-req: 1, #token: 1415, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:17:07] Decode batch. #running-req: 1, #token: 1455, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:17:07] Decode batch. #running-req: 1, #token: 1495, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:17:07] Decode batch. #running-req: 1, #token: 1535, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:17:08] Decode batch. #running-req: 1, #token: 1575, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.64, #queue-req: 0, 
[2025-09-30 14:17:08] Decode batch. #running-req: 1, #token: 1615, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:17:08] Decode batch. #running-req: 1, #token: 1655, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:17:08] Decode batch. #running-req: 1, #token: 1695, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:17:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:09] Prefill batch. #new-seq: 1, #new-token: 866, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:09] Decode batch. #running-req: 1, #token: 1193, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.71, #queue-req: 0, 
[2025-09-30 14:17:09] Decode batch. #running-req: 1, #token: 1233, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:17:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:09] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:10] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:10] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.38, #queue-req: 0, 
[2025-09-30 14:17:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:10] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:10] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:17:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:10] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:10] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:10] Decode batch. #running-req: 1, #token: 417, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.67, #queue-req: 0, 
[2025-09-30 14:17:11] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.15, #queue-req: 0, 
[2025-09-30 14:17:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:11] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:11] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 14:17:11] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:17:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:11] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:12] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.96, #queue-req: 0, 
[2025-09-30 14:17:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:12] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:12] Prefill batch. #new-seq: 1, #new-token: 459, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:12] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:12] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.17, #queue-req: 0, 
[2025-09-30 14:17:12] Decode batch. #running-req: 1, #token: 441, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.22, #queue-req: 0, 
[2025-09-30 14:17:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:12] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:13] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 14:17:13] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:17:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:13] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:13] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:13] Decode batch. #running-req: 1, #token: 423, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.16, #queue-req: 0, 
[2025-09-30 14:17:14] Decode batch. #running-req: 1, #token: 463, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.14, #queue-req: 0, 
[2025-09-30 14:17:14] Decode batch. #running-req: 1, #token: 503, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.87, #queue-req: 0, 
[2025-09-30 14:17:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:14] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:14] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:17:15] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:17:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:15] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:15] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:15] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.65, #queue-req: 0, 
[2025-09-30 14:17:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:15] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:15] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:17:16] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:17:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:16] Prefill batch. #new-seq: 1, #new-token: 1897, #cached-token: 342, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:16] Decode batch. #running-req: 1, #token: 2247, token usage: 0.04, cuda graph: True, gen throughput (token/s): 84.26, #queue-req: 0, 
[2025-09-30 14:17:16] Decode batch. #running-req: 1, #token: 2287, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.10, #queue-req: 0, 
[2025-09-30 14:17:17] Decode batch. #running-req: 1, #token: 2327, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.83, #queue-req: 0, 
[2025-09-30 14:17:17] Decode batch. #running-req: 1, #token: 2367, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:17:17] Decode batch. #running-req: 1, #token: 2407, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:17:18] Decode batch. #running-req: 1, #token: 2447, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.53, #queue-req: 0, 
[2025-09-30 14:17:18] Decode batch. #running-req: 1, #token: 2487, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.51, #queue-req: 0, 
[2025-09-30 14:17:18] Decode batch. #running-req: 1, #token: 2527, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.52, #queue-req: 0, 
[2025-09-30 14:17:19] Decode batch. #running-req: 1, #token: 2567, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.48, #queue-req: 0, 
[2025-09-30 14:17:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:19] Prefill batch. #new-seq: 1, #new-token: 1897, #cached-token: 322, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:19] Decode batch. #running-req: 1, #token: 2248, token usage: 0.04, cuda graph: True, gen throughput (token/s): 95.86, #queue-req: 0, 
[2025-09-30 14:17:19] Decode batch. #running-req: 1, #token: 2288, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:17:20] Decode batch. #running-req: 1, #token: 2328, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.92, #queue-req: 0, 
[2025-09-30 14:17:20] Decode batch. #running-req: 1, #token: 2368, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.71, #queue-req: 0, 
[2025-09-30 14:17:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:20] Prefill batch. #new-seq: 1, #new-token: 750, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:20] Decode batch. #running-req: 1, #token: 912, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.59, #queue-req: 0, 
[2025-09-30 14:17:21] Decode batch. #running-req: 1, #token: 952, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:17:21] Decode batch. #running-req: 1, #token: 992, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.40, #queue-req: 0, 
[2025-09-30 14:17:21] Decode batch. #running-req: 1, #token: 1032, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.34, #queue-req: 0, 
[2025-09-30 14:17:22] Decode batch. #running-req: 1, #token: 1072, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 14:17:22] Decode batch. #running-req: 1, #token: 1112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:17:22] Decode batch. #running-req: 1, #token: 1152, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:17:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:22] Prefill batch. #new-seq: 1, #new-token: 634, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:22] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:23] Decode batch. #running-req: 1, #token: 630, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.75, #queue-req: 0, 
[2025-09-30 14:17:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:23] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:23] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.58, #queue-req: 0, 
[2025-09-30 14:17:23] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:17:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:23] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:23] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] Decode batch. #running-req: 1, #token: 526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.50, #queue-req: 0, 
[2025-09-30 14:17:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:24] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 513, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:24] Prefill batch. #new-seq: 1, #new-token: 816, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.94, #queue-req: 0, 
[2025-09-30 14:17:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:24] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:24] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:24] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.55, #queue-req: 0, 
[2025-09-30 14:17:25] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:17:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:25] Prefill batch. #new-seq: 1, #new-token: 932, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:25] Prefill batch. #new-seq: 1, #new-token: 560, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:25] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 84.79, #queue-req: 0, 
[2025-09-30 14:17:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:25] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:26] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.55, #queue-req: 0, 
[2025-09-30 14:17:26] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:17:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:26] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:26] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:26] Decode batch. #running-req: 1, #token: 634, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.65, #queue-req: 0, 
[2025-09-30 14:17:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:26] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:26] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 628, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:27] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 96.88, #queue-req: 0, 
[2025-09-30 14:17:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:27] Prefill batch. #new-seq: 1, #new-token: 1100, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:27] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:27] Decode batch. #running-req: 1, #token: 739, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.86, #queue-req: 0, 
[2025-09-30 14:17:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:27] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:27] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 14:17:28] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:17:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:28] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:28] Prefill batch. #new-seq: 1, #new-token: 543, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:28] Decode batch. #running-req: 1, #token: 620, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.43, #queue-req: 0, 
[2025-09-30 14:17:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:28] Prefill batch. #new-seq: 1, #new-token: 1132, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:28] Prefill batch. #new-seq: 1, #new-token: 591, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:29] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 84.01, #queue-req: 0, 
[2025-09-30 14:17:29] Decode batch. #running-req: 1, #token: 814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.01, #queue-req: 0, 
[2025-09-30 14:17:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:29] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:29] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 14:17:29] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:17:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:30] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:30] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:30] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 88.22, #queue-req: 0, 
[2025-09-30 14:17:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:30] Prefill batch. #new-seq: 1, #new-token: 1245, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:30] Prefill batch. #new-seq: 1, #new-token: 661, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:30] Decode batch. #running-req: 1, #token: 851, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.33, #queue-req: 0, 
[2025-09-30 14:17:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:31] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:31] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:17:31] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:17:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:31] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:31] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.64, #queue-req: 0, 
[2025-09-30 14:17:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:31] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:32] Prefill batch. #new-seq: 1, #new-token: 1447, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:32] Prefill batch. #new-seq: 1, #new-token: 792, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:32] Decode batch. #running-req: 1, #token: 967, token usage: 0.02, cuda graph: True, gen throughput (token/s): 70.48, #queue-req: 0, 
[2025-09-30 14:17:32] Decode batch. #running-req: 1, #token: 1007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 14:17:33] Decode batch. #running-req: 1, #token: 1047, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.29, #queue-req: 0, 
[2025-09-30 14:17:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:33] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:33] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.07, #queue-req: 0, 
[2025-09-30 14:17:33] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:17:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:33] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:33] Prefill batch. #new-seq: 1, #new-token: 788, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:34] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:34] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.75, #queue-req: 0, 
[2025-09-30 14:17:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:34] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 860, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:34] Prefill batch. #new-seq: 1, #new-token: 1455, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:34] Prefill batch. #new-seq: 1, #new-token: 669, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:34] Decode batch. #running-req: 1, #token: 836, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.08, #queue-req: 0, 
[2025-09-30 14:17:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:34] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:35] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.86, #queue-req: 0, 
[2025-09-30 14:17:35] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:17:35] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:17:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:35] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:35] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:36] Decode batch. #running-req: 1, #token: 751, token usage: 0.01, cuda graph: True, gen throughput (token/s): 88.18, #queue-req: 0, 
[2025-09-30 14:17:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:36] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:36] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:36] Decode batch. #running-req: 1, #token: 912, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.50, #queue-req: 0, 
[2025-09-30 14:17:36] Decode batch. #running-req: 1, #token: 952, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:17:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:36] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:37] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:17:37] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:17:37] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:17:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:37] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:38] Prefill batch. #new-seq: 1, #new-token: 719, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:38] Decode batch. #running-req: 1, #token: 795, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.91, #queue-req: 0, 
[2025-09-30 14:17:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:38] Prefill batch. #new-seq: 1, #new-token: 1481, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:38] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:38] Decode batch. #running-req: 1, #token: 940, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.04, #queue-req: 0, 
[2025-09-30 14:17:39] Decode batch. #running-req: 1, #token: 980, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:17:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:39] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:39] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.28, #queue-req: 0, 
[2025-09-30 14:17:39] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:17:39] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.15, #queue-req: 0, 
[2025-09-30 14:17:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:40] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:40] Prefill batch. #new-seq: 1, #new-token: 760, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:40] Prefill batch. #new-seq: 1, #new-token: 1443, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:40] Prefill batch. #new-seq: 1, #new-token: 684, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:40] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.03, #queue-req: 0, 
[2025-09-30 14:17:40] Decode batch. #running-req: 1, #token: 893, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 14:17:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:40] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:41] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:17:41] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:17:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:41] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:41] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:42] Prefill batch. #new-seq: 1, #new-token: 815, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:42] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:42] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.66, #queue-req: 0, 
[2025-09-30 14:17:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:42] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:42] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.25, #queue-req: 0, 
[2025-09-30 14:17:42] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:17:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:42] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:43] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] Decode batch. #running-req: 1, #token: 209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.12, #queue-req: 0, 
[2025-09-30 14:17:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:43] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.54, #queue-req: 0, 
[2025-09-30 14:17:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 205, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:43] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:43] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:43] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.05, #queue-req: 0, 
[2025-09-30 14:17:44] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.90, #queue-req: 0, 
[2025-09-30 14:17:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:44] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:44] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:17:44] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:17:45] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:17:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:45] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:45] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:45] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.67, #queue-req: 0, 
[2025-09-30 14:17:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:45] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:45] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:46] Decode batch. #running-req: 1, #token: 402, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.38, #queue-req: 0, 
[2025-09-30 14:17:46] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.42, #queue-req: 0, 
[2025-09-30 14:17:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:46] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:46] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:17:47] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:17:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:47] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:47] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.66, #queue-req: 0, 
[2025-09-30 14:17:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:47] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:47] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:47] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 89.66, #queue-req: 0, 
[2025-09-30 14:17:47] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:48] Decode batch. #running-req: 1, #token: 476, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.50, #queue-req: 0, 
[2025-09-30 14:17:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:48] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:48] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.48, #queue-req: 0, 
[2025-09-30 14:17:48] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:17:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:48] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:49] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:49] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.09, #queue-req: 0, 
[2025-09-30 14:17:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:49] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:49] Decode batch. #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.15, #queue-req: 0, 
[2025-09-30 14:17:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:49] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:49] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:49] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:50] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.58, #queue-req: 0, 
[2025-09-30 14:17:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:50] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:50] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.95, #queue-req: 0, 
[2025-09-30 14:17:50] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:17:51] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 14:17:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:51] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:51] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:51] Decode batch. #running-req: 1, #token: 403, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.59, #queue-req: 0, 
[2025-09-30 14:17:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:51] Prefill batch. #new-seq: 1, #new-token: 937, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:51] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:51] Decode batch. #running-req: 1, #token: 825, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.03, #queue-req: 0, 
[2025-09-30 14:17:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:52] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:52] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.84, #queue-req: 0, 
[2025-09-30 14:17:52] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:17:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:52] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:52] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.59, #queue-req: 0, 
[2025-09-30 14:17:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:52] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:53] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:53] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.77, #queue-req: 0, 
[2025-09-30 14:17:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:53] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 696, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:53] Prefill batch. #new-seq: 1, #new-token: 1267, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:53] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:53] Decode batch. #running-req: 1, #token: 821, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.16, #queue-req: 0, 
[2025-09-30 14:17:54] Decode batch. #running-req: 1, #token: 861, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.01, #queue-req: 0, 
[2025-09-30 14:17:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:54] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:54] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.03, #queue-req: 0, 
[2025-09-30 14:17:54] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:17:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:55] Prefill batch. #new-seq: 1, #new-token: 1235, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:55] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:55] Decode batch. #running-req: 1, #token: 829, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.63, #queue-req: 0, 
[2025-09-30 14:17:55] Decode batch. #running-req: 1, #token: 869, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:17:55] Decode batch. #running-req: 1, #token: 909, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:17:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:55] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:56] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.26, #queue-req: 0, 
[2025-09-30 14:17:56] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:17:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:56] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:56] Prefill batch. #new-seq: 1, #new-token: 584, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:56] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.17, #queue-req: 0, 
[2025-09-30 14:17:57] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.38, #queue-req: 0, 
[2025-09-30 14:17:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:57] Prefill batch. #new-seq: 1, #new-token: 1289, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:57] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:57] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.12, #queue-req: 0, 
[2025-09-30 14:17:58] Decode batch. #running-req: 1, #token: 926, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:17:58] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:17:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:58] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:58] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.58, #queue-req: 0, 
[2025-09-30 14:17:59] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:17:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:59] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:59] Prefill batch. #new-seq: 1, #new-token: 704, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:59] Prefill batch. #new-seq: 1, #new-token: 1227, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:17:59] Prefill batch. #new-seq: 1, #new-token: 519, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:17:59] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.25, #queue-req: 0, 
[2025-09-30 14:18:00] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.58, #queue-req: 0, 
[2025-09-30 14:18:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:00] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 202, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:00] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.08, #queue-req: 0, 
[2025-09-30 14:18:00] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:18:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:00] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:01] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.31, #queue-req: 0, 
[2025-09-30 14:18:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:01] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:01] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:01] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 593, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:01] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.34, #queue-req: 0, 
[2025-09-30 14:18:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:01] Prefill batch. #new-seq: 1, #new-token: 1254, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:01] Prefill batch. #new-seq: 1, #new-token: 741, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:02] Decode batch. #running-req: 1, #token: 938, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.64, #queue-req: 0, 
[2025-09-30 14:18:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:02] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:02] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.86, #queue-req: 0, 
[2025-09-30 14:18:02] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:18:02] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.09, #queue-req: 0, 
[2025-09-30 14:18:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:03] Prefill batch. #new-seq: 1, #new-token: 1426, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:03] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:03] Decode batch. #running-req: 1, #token: 865, token usage: 0.01, cuda graph: True, gen throughput (token/s): 94.46, #queue-req: 0, 
[2025-09-30 14:18:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:03] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:03] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.62, #queue-req: 0, 
[2025-09-30 14:18:04] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:18:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:04] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.46, #queue-req: 0, 
[2025-09-30 14:18:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:04] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:04] Decode batch. #running-req: 1, #token: 787, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.27, #queue-req: 0, 
[2025-09-30 14:18:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:05] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 759, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:05] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:05] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 61.14, #queue-req: 0, 
[2025-09-30 14:18:05] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:18:06] Decode batch. #running-req: 1, #token: 1652, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:18:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:06] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:06] Decode batch. #running-req: 1, #token: 1576, token usage: 0.02, cuda graph: True, gen throughput (token/s): 105.51, #queue-req: 0, 
[2025-09-30 14:18:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:06] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:06] Decode batch. #running-req: 1, #token: 547, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.61, #queue-req: 0, 
[2025-09-30 14:18:07] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.79, #queue-req: 0, 
[2025-09-30 14:18:07] Decode batch. #running-req: 1, #token: 627, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.64, #queue-req: 0, 
[2025-09-30 14:18:07] Decode batch. #running-req: 1, #token: 667, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.45, #queue-req: 0, 
[2025-09-30 14:18:07] Decode batch. #running-req: 1, #token: 707, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.36, #queue-req: 0, 
[2025-09-30 14:18:08] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:18:08] Decode batch. #running-req: 1, #token: 787, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:18:08] Decode batch. #running-req: 1, #token: 827, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:18:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:09] Prefill batch. #new-seq: 1, #new-token: 1408, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:09] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:09] Decode batch. #running-req: 1, #token: 895, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.52, #queue-req: 0, 
[2025-09-30 14:18:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:09] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:09] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.35, #queue-req: 0, 
[2025-09-30 14:18:10] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:18:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:10] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:10] Prefill batch. #new-seq: 1, #new-token: 717, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:10] Decode batch. #running-req: 1, #token: 805, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.68, #queue-req: 0, 
[2025-09-30 14:18:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:10] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:10] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.92, #queue-req: 0, 
[2025-09-30 14:18:11] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.79, #queue-req: 0, 
[2025-09-30 14:18:11] Decode batch. #running-req: 1, #token: 625, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.61, #queue-req: 0, 
[2025-09-30 14:18:11] Decode batch. #running-req: 1, #token: 665, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.54, #queue-req: 0, 
[2025-09-30 14:18:12] Decode batch. #running-req: 1, #token: 705, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.37, #queue-req: 0, 
[2025-09-30 14:18:12] Decode batch. #running-req: 1, #token: 745, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.28, #queue-req: 0, 
[2025-09-30 14:18:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:12] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:12] Decode batch. #running-req: 1, #token: 509, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.23, #queue-req: 0, 
[2025-09-30 14:18:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:13] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:13] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.06, #queue-req: 0, 
[2025-09-30 14:18:13] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.07, #queue-req: 0, 
[2025-09-30 14:18:13] Decode batch. #running-req: 1, #token: 818, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.73, #queue-req: 0, 
[2025-09-30 14:18:14] Decode batch. #running-req: 1, #token: 858, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:18:14] Decode batch. #running-req: 1, #token: 898, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.63, #queue-req: 0, 
[2025-09-30 14:18:14] Decode batch. #running-req: 1, #token: 938, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:18:14] Decode batch. #running-req: 1, #token: 978, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:18:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:15] Prefill batch. #new-seq: 1, #new-token: 1477, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:15] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:15] Decode batch. #running-req: 1, #token: 932, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.66, #queue-req: 0, 
[2025-09-30 14:18:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:15] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:15] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.90, #queue-req: 0, 
[2025-09-30 14:18:16] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:18:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:16] Prefill batch. #new-seq: 1, #new-token: 1499, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:16] Prefill batch. #new-seq: 1, #new-token: 743, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:16] Decode batch. #running-req: 1, #token: 915, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.83, #queue-req: 0, 
[2025-09-30 14:18:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:16] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:17] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.80, #queue-req: 0, 
[2025-09-30 14:18:17] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:18:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:17] Prefill batch. #new-seq: 1, #new-token: 1470, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:17] Prefill batch. #new-seq: 1, #new-token: 728, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:17] Decode batch. #running-req: 1, #token: 901, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.56, #queue-req: 0, 
[2025-09-30 14:18:18] Decode batch. #running-req: 1, #token: 941, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:18:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:18] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:18] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.72, #queue-req: 0, 
[2025-09-30 14:18:18] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:18:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:19] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:19] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.15, #queue-req: 0, 
[2025-09-30 14:18:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:19] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:19] Decode batch. #running-req: 1, #token: 822, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.61, #queue-req: 0, 
[2025-09-30 14:18:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:19] Prefill batch. #new-seq: 1, #new-token: 1411, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:19] Prefill batch. #new-seq: 1, #new-token: 679, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:20] Decode batch. #running-req: 1, #token: 883, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.67, #queue-req: 0, 
[2025-09-30 14:18:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:20] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 206, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:20] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.80, #queue-req: 0, 
[2025-09-30 14:18:20] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:18:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:21] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:21] Prefill batch. #new-seq: 1, #new-token: 675, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:21] Decode batch. #running-req: 1, #token: 760, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.41, #queue-req: 0, 
[2025-09-30 14:18:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:21] Prefill batch. #new-seq: 1, #new-token: 1241, #cached-token: 88, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:21] Prefill batch. #new-seq: 1, #new-token: 568, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:21] Decode batch. #running-req: 1, #token: 747, token usage: 0.01, cuda graph: True, gen throughput (token/s): 75.69, #queue-req: 0, 
[2025-09-30 14:18:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:21] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:22] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:18:22] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:22] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:22] Prefill batch. #new-seq: 1, #new-token: 564, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:23] Prefill batch. #new-seq: 1, #new-token: 1019, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:23] Prefill batch. #new-seq: 1, #new-token: 454, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:23] Decode batch. #running-req: 1, #token: 624, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.83, #queue-req: 0, 
[2025-09-30 14:18:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:23] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:23] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.29, #queue-req: 0, 
[2025-09-30 14:18:23] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:18:24] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:18:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:24] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:24] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:24] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:24] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.27, #queue-req: 0, 
[2025-09-30 14:18:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 525, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:25] Prefill batch. #new-seq: 1, #new-token: 625, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:25] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:25] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.28, #queue-req: 0, 
[2025-09-30 14:18:25] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.38, #queue-req: 0, 
[2025-09-30 14:18:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:25] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:25] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.92, #queue-req: 0, 
[2025-09-30 14:18:26] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:18:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:26] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:26] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:26] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.18, #queue-req: 0, 
[2025-09-30 14:18:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:26] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:26] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 245, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:26] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.12, #queue-req: 0, 
[2025-09-30 14:18:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:27] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:27] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:27] Decode batch. #running-req: 1, #token: 534, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.99, #queue-req: 0, 
[2025-09-30 14:18:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:27] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:27] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.54, #queue-req: 0, 
[2025-09-30 14:18:28] Decode batch. #running-req: 1, #token: 446, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.95, #queue-req: 0, 
[2025-09-30 14:18:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:28] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.71, #queue-req: 0, 
[2025-09-30 14:18:28] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:28] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:28] Prefill batch. #new-seq: 1, #new-token: 825, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:28] Prefill batch. #new-seq: 1, #new-token: 495, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:29] Decode batch. #running-req: 1, #token: 666, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.93, #queue-req: 0, 
[2025-09-30 14:18:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:29] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:29] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.55, #queue-req: 0, 
[2025-09-30 14:18:29] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:18:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:29] Prefill batch. #new-seq: 1, #new-token: 1007, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:30] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:30] Decode batch. #running-req: 1, #token: 684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.93, #queue-req: 0, 
[2025-09-30 14:18:30] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:18:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:30] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 204, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:30] Decode batch. #running-req: 1, #token: 385, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.78, #queue-req: 0, 
[2025-09-30 14:18:31] Decode batch. #running-req: 1, #token: 425, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.83, #queue-req: 0, 
[2025-09-30 14:18:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:31] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:31] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:31] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.65, #queue-req: 0, 
[2025-09-30 14:18:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:31] Prefill batch. #new-seq: 1, #new-token: 869, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:31] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:32] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.36, #queue-req: 0, 
[2025-09-30 14:18:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:32] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:32] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:18:32] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:18:32] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:18:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:32] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:33] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:33] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:33] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.96, #queue-req: 0, 
[2025-09-30 14:18:33] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:33] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.30, #queue-req: 0, 
[2025-09-30 14:18:34] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.14, #queue-req: 0, 
[2025-09-30 14:18:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:34] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 14:18:34] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:18:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:35] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:35] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:35] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.79, #queue-req: 0, 
[2025-09-30 14:18:35] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.15, #queue-req: 0, 
[2025-09-30 14:18:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:35] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:36] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.00, #queue-req: 0, 
[2025-09-30 14:18:36] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:18:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:36] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:36] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:36] Decode batch. #running-req: 1, #token: 618, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.01, #queue-req: 0, 
[2025-09-30 14:18:37] Decode batch. #running-req: 1, #token: 658, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.79, #queue-req: 0, 
[2025-09-30 14:18:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:37] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:37] Decode batch. #running-req: 1, #token: 226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.88, #queue-req: 0, 
[2025-09-30 14:18:37] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:18:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:38] Prefill batch. #new-seq: 1, #new-token: 2292, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:38] Decode batch. #running-req: 1, #token: 2633, token usage: 0.04, cuda graph: True, gen throughput (token/s): 65.69, #queue-req: 0, 
[2025-09-30 14:18:38] Decode batch. #running-req: 1, #token: 2673, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:18:39] Decode batch. #running-req: 1, #token: 2713, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:18:39] Decode batch. #running-req: 1, #token: 2753, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:18:39] Decode batch. #running-req: 1, #token: 2793, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 14:18:39] Decode batch. #running-req: 1, #token: 2833, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.78, #queue-req: 0, 
[2025-09-30 14:18:40] Decode batch. #running-req: 1, #token: 2873, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:18:40] Decode batch. #running-req: 1, #token: 2913, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:18:40] Decode batch. #running-req: 1, #token: 2953, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:18:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:41] Prefill batch. #new-seq: 1, #new-token: 2292, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:41] Decode batch. #running-req: 1, #token: 2636, token usage: 0.04, cuda graph: True, gen throughput (token/s): 91.48, #queue-req: 0, 
[2025-09-30 14:18:41] Decode batch. #running-req: 1, #token: 2676, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:18:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:41] Prefill batch. #new-seq: 1, #new-token: 535, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:42] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.07, #queue-req: 0, 
[2025-09-30 14:18:42] Decode batch. #running-req: 1, #token: 722, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.31, #queue-req: 0, 
[2025-09-30 14:18:42] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.18, #queue-req: 0, 
[2025-09-30 14:18:42] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.78, #queue-req: 0, 
[2025-09-30 14:18:43] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.74, #queue-req: 0, 
[2025-09-30 14:18:43] Decode batch. #running-req: 1, #token: 882, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.65, #queue-req: 0, 
[2025-09-30 14:18:43] Decode batch. #running-req: 1, #token: 922, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.53, #queue-req: 0, 
[2025-09-30 14:18:44] Decode batch. #running-req: 1, #token: 962, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:18:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:44] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:44] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:44] Decode batch. #running-req: 1, #token: 463, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.25, #queue-req: 0, 
[2025-09-30 14:18:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:45] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:45] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0, 
[2025-09-30 14:18:45] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:18:45] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:45] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:45] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:46] Prefill batch. #new-seq: 1, #new-token: 850, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:46] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:46] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.39, #queue-req: 0, 
[2025-09-30 14:18:46] Decode batch. #running-req: 1, #token: 778, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.30, #queue-req: 0, 
[2025-09-30 14:18:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:46] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:47] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.87, #queue-req: 0, 
[2025-09-30 14:18:47] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:47] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:47] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.88, #queue-req: 0, 
[2025-09-30 14:18:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:47] Prefill batch. #new-seq: 1, #new-token: 563, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:48] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:48] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 635, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:48] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.86, #queue-req: 0, 
[2025-09-30 14:18:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:48] Prefill batch. #new-seq: 1, #new-token: 1167, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:48] Prefill batch. #new-seq: 1, #new-token: 606, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:48] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.65, #queue-req: 0, 
[2025-09-30 14:18:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:48] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:49] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 14:18:49] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:18:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:49] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:49] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:50] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:50] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.53, #queue-req: 0, 
[2025-09-30 14:18:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:50] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 674, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:50] Prefill batch. #new-seq: 1, #new-token: 889, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:50] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:50] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.82, #queue-req: 0, 
[2025-09-30 14:18:50] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.88, #queue-req: 0, 
[2025-09-30 14:18:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:50] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:51] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.66, #queue-req: 0, 
[2025-09-30 14:18:51] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:51] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:51] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:52] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:52] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.70, #queue-req: 0, 
[2025-09-30 14:18:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:52] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 357, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:52] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:52] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:52] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.80, #queue-req: 0, 
[2025-09-30 14:18:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:53] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:53] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.08, #queue-req: 0, 
[2025-09-30 14:18:53] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:53] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:18:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:53] Prefill batch. #new-seq: 1, #new-token: 1011, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:54] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:54] Decode batch. #running-req: 1, #token: 725, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.29, #queue-req: 0, 
[2025-09-30 14:18:54] Decode batch. #running-req: 1, #token: 765, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:18:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:54] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:54] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.89, #queue-req: 0, 
[2025-09-30 14:18:55] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 14:18:55] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.01, #queue-req: 0, 
[2025-09-30 14:18:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:55] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:55] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:55] Prefill batch. #new-seq: 1, #new-token: 763, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:55] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:56] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.33, #queue-req: 0, 
[2025-09-30 14:18:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:56] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.14, #queue-req: 0, 
[2025-09-30 14:18:56] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:56] Decode batch. #running-req: 1, #token: 440, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 14:18:56] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.68, #queue-req: 0, 
[2025-09-30 14:18:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:57] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:57] Decode batch. #running-req: 1, #token: 109, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.84, #queue-req: 0, 
[2025-09-30 14:18:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:57] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:57] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:57] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:57] Decode batch. #running-req: 1, #token: 441, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.23, #queue-req: 0, 
[2025-09-30 14:18:58] Decode batch. #running-req: 1, #token: 481, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.86, #queue-req: 0, 
[2025-09-30 14:18:58] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.46, #queue-req: 0, 
[2025-09-30 14:18:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:58] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:58] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0, 
[2025-09-30 14:18:59] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:18:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:59] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:59] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.95, #queue-req: 0, 
[2025-09-30 14:18:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:18:59] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:18:59] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.82, #queue-req: 0, 
[2025-09-30 14:18:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:00] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:00] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 334, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:00] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.76, #queue-req: 0, 
[2025-09-30 14:19:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:00] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.92, #queue-req: 0, 
[2025-09-30 14:19:00] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:00] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:01] Decode batch. #running-req: 1, #token: 538, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.49, #queue-req: 0, 
[2025-09-30 14:19:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:01] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 14:19:01] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:19:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:02] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:02] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:02] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 108.11, #queue-req: 0, 
[2025-09-30 14:19:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:02] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:02] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.48, #queue-req: 0, 
[2025-09-30 14:19:02] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:19:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:03] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:03] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.93, #queue-req: 0, 
[2025-09-30 14:19:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:03] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:03] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:03] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:03] Decode batch. #running-req: 1, #token: 496, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.35, #queue-req: 0, 
[2025-09-30 14:19:04] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.46, #queue-req: 0, 
[2025-09-30 14:19:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:04] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:04] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.81, #queue-req: 0, 
[2025-09-30 14:19:04] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:19:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:05] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:05] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.61, #queue-req: 0, 
[2025-09-30 14:19:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:05] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:05] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.99, #queue-req: 0, 
[2025-09-30 14:19:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:05] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:05] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:06] Decode batch. #running-req: 1, #token: 570, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.63, #queue-req: 0, 
[2025-09-30 14:19:06] Decode batch. #running-req: 1, #token: 610, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.95, #queue-req: 0, 
[2025-09-30 14:19:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:06] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:06] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:19:07] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:19:07] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:19:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:07] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:07] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:08] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.80, #queue-req: 0, 
[2025-09-30 14:19:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:08] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:08] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.62, #queue-req: 0, 
[2025-09-30 14:19:08] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:19:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:09] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:09] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:09] Decode batch. #running-req: 1, #token: 408, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.61, #queue-req: 0, 
[2025-09-30 14:19:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:09] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:09] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:09] Decode batch. #running-req: 1, #token: 209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 75.20, #queue-req: 0, 
[2025-09-30 14:19:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:09] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:10] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.16, #queue-req: 0, 
[2025-09-30 14:19:10] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:19:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:10] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:10] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:10] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:10] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:11] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.37, #queue-req: 0, 
[2025-09-30 14:19:11] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.82, #queue-req: 0, 
[2025-09-30 14:19:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:11] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:11] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:19:11] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:19:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:12] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:12] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:12] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:12] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:12] Decode batch. #running-req: 1, #token: 505, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.43, #queue-req: 0, 
[2025-09-30 14:19:13] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.39, #queue-req: 0, 
[2025-09-30 14:19:13] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0, 
[2025-09-30 14:19:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:13] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:13] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.88, #queue-req: 0, 
[2025-09-30 14:19:13] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:19:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:14] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:14] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:14] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.05, #queue-req: 0, 
[2025-09-30 14:19:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:14] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:14] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:14] Decode batch. #running-req: 1, #token: 203, token usage: 0.00, cuda graph: True, gen throughput (token/s): 61.09, #queue-req: 0, 
[2025-09-30 14:19:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:15] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:15] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.80, #queue-req: 0, 
[2025-09-30 14:19:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:15] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:15] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.23, #queue-req: 0, 
[2025-09-30 14:19:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:15] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:16] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:16] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:16] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 69.61, #queue-req: 0, 
[2025-09-30 14:19:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:16] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:16] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.53, #queue-req: 0, 
[2025-09-30 14:19:16] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:19:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:17] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:17] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:17] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.04, #queue-req: 0, 
[2025-09-30 14:19:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:17] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:17] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.19, #queue-req: 0, 
[2025-09-30 14:19:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:18] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:18] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 70.44, #queue-req: 0, 
[2025-09-30 14:19:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:18] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:18] Decode batch. #running-req: 1, #token: 564, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.95, #queue-req: 0, 
[2025-09-30 14:19:18] Decode batch. #running-req: 1, #token: 604, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:19:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:19] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:19] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:19:19] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:19:19] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.96, #queue-req: 0, 
[2025-09-30 14:19:20] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.86, #queue-req: 0, 
[2025-09-30 14:19:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:20] Prefill batch. #new-seq: 1, #new-token: 703, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:20] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:20] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.47, #queue-req: 0, 
[2025-09-30 14:19:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:20] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.20, #queue-req: 0, 
[2025-09-30 14:19:20] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:21] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.97, #queue-req: 0, 
[2025-09-30 14:19:21] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.00, #queue-req: 0, 
[2025-09-30 14:19:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:21] Decode batch. #running-req: 1, #token: 108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.78, #queue-req: 0, 
[2025-09-30 14:19:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:21] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:22] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:22] Decode batch. #running-req: 1, #token: 113, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.16, #queue-req: 0, 
[2025-09-30 14:19:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:22] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 414, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:22] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:22] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:22] Decode batch. #running-req: 1, #token: 405, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.64, #queue-req: 0, 
[2025-09-30 14:19:23] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.15, #queue-req: 0, 
[2025-09-30 14:19:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:23] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:23] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 14:19:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:23] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:23] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:23] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.70, #queue-req: 0, 
[2025-09-30 14:19:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:24] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:24] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:24] Decode batch. #running-req: 1, #token: 444, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.50, #queue-req: 0, 
[2025-09-30 14:19:24] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.01, #queue-req: 0, 
[2025-09-30 14:19:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:25] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:25] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.97, #queue-req: 0, 
[2025-09-30 14:19:25] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:19:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:25] Prefill batch. #new-seq: 1, #new-token: 540, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:25] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:25] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.82, #queue-req: 0, 
[2025-09-30 14:19:26] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.83, #queue-req: 0, 
[2025-09-30 14:19:26] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:19:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:26] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:26] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:19:27] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:19:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:27] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:27] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:27] Decode batch. #running-req: 1, #token: 379, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.02, #queue-req: 0, 
[2025-09-30 14:19:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:28] Prefill batch. #new-seq: 1, #new-token: 532, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:28] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:28] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.31, #queue-req: 0, 
[2025-09-30 14:19:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:28] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:28] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.43, #queue-req: 0, 
[2025-09-30 14:19:28] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:19:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:29] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:29] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.06, #queue-req: 0, 
[2025-09-30 14:19:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:29] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:29] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:29] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:30] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.76, #queue-req: 0, 
[2025-09-30 14:19:30] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.33, #queue-req: 0, 
[2025-09-30 14:19:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:30] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:30] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.72, #queue-req: 0, 
[2025-09-30 14:19:30] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 14:19:31] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:19:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:31] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:31] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:31] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.72, #queue-req: 0, 
[2025-09-30 14:19:32] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.19, #queue-req: 0, 
[2025-09-30 14:19:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:32] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:32] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.83, #queue-req: 0, 
[2025-09-30 14:19:32] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:19:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:33] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:33] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:33] Decode batch. #running-req: 1, #token: 176, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.91, #queue-req: 0, 
[2025-09-30 14:19:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:33] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:33] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:33] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.39, #queue-req: 0, 
[2025-09-30 14:19:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:33] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:34] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:34] Decode batch. #running-req: 1, #token: 488, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.73, #queue-req: 0, 
[2025-09-30 14:19:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:34] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:34] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.83, #queue-req: 0, 
[2025-09-30 14:19:34] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:19:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:35] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:35] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 83.05, #queue-req: 0, 
[2025-09-30 14:19:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:35] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:35] Prefill batch. #new-seq: 1, #new-token: 1145, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:36] Decode batch. #running-req: 1, #token: 1492, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.31, #queue-req: 0, 
[2025-09-30 14:19:36] Decode batch. #running-req: 1, #token: 1532, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:19:36] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.65, #queue-req: 0, 
[2025-09-30 14:19:36] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:19:37] Decode batch. #running-req: 1, #token: 1652, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:19:37] Decode batch. #running-req: 1, #token: 1692, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:19:37] Decode batch. #running-req: 1, #token: 1732, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:19:38] Decode batch. #running-req: 1, #token: 1772, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:19:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:38] Prefill batch. #new-seq: 1, #new-token: 1145, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:38] Decode batch. #running-req: 1, #token: 1479, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.17, #queue-req: 0, 
[2025-09-30 14:19:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:38] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 251, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:38] Decode batch. #running-req: 1, #token: 733, token usage: 0.01, cuda graph: True, gen throughput (token/s): 119.05, #queue-req: 0, 
[2025-09-30 14:19:39] Decode batch. #running-req: 1, #token: 773, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.15, #queue-req: 0, 
[2025-09-30 14:19:39] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.75, #queue-req: 0, 
[2025-09-30 14:19:39] Decode batch. #running-req: 1, #token: 853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.66, #queue-req: 0, 
[2025-09-30 14:19:40] Decode batch. #running-req: 1, #token: 893, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.61, #queue-req: 0, 
[2025-09-30 14:19:40] Decode batch. #running-req: 1, #token: 933, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.54, #queue-req: 0, 
[2025-09-30 14:19:40] Decode batch. #running-req: 1, #token: 973, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.47, #queue-req: 0, 
[2025-09-30 14:19:41] Decode batch. #running-req: 1, #token: 1013, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.41, #queue-req: 0, 
[2025-09-30 14:19:41] Decode batch. #running-req: 1, #token: 1053, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 14:19:41] Decode batch. #running-req: 1, #token: 1093, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:19:42] Decode batch. #running-req: 1, #token: 1133, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:19:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:42] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:42] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:42] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.86, #queue-req: 0, 
[2025-09-30 14:19:42] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:42] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:19:43] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:19:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:43] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:43] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:43] Decode batch. #running-req: 1, #token: 210, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.31, #queue-req: 0, 
[2025-09-30 14:19:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:44] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:44] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:44] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.52, #queue-req: 0, 
[2025-09-30 14:19:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:44] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:44] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.45, #queue-req: 0, 
[2025-09-30 14:19:44] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:19:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:45] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:45] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:45] Decode batch. #running-req: 1, #token: 191, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.52, #queue-req: 0, 
[2025-09-30 14:19:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:45] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:45] Prefill batch. #new-seq: 1, #new-token: 535, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:46] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.38, #queue-req: 0, 
[2025-09-30 14:19:46] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:46] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:19:46] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:19:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:46] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:46] Prefill batch. #new-seq: 1, #new-token: 531, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:47] Decode batch. #running-req: 1, #token: 621, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.59, #queue-req: 0, 
[2025-09-30 14:19:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:47] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:47] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:47] Decode batch. #running-req: 1, #token: 762, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.73, #queue-req: 0, 
[2025-09-30 14:19:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:47] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:48] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 14:19:48] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:19:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:48] Prefill batch. #new-seq: 1, #new-token: 1086, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:48] Prefill batch. #new-seq: 1, #new-token: 523, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:48] Decode batch. #running-req: 1, #token: 700, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.97, #queue-req: 0, 
[2025-09-30 14:19:49] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:19:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:49] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:49] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.03, #queue-req: 0, 
[2025-09-30 14:19:49] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:19:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:49] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:49] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:50] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:50] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 60.85, #queue-req: 0, 
[2025-09-30 14:19:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:50] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 590, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:50] Prefill batch. #new-seq: 1, #new-token: 965, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:51] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:51] Decode batch. #running-req: 1, #token: 625, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.27, #queue-req: 0, 
[2025-09-30 14:19:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:51] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:51] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:19:51] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:19:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:51] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:51] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:52] Decode batch. #running-req: 1, #token: 542, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.00, #queue-req: 0, 
[2025-09-30 14:19:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:52] Prefill batch. #new-seq: 1, #new-token: 872, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:52] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:52] Decode batch. #running-req: 1, #token: 632, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.43, #queue-req: 0, 
[2025-09-30 14:19:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:52] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:53] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.22, #queue-req: 0, 
[2025-09-30 14:19:53] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:19:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:53] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:53] Prefill batch. #new-seq: 1, #new-token: 429, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:53] Decode batch. #running-req: 1, #token: 518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.16, #queue-req: 0, 
[2025-09-30 14:19:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:54] Prefill batch. #new-seq: 1, #new-token: 927, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:54] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:54] Decode batch. #running-req: 1, #token: 695, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.67, #queue-req: 0, 
[2025-09-30 14:19:54] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:19:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:55] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:55] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.66, #queue-req: 0, 
[2025-09-30 14:19:55] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:19:55] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:19:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:55] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:56] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:56] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.06, #queue-req: 0, 
[2025-09-30 14:19:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:56] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 568, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:56] Decode batch. #running-req: 1, #token: 586, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.87, #queue-req: 0, 
[2025-09-30 14:19:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:57] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:57] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:57] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.11, #queue-req: 0, 
[2025-09-30 14:19:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:57] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:57] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:19:58] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:19:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:58] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:58] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:58] Decode batch. #running-req: 1, #token: 364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.20, #queue-req: 0, 
[2025-09-30 14:19:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:59] Prefill batch. #new-seq: 1, #new-token: 521, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:59] Prefill batch. #new-seq: 1, #new-token: 299, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:59] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.81, #queue-req: 0, 
[2025-09-30 14:19:59] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.84, #queue-req: 0, 
[2025-09-30 14:19:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:19:59] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:19:59] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.83, #queue-req: 0, 
[2025-09-30 14:20:00] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:20:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:00] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:00] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.84, #queue-req: 0, 
[2025-09-30 14:20:00] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:01] Decode batch. #running-req: 1, #token: 441, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.76, #queue-req: 0, 
[2025-09-30 14:20:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:01] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:20:01] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.60, #queue-req: 0, 
[2025-09-30 14:20:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:02] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:02] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:02] Decode batch. #running-req: 1, #token: 501, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.30, #queue-req: 0, 
[2025-09-30 14:20:02] Decode batch. #running-req: 1, #token: 541, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.46, #queue-req: 0, 
[2025-09-30 14:20:03] Decode batch. #running-req: 1, #token: 581, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.21, #queue-req: 0, 
[2025-09-30 14:20:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:03] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:03] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.90, #queue-req: 0, 
[2025-09-30 14:20:03] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:20:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:04] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:04] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.56, #queue-req: 0, 
[2025-09-30 14:20:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:04] Prefill batch. #new-seq: 1, #new-token: 1874, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:04] Decode batch. #running-req: 1, #token: 2231, token usage: 0.03, cuda graph: True, gen throughput (token/s): 50.44, #queue-req: 0, 
[2025-09-30 14:20:05] Decode batch. #running-req: 1, #token: 2271, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:20:05] Decode batch. #running-req: 1, #token: 2311, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.09, #queue-req: 0, 
[2025-09-30 14:20:05] Decode batch. #running-req: 1, #token: 2351, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:20:06] Decode batch. #running-req: 1, #token: 2391, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:20:06] Decode batch. #running-req: 1, #token: 2431, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.62, #queue-req: 0, 
[2025-09-30 14:20:06] Decode batch. #running-req: 1, #token: 2471, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:20:07] Decode batch. #running-req: 1, #token: 2511, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:20:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:07] Prefill batch. #new-seq: 1, #new-token: 1874, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:07] Decode batch. #running-req: 1, #token: 2195, token usage: 0.03, cuda graph: True, gen throughput (token/s): 96.12, #queue-req: 0, 
[2025-09-30 14:20:07] Decode batch. #running-req: 1, #token: 2235, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:20:08] Decode batch. #running-req: 1, #token: 2275, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:20:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:08] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 157, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:08] Decode batch. #running-req: 1, #token: 880, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.54, #queue-req: 0, 
[2025-09-30 14:20:08] Decode batch. #running-req: 1, #token: 920, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:20:09] Decode batch. #running-req: 1, #token: 960, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:20:09] Decode batch. #running-req: 1, #token: 1000, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.35, #queue-req: 0, 
[2025-09-30 14:20:09] Decode batch. #running-req: 1, #token: 1040, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 14:20:10] Decode batch. #running-req: 1, #token: 1080, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:20:10] Decode batch. #running-req: 1, #token: 1120, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:20:10] Decode batch. #running-req: 1, #token: 1160, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:20:10] Decode batch. #running-req: 1, #token: 1200, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:20:11] Decode batch. #running-req: 1, #token: 1240, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:20:11] Decode batch. #running-req: 1, #token: 1280, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:20:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:12] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:12] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:12] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.84, #queue-req: 0, 
[2025-09-30 14:20:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:12] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:12] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.62, #queue-req: 0, 
[2025-09-30 14:20:12] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:20:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:20:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:13] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:13] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.36, #queue-req: 0, 
[2025-09-30 14:20:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:13] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:14] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:14] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.33, #queue-req: 0, 
[2025-09-30 14:20:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:14] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:14] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:20:14] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:20:15] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:20:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:15] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:15] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:15] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.22, #queue-req: 0, 
[2025-09-30 14:20:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:16] Prefill batch. #new-seq: 1, #new-token: 561, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:16] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:16] Decode batch. #running-req: 1, #token: 415, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.49, #queue-req: 0, 
[2025-09-30 14:20:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:16] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:16] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.13, #queue-req: 0, 
[2025-09-30 14:20:17] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:20:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:17] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:17] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:17] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.53, #queue-req: 0, 
[2025-09-30 14:20:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:17] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:17] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:18] Decode batch. #running-req: 1, #token: 412, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.71, #queue-req: 0, 
[2025-09-30 14:20:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:18] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:18] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:20:18] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:20:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:18] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:18] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:19] Prefill batch. #new-seq: 1, #new-token: 395, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:19] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:19] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.40, #queue-req: 0, 
[2025-09-30 14:20:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:19] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:20] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 14:20:20] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:20:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:20] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:20] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.14, #queue-req: 0, 
[2025-09-30 14:20:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:20] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:21] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:21] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:21] Decode batch. #running-req: 1, #token: 409, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.87, #queue-req: 0, 
[2025-09-30 14:20:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:21] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:21] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.16, #queue-req: 0, 
[2025-09-30 14:20:22] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:20:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:22] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:22] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:22] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.99, #queue-req: 0, 
[2025-09-30 14:20:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:23] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:23] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:23] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.81, #queue-req: 0, 
[2025-09-30 14:20:23] Decode batch. #running-req: 1, #token: 446, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.14, #queue-req: 0, 
[2025-09-30 14:20:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:23] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:23] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.29, #queue-req: 0, 
[2025-09-30 14:20:24] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:20:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:24] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:24] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.61, #queue-req: 0, 
[2025-09-30 14:20:24] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:25] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:25] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 289, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:25] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.31, #queue-req: 0, 
[2025-09-30 14:20:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:25] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:25] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:25] Decode batch. #running-req: 1, #token: 544, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.45, #queue-req: 0, 
[2025-09-30 14:20:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:26] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:26] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 14:20:26] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:20:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:27] Prefill batch. #new-seq: 1, #new-token: 1382, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:27] Decode batch. #running-req: 1, #token: 1734, token usage: 0.03, cuda graph: True, gen throughput (token/s): 56.82, #queue-req: 0, 
[2025-09-30 14:20:27] Decode batch. #running-req: 1, #token: 1774, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.37, #queue-req: 0, 
[2025-09-30 14:20:27] Decode batch. #running-req: 1, #token: 1814, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.14, #queue-req: 0, 
[2025-09-30 14:20:28] Decode batch. #running-req: 1, #token: 1854, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:20:28] Decode batch. #running-req: 1, #token: 1894, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:20:28] Decode batch. #running-req: 1, #token: 1934, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.99, #queue-req: 0, 
[2025-09-30 14:20:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:28] Prefill batch. #new-seq: 1, #new-token: 1382, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:29] Decode batch. #running-req: 1, #token: 1727, token usage: 0.03, cuda graph: True, gen throughput (token/s): 103.61, #queue-req: 0, 
[2025-09-30 14:20:29] Decode batch. #running-req: 1, #token: 1767, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:20:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:29] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 229, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:29] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.60, #queue-req: 0, 
[2025-09-30 14:20:30] Decode batch. #running-req: 1, #token: 846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.70, #queue-req: 0, 
[2025-09-30 14:20:30] Decode batch. #running-req: 1, #token: 886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:20:30] Decode batch. #running-req: 1, #token: 926, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.48, #queue-req: 0, 
[2025-09-30 14:20:31] Decode batch. #running-req: 1, #token: 966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.43, #queue-req: 0, 
[2025-09-30 14:20:31] Decode batch. #running-req: 1, #token: 1006, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.40, #queue-req: 0, 
[2025-09-30 14:20:31] Decode batch. #running-req: 1, #token: 1046, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.14, #queue-req: 0, 
[2025-09-30 14:20:31] Decode batch. #running-req: 1, #token: 1086, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:20:32] Decode batch. #running-req: 1, #token: 1126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:20:32] Decode batch. #running-req: 1, #token: 1166, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:20:32] Decode batch. #running-req: 1, #token: 1206, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:20:33] Decode batch. #running-req: 1, #token: 1246, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:20:33] Decode batch. #running-req: 1, #token: 1286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.62, #queue-req: 0, 
[2025-09-30 14:20:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:34] Prefill batch. #new-seq: 1, #new-token: 684, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:34] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:34] Decode batch. #running-req: 1, #token: 512, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.51, #queue-req: 0, 
[2025-09-30 14:20:34] Decode batch. #running-req: 1, #token: 552, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:20:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:34] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:34] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:20:35] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:20:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:35] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:35] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:35] Decode batch. #running-req: 1, #token: 854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.77, #queue-req: 0, 
[2025-09-30 14:20:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:35] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:36] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.22, #queue-req: 0, 
[2025-09-30 14:20:36] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:20:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:36] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:36] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:36] Decode batch. #running-req: 1, #token: 742, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.41, #queue-req: 0, 
[2025-09-30 14:20:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:37] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.44, #queue-req: 0, 
[2025-09-30 14:20:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:37] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 730, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:37] Prefill batch. #new-seq: 1, #new-token: 1232, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:38] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:38] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.31, #queue-req: 0, 
[2025-09-30 14:20:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:38] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:38] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.02, #queue-req: 0, 
[2025-09-30 14:20:38] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:20:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:38] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:39] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:39] Decode batch. #running-req: 1, #token: 658, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.58, #queue-req: 0, 
[2025-09-30 14:20:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:39] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:39] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:40] Decode batch. #running-req: 1, #token: 613, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.09, #queue-req: 0, 
[2025-09-30 14:20:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:40] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:40] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.62, #queue-req: 0, 
[2025-09-30 14:20:40] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:20:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:41] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:41] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.30, #queue-req: 0, 
[2025-09-30 14:20:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:41] Prefill batch. #new-seq: 1, #new-token: 416, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:41] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:41] Decode batch. #running-req: 1, #token: 108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.48, #queue-req: 0, 
[2025-09-30 14:20:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 490, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:42] Prefill batch. #new-seq: 1, #new-token: 712, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:42] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.29, #queue-req: 0, 
[2025-09-30 14:20:42] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:42] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.51, #queue-req: 0, 
[2025-09-30 14:20:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:42] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 205, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:43] Decode batch. #running-req: 1, #token: 346, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.61, #queue-req: 0, 
[2025-09-30 14:20:43] Decode batch. #running-req: 1, #token: 386, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 14:20:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:43] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:43] Decode batch. #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.08, #queue-req: 0, 
[2025-09-30 14:20:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:44] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:44] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:44] Prefill batch. #new-seq: 1, #new-token: 465, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:44] Decode batch. #running-req: 1, #token: 632, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.83, #queue-req: 0, 
[2025-09-30 14:20:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:44] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:44] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:20:45] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:20:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:45] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:45] Prefill batch. #new-seq: 1, #new-token: 461, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:45] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.70, #queue-req: 0, 
[2025-09-30 14:20:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:46] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:46] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 532, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:46] Decode batch. #running-req: 1, #token: 545, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.65, #queue-req: 0, 
[2025-09-30 14:20:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:46] Prefill batch. #new-seq: 1, #new-token: 949, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:46] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:47] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.59, #queue-req: 0, 
[2025-09-30 14:20:47] Decode batch. #running-req: 1, #token: 720, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:20:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:47] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:47] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.87, #queue-req: 0, 
[2025-09-30 14:20:47] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:20:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:48] Prefill batch. #new-seq: 1, #new-token: 742, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:48] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:48] Decode batch. #running-req: 1, #token: 421, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.07, #queue-req: 0, 
[2025-09-30 14:20:48] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 14:20:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:49] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:49] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:20:49] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:20:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:49] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:49] Prefill batch. #new-seq: 1, #new-token: 253, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:49] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.79, #queue-req: 0, 
[2025-09-30 14:20:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:50] Prefill batch. #new-seq: 1, #new-token: 532, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:50] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:50] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.97, #queue-req: 0, 
[2025-09-30 14:20:51] Decode batch. #running-req: 1, #token: 564, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:20:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:51] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:51] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 14:20:51] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:20:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:52] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:52] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:52] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.65, #queue-req: 0, 
[2025-09-30 14:20:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:52] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:52] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 349, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:52] Decode batch. #running-req: 1, #token: 353, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.84, #queue-req: 0, 
[2025-09-30 14:20:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:53] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:53] Prefill batch. #new-seq: 1, #new-token: 352, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:53] Decode batch. #running-req: 1, #token: 532, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.97, #queue-req: 0, 
[2025-09-30 14:20:53] Decode batch. #running-req: 1, #token: 572, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.14, #queue-req: 0, 
[2025-09-30 14:20:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:53] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:54] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.53, #queue-req: 0, 
[2025-09-30 14:20:54] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:20:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:54] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:54] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:55] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.72, #queue-req: 0, 
[2025-09-30 14:20:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:55] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:55] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:55] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.78, #queue-req: 0, 
[2025-09-30 14:20:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:55] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:56] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 14:20:56] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:20:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:56] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:56] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:57] Decode batch. #running-req: 1, #token: 554, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.18, #queue-req: 0, 
[2025-09-30 14:20:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:57] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:57] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.76, #queue-req: 0, 
[2025-09-30 14:20:57] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:20:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:57] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:58] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:58] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.16, #queue-req: 0, 
[2025-09-30 14:20:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:58] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:58] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 430, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:58] Decode batch. #running-req: 1, #token: 443, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.19, #queue-req: 0, 
[2025-09-30 14:20:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:59] Prefill batch. #new-seq: 1, #new-token: 677, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:59] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:59] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.49, #queue-req: 0, 
[2025-09-30 14:20:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:20:59] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:20:59] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 14:21:00] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:21:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:00] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:00] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.07, #queue-req: 0, 
[2025-09-30 14:21:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:00] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:01] Prefill batch. #new-seq: 1, #new-token: 697, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:01] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:01] Decode batch. #running-req: 1, #token: 552, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.05, #queue-req: 0, 
[2025-09-30 14:21:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:01] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:01] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.30, #queue-req: 0, 
[2025-09-30 14:21:02] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:21:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:02] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:02] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.49, #queue-req: 0, 
[2025-09-30 14:21:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:02] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:03] Prefill batch. #new-seq: 1, #new-token: 979, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:03] Prefill batch. #new-seq: 1, #new-token: 603, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:03] Decode batch. #running-req: 1, #token: 777, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.65, #queue-req: 0, 
[2025-09-30 14:21:03] Decode batch. #running-req: 1, #token: 817, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.01, #queue-req: 0, 
[2025-09-30 14:21:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:03] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:03] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.57, #queue-req: 0, 
[2025-09-30 14:21:04] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 14:21:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:04] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:04] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.54, #queue-req: 0, 
[2025-09-30 14:21:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:04] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:05] Prefill batch. #new-seq: 1, #new-token: 979, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:05] Prefill batch. #new-seq: 1, #new-token: 382, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:05] Decode batch. #running-req: 1, #token: 556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.56, #queue-req: 0, 
[2025-09-30 14:21:05] Decode batch. #running-req: 1, #token: 596, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.01, #queue-req: 0, 
[2025-09-30 14:21:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:05] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:06] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.65, #queue-req: 0, 
[2025-09-30 14:21:06] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:21:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:06] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:06] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:06] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.31, #queue-req: 0, 
[2025-09-30 14:21:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:07] Prefill batch. #new-seq: 1, #new-token: 1016, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:07] Prefill batch. #new-seq: 1, #new-token: 642, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:07] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.14, #queue-req: 0, 
[2025-09-30 14:21:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:08] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:08] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.94, #queue-req: 0, 
[2025-09-30 14:21:08] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:21:08] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:21:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:08] Prefill batch. #new-seq: 1, #new-token: 1149, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:08] Prefill batch. #new-seq: 1, #new-token: 508, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:09] Decode batch. #running-req: 1, #token: 714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.44, #queue-req: 0, 
[2025-09-30 14:21:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:09] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:09] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.71, #queue-req: 0, 
[2025-09-30 14:21:09] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:21:10] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:21:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:10] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:10] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:10] Decode batch. #running-req: 1, #token: 605, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.93, #queue-req: 0, 
[2025-09-30 14:21:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:10] Prefill batch. #new-seq: 1, #new-token: 1061, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:11] Prefill batch. #new-seq: 1, #new-token: 559, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:11] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:11] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.14, #queue-req: 0, 
[2025-09-30 14:21:11] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:21:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:11] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:12] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.71, #queue-req: 0, 
[2025-09-30 14:21:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:12] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:12] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:12] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.18, #queue-req: 0, 
[2025-09-30 14:21:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 627, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:13] Prefill batch. #new-seq: 1, #new-token: 1142, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:13] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:13] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.88, #queue-req: 0, 
[2025-09-30 14:21:13] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.11, #queue-req: 0, 
[2025-09-30 14:21:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:14] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:14] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.92, #queue-req: 0, 
[2025-09-30 14:21:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:14] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:14] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:14] Decode batch. #running-req: 1, #token: 664, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.50, #queue-req: 0, 
[2025-09-30 14:21:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:15] Prefill batch. #new-seq: 1, #new-token: 1231, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:15] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:15] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.42, #queue-req: 0, 
[2025-09-30 14:21:15] Decode batch. #running-req: 1, #token: 864, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:21:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:15] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:16] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 14:21:16] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:21:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:16] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:16] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.24, #queue-req: 0, 
[2025-09-30 14:21:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:16] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:17] Prefill batch. #new-seq: 1, #new-token: 1093, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:17] Prefill batch. #new-seq: 1, #new-token: 450, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:17] Decode batch. #running-req: 1, #token: 618, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.12, #queue-req: 0, 
[2025-09-30 14:21:17] Decode batch. #running-req: 1, #token: 658, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.78, #queue-req: 0, 
[2025-09-30 14:21:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:18] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:18] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.56, #queue-req: 0, 
[2025-09-30 14:21:18] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:21:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:18] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:18] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:18] Decode batch. #running-req: 1, #token: 523, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.11, #queue-req: 0, 
[2025-09-30 14:21:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:19] Prefill batch. #new-seq: 1, #new-token: 860, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:19] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:19] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.16, #queue-req: 0, 
[2025-09-30 14:21:20] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.89, #queue-req: 0, 
[2025-09-30 14:21:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:20] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:20] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.10, #queue-req: 0, 
[2025-09-30 14:21:20] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:21:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:21] Prefill batch. #new-seq: 1, #new-token: 952, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:21] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:21] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.09, #queue-req: 0, 
[2025-09-30 14:21:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:21] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:21] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.49, #queue-req: 0, 
[2025-09-30 14:21:21] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:21:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:22] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:22] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.65, #queue-req: 0, 
[2025-09-30 14:21:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:22] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:22] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.38, #queue-req: 0, 
[2025-09-30 14:21:23] Prefill batch. #new-seq: 1, #new-token: 851, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:23] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:23] Decode batch. #running-req: 1, #token: 518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.43, #queue-req: 0, 
[2025-09-30 14:21:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:23] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:23] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.48, #queue-req: 0, 
[2025-09-30 14:21:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:23] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:24] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.59, #queue-req: 0, 
[2025-09-30 14:21:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:24] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:24] Prefill batch. #new-seq: 1, #new-token: 655, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:24] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:24] Decode batch. #running-req: 1, #token: 517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.71, #queue-req: 0, 
[2025-09-30 14:21:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:25] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:25] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:21:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:25] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:25] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.86, #queue-req: 0, 
[2025-09-30 14:21:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:25] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:26] Prefill batch. #new-seq: 1, #new-token: 663, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:26] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:26] Decode batch. #running-req: 1, #token: 536, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.82, #queue-req: 0, 
[2025-09-30 14:21:26] Decode batch. #running-req: 1, #token: 576, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 14:21:26] Decode batch. #running-req: 1, #token: 616, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.96, #queue-req: 0, 
[2025-09-30 14:21:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:26] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:27] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:21:27] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:21:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:27] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:27] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:28] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 395, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:28] Decode batch. #running-req: 1, #token: 398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.72, #queue-req: 0, 
[2025-09-30 14:21:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:28] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:28] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.34, #queue-req: 0, 
[2025-09-30 14:21:29] Decode batch. #running-req: 1, #token: 548, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.93, #queue-req: 0, 
[2025-09-30 14:21:29] Decode batch. #running-req: 1, #token: 588, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.79, #queue-req: 0, 
[2025-09-30 14:21:29] Decode batch. #running-req: 1, #token: 628, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.62, #queue-req: 0, 
[2025-09-30 14:21:29] Decode batch. #running-req: 1, #token: 668, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.54, #queue-req: 0, 
[2025-09-30 14:21:30] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0, 
[2025-09-30 14:21:30] Decode batch. #running-req: 1, #token: 748, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:21:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:30] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:30] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.97, #queue-req: 0, 
[2025-09-30 14:21:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:30] Prefill batch. #new-seq: 1, #new-token: 846, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:31] Decode batch. #running-req: 1, #token: 1003, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.05, #queue-req: 0, 
[2025-09-30 14:21:31] Decode batch. #running-req: 1, #token: 1043, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.25, #queue-req: 0, 
[2025-09-30 14:21:31] Decode batch. #running-req: 1, #token: 1083, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:21:32] Decode batch. #running-req: 1, #token: 1123, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:21:32] Decode batch. #running-req: 1, #token: 1163, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:21:32] Decode batch. #running-req: 1, #token: 1203, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:21:33] Decode batch. #running-req: 1, #token: 1243, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:21:33] Decode batch. #running-req: 1, #token: 1283, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:21:33] Decode batch. #running-req: 1, #token: 1323, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:21:34] Decode batch. #running-req: 1, #token: 1363, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.22, #queue-req: 0, 
[2025-09-30 14:21:34] Decode batch. #running-req: 1, #token: 1403, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:21:34] Decode batch. #running-req: 1, #token: 1443, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:21:34] Decode batch. #running-req: 1, #token: 1483, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:21:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:35] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:35] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:35] Decode batch. #running-req: 1, #token: 512, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.22, #queue-req: 0, 
[2025-09-30 14:21:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:35] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:35] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.09, #queue-req: 0, 
[2025-09-30 14:21:36] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:21:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:36] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:36] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.06, #queue-req: 0, 
[2025-09-30 14:21:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:36] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:37] Prefill batch. #new-seq: 1, #new-token: 934, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:37] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:37] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.08, #queue-req: 0, 
[2025-09-30 14:21:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:37] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:37] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.65, #queue-req: 0, 
[2025-09-30 14:21:37] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:21:38] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:21:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:38] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:38] Decode batch. #running-req: 1, #token: 694, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.01, #queue-req: 0, 
[2025-09-30 14:21:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:38] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:39] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 675, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:39] Decode batch. #running-req: 1, #token: 692, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.22, #queue-req: 0, 
[2025-09-30 14:21:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:39] Prefill batch. #new-seq: 1, #new-token: 1149, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:39] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:39] Decode batch. #running-req: 1, #token: 742, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.05, #queue-req: 0, 
[2025-09-30 14:21:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:40] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:40] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:21:40] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:21:40] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:21:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:41] Prefill batch. #new-seq: 1, #new-token: 1074, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:41] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:41] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:41] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.00, #queue-req: 0, 
[2025-09-30 14:21:41] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:21:42] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:21:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:42] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:42] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.48, #queue-req: 0, 
[2025-09-30 14:21:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:42] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:43] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:43] Decode batch. #running-req: 1, #token: 114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 52.08, #queue-req: 0, 
[2025-09-30 14:21:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 598, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:43] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 118.47, #queue-req: 0, 
[2025-09-30 14:21:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:44] Prefill batch. #new-seq: 1, #new-token: 933, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:44] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:44] Decode batch. #running-req: 1, #token: 610, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.80, #queue-req: 0, 
[2025-09-30 14:21:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:44] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:44] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:21:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:45] Prefill batch. #new-seq: 1, #new-token: 842, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:45] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:45] Decode batch. #running-req: 1, #token: 667, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.69, #queue-req: 0, 
[2025-09-30 14:21:45] Decode batch. #running-req: 1, #token: 707, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:21:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:45] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:46] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:21:46] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:21:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:46] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:47] Decode batch. #running-req: 1, #token: 109, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.44, #queue-req: 0, 
[2025-09-30 14:21:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:47] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:47] Prefill batch. #new-seq: 1, #new-token: 966, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:47] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 192, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:47] Decode batch. #running-req: 1, #token: 775, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.36, #queue-req: 0, 
[2025-09-30 14:21:48] Decode batch. #running-req: 1, #token: 815, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:21:48] Decode batch. #running-req: 1, #token: 855, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:21:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:48] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:48] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.15, #queue-req: 0, 
[2025-09-30 14:21:49] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:21:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:49] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:49] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.93, #queue-req: 0, 
[2025-09-30 14:21:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:49] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:49] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.23, #queue-req: 0, 
[2025-09-30 14:21:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:50] Prefill batch. #new-seq: 1, #new-token: 843, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:50] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:50] Decode batch. #running-req: 1, #token: 520, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.73, #queue-req: 0, 
[2025-09-30 14:21:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:50] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:51] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:21:51] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:21:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:51] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:51] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:51] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.45, #queue-req: 0, 
[2025-09-30 14:21:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:52] Prefill batch. #new-seq: 1, #new-token: 803, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:52] Decode batch. #running-req: 1, #token: 1172, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.89, #queue-req: 0, 
[2025-09-30 14:21:53] Decode batch. #running-req: 1, #token: 1212, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:21:53] Decode batch. #running-req: 1, #token: 1252, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:21:53] Decode batch. #running-req: 1, #token: 1292, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.55, #queue-req: 0, 
[2025-09-30 14:21:53] Decode batch. #running-req: 1, #token: 1332, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 14:21:54] Decode batch. #running-req: 1, #token: 1372, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.20, #queue-req: 0, 
[2025-09-30 14:21:54] Decode batch. #running-req: 1, #token: 1412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 14:21:54] Decode batch. #running-req: 1, #token: 1452, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:21:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:55] Prefill batch. #new-seq: 1, #new-token: 803, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:55] Decode batch. #running-req: 1, #token: 1137, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.91, #queue-req: 0, 
[2025-09-30 14:21:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:21:55] Prefill batch. #new-seq: 1, #new-token: 854, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:21:55] Decode batch. #running-req: 1, #token: 980, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.49, #queue-req: 0, 
[2025-09-30 14:21:55] Decode batch. #running-req: 1, #token: 1020, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 14:21:56] Decode batch. #running-req: 1, #token: 1060, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:21:56] Decode batch. #running-req: 1, #token: 1100, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:21:56] Decode batch. #running-req: 1, #token: 1140, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:21:57] Decode batch. #running-req: 1, #token: 1180, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:21:57] Decode batch. #running-req: 1, #token: 1220, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.69, #queue-req: 0, 
[2025-09-30 14:21:57] Decode batch. #running-req: 1, #token: 1260, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:21:58] Decode batch. #running-req: 1, #token: 1300, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.45, #queue-req: 0, 
[2025-09-30 14:21:58] Decode batch. #running-req: 1, #token: 1340, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 14:21:58] Decode batch. #running-req: 1, #token: 1380, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 14:21:58] Decode batch. #running-req: 1, #token: 1420, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:21:59] Decode batch. #running-req: 1, #token: 1460, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:21:59] Decode batch. #running-req: 1, #token: 1500, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.10, #queue-req: 0, 
[2025-09-30 14:21:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:00] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:00] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:00] Decode batch. #running-req: 1, #token: 542, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.73, #queue-req: 0, 
[2025-09-30 14:22:00] Decode batch. #running-req: 1, #token: 582, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.11, #queue-req: 0, 
[2025-09-30 14:22:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:00] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:00] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.48, #queue-req: 0, 
[2025-09-30 14:22:01] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:22:01] Decode batch. #running-req: 1, #token: 360, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:22:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:01] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:01] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:02] Prefill batch. #new-seq: 1, #new-token: 790, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:02] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:02] Decode batch. #running-req: 1, #token: 602, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.21, #queue-req: 0, 
[2025-09-30 14:22:02] Decode batch. #running-req: 1, #token: 642, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.86, #queue-req: 0, 
[2025-09-30 14:22:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:02] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:03] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.25, #queue-req: 0, 
[2025-09-30 14:22:03] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:22:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:03] Decode batch. #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.75, #queue-req: 0, 
[2025-09-30 14:22:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:03] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:04] Prefill batch. #new-seq: 1, #new-token: 848, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:04] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:04] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.61, #queue-req: 0, 
[2025-09-30 14:22:04] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.85, #queue-req: 0, 
[2025-09-30 14:22:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:04] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:05] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:22:05] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:22:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:05] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:05] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:05] Decode batch. #running-req: 1, #token: 503, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.84, #queue-req: 0, 
[2025-09-30 14:22:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:06] Prefill batch. #new-seq: 1, #new-token: 829, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:06] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:06] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.64, #queue-req: 0, 
[2025-09-30 14:22:07] Decode batch. #running-req: 1, #token: 624, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.93, #queue-req: 0, 
[2025-09-30 14:22:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:07] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:07] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.27, #queue-req: 0, 
[2025-09-30 14:22:07] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:22:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:07] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:08] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:08] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.29, #queue-req: 0, 
[2025-09-30 14:22:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:08] Prefill batch. #new-seq: 1, #new-token: 857, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:08] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:08] Decode batch. #running-req: 1, #token: 655, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.87, #queue-req: 0, 
[2025-09-30 14:22:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:09] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:09] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:22:09] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:22:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:09] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:09] Prefill batch. #new-seq: 1, #new-token: 456, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:09] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.74, #queue-req: 0, 
[2025-09-30 14:22:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:10] Prefill batch. #new-seq: 1, #new-token: 817, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:10] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:10] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.56, #queue-req: 0, 
[2025-09-30 14:22:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:10] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:10] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.99, #queue-req: 0, 
[2025-09-30 14:22:11] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:22:11] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:22:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:11] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:11] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:12] Prefill batch. #new-seq: 1, #new-token: 459, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:12] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:12] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.74, #queue-req: 0, 
[2025-09-30 14:22:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:12] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:12] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.43, #queue-req: 0, 
[2025-09-30 14:22:12] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:22:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:13] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:13] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:13] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.12, #queue-req: 0, 
[2025-09-30 14:22:13] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.33, #queue-req: 0, 
[2025-09-30 14:22:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:14] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:14] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.86, #queue-req: 0, 
[2025-09-30 14:22:14] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:22:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:14] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:14] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 178, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:15] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.36, #queue-req: 0, 
[2025-09-30 14:22:15] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.36, #queue-req: 0, 
[2025-09-30 14:22:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:15] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:15] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:22:16] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:22:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:16] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:16] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:16] Decode batch. #running-req: 1, #token: 141, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.87, #queue-req: 0, 
[2025-09-30 14:22:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:16] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:17] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:17] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.66, #queue-req: 0, 
[2025-09-30 14:22:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:17] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:17] Decode batch. #running-req: 1, #token: 480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.99, #queue-req: 0, 
[2025-09-30 14:22:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:17] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:18] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 14:22:18] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:22:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:18] Prefill batch. #new-seq: 1, #new-token: 848, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:19] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:19] Decode batch. #running-req: 1, #token: 751, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.74, #queue-req: 0, 
[2025-09-30 14:22:19] Decode batch. #running-req: 1, #token: 791, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:22:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:19] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:19] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.74, #queue-req: 0, 
[2025-09-30 14:22:20] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.52, #queue-req: 0, 
[2025-09-30 14:22:20] Decode batch. #running-req: 1, #token: 719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.37, #queue-req: 0, 
[2025-09-30 14:22:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:20] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:20] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:20] Decode batch. #running-req: 1, #token: 660, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.77, #queue-req: 0, 
[2025-09-30 14:22:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:21] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:21] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 645, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:21] Decode batch. #running-req: 1, #token: 648, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.04, #queue-req: 0, 
[2025-09-30 14:22:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:21] Prefill batch. #new-seq: 1, #new-token: 724, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:21] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:22] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.20, #queue-req: 0, 
[2025-09-30 14:22:22] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.11, #queue-req: 0, 
[2025-09-30 14:22:22] Decode batch. #running-req: 1, #token: 491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.01, #queue-req: 0, 
[2025-09-30 14:22:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:22] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:23] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:22:23] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:22:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:23] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:23] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:23] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.50, #queue-req: 0, 
[2025-09-30 14:22:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:24] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 218, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:24] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.70, #queue-req: 0, 
[2025-09-30 14:22:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:24] Prefill batch. #new-seq: 1, #new-token: 798, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:24] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:25] Decode batch. #running-req: 1, #token: 839, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.37, #queue-req: 0, 
[2025-09-30 14:22:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:25] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:25] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.80, #queue-req: 0, 
[2025-09-30 14:22:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:25] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:25] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.83, #queue-req: 0, 
[2025-09-30 14:22:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:25] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:26] Prefill batch. #new-seq: 1, #new-token: 734, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:26] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:26] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.75, #queue-req: 0, 
[2025-09-30 14:22:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:26] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:26] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.70, #queue-req: 0, 
[2025-09-30 14:22:27] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:22:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:27] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:27] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 78.08, #queue-req: 0, 
[2025-09-30 14:22:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:27] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:28] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:28] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:28] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.86, #queue-req: 0, 
[2025-09-30 14:22:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:28] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:28] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.33, #queue-req: 0, 
[2025-09-30 14:22:29] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:22:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:29] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:29] Decode batch. #running-req: 1, #token: 120, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.38, #queue-req: 0, 
[2025-09-30 14:22:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:29] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:29] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:29] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 155, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:30] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.33, #queue-req: 0, 
[2025-09-30 14:22:30] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.18, #queue-req: 0, 
[2025-09-30 14:22:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:30] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:30] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:22:31] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:22:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:31] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:31] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.11, #queue-req: 0, 
[2025-09-30 14:22:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:31] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:32] Prefill batch. #new-seq: 1, #new-token: 624, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:32] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.19, #queue-req: 0, 
[2025-09-30 14:22:32] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 187, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:32] Decode batch. #running-req: 1, #token: 593, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.78, #queue-req: 0, 
[2025-09-30 14:22:32] Decode batch. #running-req: 1, #token: 633, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.79, #queue-req: 0, 
[2025-09-30 14:22:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:33] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:33] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:22:33] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:22:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:33] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:33] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:33] Decode batch. #running-req: 1, #token: 373, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.39, #queue-req: 0, 
[2025-09-30 14:22:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:34] Prefill batch. #new-seq: 1, #new-token: 815, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:34] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:34] Decode batch. #running-req: 1, #token: 713, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.18, #queue-req: 0, 
[2025-09-30 14:22:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:34] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:35] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:22:35] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:22:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:35] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:35] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.37, #queue-req: 0, 
[2025-09-30 14:22:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:35] Prefill batch. #new-seq: 1, #new-token: 518, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:36] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:36] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.48, #queue-req: 0, 
[2025-09-30 14:22:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:36] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 590, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:36] Prefill batch. #new-seq: 1, #new-token: 3028, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:37] Decode batch. #running-req: 1, #token: 3380, token usage: 0.05, cuda graph: True, gen throughput (token/s): 50.94, #queue-req: 0, 
[2025-09-30 14:22:37] Decode batch. #running-req: 1, #token: 3420, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.16, #queue-req: 0, 
[2025-09-30 14:22:37] Decode batch. #running-req: 1, #token: 3460, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:22:38] Decode batch. #running-req: 1, #token: 3500, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.08, #queue-req: 0, 
[2025-09-30 14:22:38] Decode batch. #running-req: 1, #token: 3540, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:22:38] Decode batch. #running-req: 1, #token: 3580, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:22:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:38] Prefill batch. #new-seq: 1, #new-token: 3028, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:39] Decode batch. #running-req: 1, #token: 3369, token usage: 0.05, cuda graph: True, gen throughput (token/s): 82.83, #queue-req: 0, 
[2025-09-30 14:22:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:39] Prefill batch. #new-seq: 1, #new-token: 623, #cached-token: 259, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:39] Decode batch. #running-req: 1, #token: 912, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.91, #queue-req: 0, 
[2025-09-30 14:22:39] Decode batch. #running-req: 1, #token: 952, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:22:40] Decode batch. #running-req: 1, #token: 992, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:22:40] Decode batch. #running-req: 1, #token: 1032, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.29, #queue-req: 0, 
[2025-09-30 14:22:40] Decode batch. #running-req: 1, #token: 1072, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.96, #queue-req: 0, 
[2025-09-30 14:22:41] Decode batch. #running-req: 1, #token: 1112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.95, #queue-req: 0, 
[2025-09-30 14:22:41] Decode batch. #running-req: 1, #token: 1152, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:22:41] Decode batch. #running-req: 1, #token: 1192, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:22:42] Decode batch. #running-req: 1, #token: 1232, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:22:42] Decode batch. #running-req: 1, #token: 1272, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:22:42] Decode batch. #running-req: 1, #token: 1312, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 14:22:43] Decode batch. #running-req: 1, #token: 1352, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.23, #queue-req: 0, 
[2025-09-30 14:22:43] Decode batch. #running-req: 1, #token: 1392, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:22:43] Decode batch. #running-req: 1, #token: 1432, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:22:43] Decode batch. #running-req: 1, #token: 1472, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:22:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:44] Prefill batch. #new-seq: 1, #new-token: 1152, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:44] Prefill batch. #new-seq: 1, #new-token: 637, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:44] Decode batch. #running-req: 1, #token: 827, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.04, #queue-req: 0, 
[2025-09-30 14:22:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:44] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:45] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 14:22:45] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:22:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:45] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:45] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:46] Prefill batch. #new-seq: 1, #new-token: 1227, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:46] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:46] Decode batch. #running-req: 1, #token: 767, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.59, #queue-req: 0, 
[2025-09-30 14:22:46] Decode batch. #running-req: 1, #token: 807, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 14:22:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:46] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:46] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:22:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:47] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:47] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.02, #queue-req: 0, 
[2025-09-30 14:22:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:47] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:47] Prefill batch. #new-seq: 1, #new-token: 941, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:47] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:48] Decode batch. #running-req: 1, #token: 519, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.15, #queue-req: 0, 
[2025-09-30 14:22:48] Decode batch. #running-req: 1, #token: 559, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.33, #queue-req: 0, 
[2025-09-30 14:22:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:48] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:48] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 126.36, #queue-req: 0, 
[2025-09-30 14:22:48] Decode batch. #running-req: 1, #token: 385, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.08, #queue-req: 0, 
[2025-09-30 14:22:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:49] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:49] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:49] Decode batch. #running-req: 1, #token: 435, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.50, #queue-req: 0, 
[2025-09-30 14:22:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:49] Prefill batch. #new-seq: 1, #new-token: 1061, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:50] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:50] Decode batch. #running-req: 1, #token: 911, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.90, #queue-req: 0, 
[2025-09-30 14:22:50] Decode batch. #running-req: 1, #token: 951, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:22:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:50] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:50] Decode batch. #running-req: 1, #token: 415, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.65, #queue-req: 0, 
[2025-09-30 14:22:51] Decode batch. #running-req: 1, #token: 455, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.86, #queue-req: 0, 
[2025-09-30 14:22:51] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.60, #queue-req: 0, 
[2025-09-30 14:22:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:51] Prefill batch. #new-seq: 1, #new-token: 1315, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:51] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:51] Decode batch. #running-req: 1, #token: 794, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.24, #queue-req: 0, 
[2025-09-30 14:22:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:52] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:52] Decode batch. #running-req: 1, #token: 399, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.54, #queue-req: 0, 
[2025-09-30 14:22:52] Decode batch. #running-req: 1, #token: 439, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.00, #queue-req: 0, 
[2025-09-30 14:22:52] Decode batch. #running-req: 1, #token: 479, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.71, #queue-req: 0, 
[2025-09-30 14:22:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:52] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:53] Decode batch. #running-req: 1, #token: 121, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.04, #queue-req: 0, 
[2025-09-30 14:22:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:53] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:53] Prefill batch. #new-seq: 1, #new-token: 1076, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:53] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:54] Decode batch. #running-req: 1, #token: 670, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.04, #queue-req: 0, 
[2025-09-30 14:22:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:54] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:54] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:22:54] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:22:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:54] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:55] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:55] Decode batch. #running-req: 1, #token: 557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.71, #queue-req: 0, 
[2025-09-30 14:22:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:55] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:55] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 548, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:55] Decode batch. #running-req: 1, #token: 566, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.05, #queue-req: 0, 
[2025-09-30 14:22:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:56] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:56] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:56] Decode batch. #running-req: 1, #token: 626, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.83, #queue-req: 0, 
[2025-09-30 14:22:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:56] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:56] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.87, #queue-req: 0, 
[2025-09-30 14:22:57] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:22:57] Decode batch. #running-req: 1, #token: 353, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:22:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:57] Prefill batch. #new-seq: 1, #new-token: 894, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:57] Prefill batch. #new-seq: 1, #new-token: 445, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:58] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.51, #queue-req: 0, 
[2025-09-30 14:22:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:58] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:58] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.82, #queue-req: 0, 
[2025-09-30 14:22:58] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:22:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:58] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:59] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:59] Decode batch. #running-req: 1, #token: 517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.66, #queue-req: 0, 
[2025-09-30 14:22:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:59] Prefill batch. #new-seq: 1, #new-token: 716, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:22:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:22:59] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:00] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.56, #queue-req: 0, 
[2025-09-30 14:23:00] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:23:00] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.13, #queue-req: 0, 
[2025-09-30 14:23:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:00] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:00] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.26, #queue-req: 0, 
[2025-09-30 14:23:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:01] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:01] Prefill batch. #new-seq: 1, #new-token: 446, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:01] Decode batch. #running-req: 1, #token: 612, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.48, #queue-req: 0, 
[2025-09-30 14:23:02] Decode batch. #running-req: 1, #token: 652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.83, #queue-req: 0, 
[2025-09-30 14:23:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:02] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:02] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.21, #queue-req: 0, 
[2025-09-30 14:23:02] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:23:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:02] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:02] Prefill batch. #new-seq: 1, #new-token: 442, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:03] Decode batch. #running-req: 1, #token: 527, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.65, #queue-req: 0, 
[2025-09-30 14:23:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:03] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:03] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:03] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.59, #queue-req: 0, 
[2025-09-30 14:23:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:04] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:04] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:23:04] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:23:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:05] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:05] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:05] Decode batch. #running-req: 1, #token: 499, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.17, #queue-req: 0, 
[2025-09-30 14:23:05] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.34, #queue-req: 0, 
[2025-09-30 14:23:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:05] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:05] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.87, #queue-req: 0, 
[2025-09-30 14:23:06] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:23:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:06] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:06] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:06] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.53, #queue-req: 0, 
[2025-09-30 14:23:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:07] Prefill batch. #new-seq: 1, #new-token: 404, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:07] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:07] Decode batch. #running-req: 1, #token: 376, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.32, #queue-req: 0, 
[2025-09-30 14:23:07] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 14:23:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:07] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:08] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.94, #queue-req: 0, 
[2025-09-30 14:23:08] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:23:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:08] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:08] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:08] Decode batch. #running-req: 1, #token: 180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.07, #queue-req: 0, 
[2025-09-30 14:23:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:09] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:09] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:09] Decode batch. #running-req: 1, #token: 190, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.02, #queue-req: 0, 
[2025-09-30 14:23:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:09] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:09] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:10] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.65, #queue-req: 0, 
[2025-09-30 14:23:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:10] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:10] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:23:10] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:23:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:10] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:11] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:11] Decode batch. #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.19, #queue-req: 0, 
[2025-09-30 14:23:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:11] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:11] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:11] Decode batch. #running-req: 1, #token: 206, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.07, #queue-req: 0, 
[2025-09-30 14:23:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:12] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:12] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:12] Decode batch. #running-req: 1, #token: 452, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.51, #queue-req: 0, 
[2025-09-30 14:23:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:12] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:12] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.24, #queue-req: 0, 
[2025-09-30 14:23:13] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:23:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:13] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:13] Prefill batch. #new-seq: 1, #new-token: 386, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:13] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.36, #queue-req: 0, 
[2025-09-30 14:23:14] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.07, #queue-req: 0, 
[2025-09-30 14:23:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:14] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:14] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:23:14] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:23:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:14] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:15] Prefill batch. #new-seq: 1, #new-token: 382, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:15] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.01, #queue-req: 0, 
[2025-09-30 14:23:15] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.58, #queue-req: 0, 
[2025-09-30 14:23:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:15] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:16] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 454, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:16] Decode batch. #running-req: 1, #token: 476, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.35, #queue-req: 0, 
[2025-09-30 14:23:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:16] Prefill batch. #new-seq: 1, #new-token: 1312, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:16] Decode batch. #running-req: 1, #token: 1690, token usage: 0.03, cuda graph: True, gen throughput (token/s): 55.06, #queue-req: 0, 
[2025-09-30 14:23:17] Decode batch. #running-req: 1, #token: 1730, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:23:17] Decode batch. #running-req: 1, #token: 1770, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:23:17] Decode batch. #running-req: 1, #token: 1810, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.26, #queue-req: 0, 
[2025-09-30 14:23:18] Decode batch. #running-req: 1, #token: 1850, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:23:18] Decode batch. #running-req: 1, #token: 1890, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:23:18] Decode batch. #running-req: 1, #token: 1930, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:23:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:19] Prefill batch. #new-seq: 1, #new-token: 1312, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:19] Decode batch. #running-req: 1, #token: 1647, token usage: 0.03, cuda graph: True, gen throughput (token/s): 104.20, #queue-req: 0, 
[2025-09-30 14:23:19] Decode batch. #running-req: 1, #token: 1687, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:23:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:19] Prefill batch. #new-seq: 1, #new-token: 787, #cached-token: 238, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:19] Decode batch. #running-req: 1, #token: 1052, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.14, #queue-req: 0, 
[2025-09-30 14:23:20] Decode batch. #running-req: 1, #token: 1092, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:23:20] Decode batch. #running-req: 1, #token: 1132, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.85, #queue-req: 0, 
[2025-09-30 14:23:20] Decode batch. #running-req: 1, #token: 1172, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:23:21] Decode batch. #running-req: 1, #token: 1212, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:23:21] Decode batch. #running-req: 1, #token: 1252, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:23:21] Decode batch. #running-req: 1, #token: 1292, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.55, #queue-req: 0, 
[2025-09-30 14:23:22] Decode batch. #running-req: 1, #token: 1332, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.24, #queue-req: 0, 
[2025-09-30 14:23:22] Decode batch. #running-req: 1, #token: 1372, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:23:22] Decode batch. #running-req: 1, #token: 1412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:23:23] Decode batch. #running-req: 1, #token: 1452, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:23:23] Decode batch. #running-req: 1, #token: 1492, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:23:23] Decode batch. #running-req: 1, #token: 1532, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:23:23] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.61, #queue-req: 0, 
[2025-09-30 14:23:24] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:23:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:24] Prefill batch. #new-seq: 1, #new-token: 966, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:24] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:24] Decode batch. #running-req: 1, #token: 756, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.04, #queue-req: 0, 
[2025-09-30 14:23:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:25] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.11, #queue-req: 0, 
[2025-09-30 14:23:25] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:25] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:23:25] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:23:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:26] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:26] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:26] Decode batch. #running-req: 1, #token: 676, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.95, #queue-req: 0, 
[2025-09-30 14:23:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:26] Prefill batch. #new-seq: 1, #new-token: 1154, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:26] Prefill batch. #new-seq: 1, #new-token: 574, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:27] Decode batch. #running-req: 1, #token: 771, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.86, #queue-req: 0, 
[2025-09-30 14:23:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:27] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:27] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.98, #queue-req: 0, 
[2025-09-30 14:23:27] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:23:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:28] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:28] Prefill batch. #new-seq: 1, #new-token: 570, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:28] Decode batch. #running-req: 1, #token: 654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.88, #queue-req: 0, 
[2025-09-30 14:23:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:28] Prefill batch. #new-seq: 1, #new-token: 1173, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:29] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:29] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.74, #queue-req: 0, 
[2025-09-30 14:23:29] Decode batch. #running-req: 1, #token: 829, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.01, #queue-req: 0, 
[2025-09-30 14:23:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:29] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:23:29] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:30] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.36, #queue-req: 0, 
[2025-09-30 14:23:30] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:23:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:30] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:30] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:31] Decode batch. #running-req: 1, #token: 699, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.89, #queue-req: 0, 
[2025-09-30 14:23:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:31] Prefill batch. #new-seq: 1, #new-token: 1046, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:31] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:31] Decode batch. #running-req: 1, #token: 648, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.78, #queue-req: 0, 
[2025-09-30 14:23:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:31] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:32] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 14:23:32] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:23:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:32] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:32] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:32] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.59, #queue-req: 0, 
[2025-09-30 14:23:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:33] Prefill batch. #new-seq: 1, #new-token: 813, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:33] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:33] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.90, #queue-req: 0, 
[2025-09-30 14:23:34] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.15, #queue-req: 0, 
[2025-09-30 14:23:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:34] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:34] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:23:34] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:23:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:34] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:34] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:35] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.42, #queue-req: 0, 
[2025-09-30 14:23:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:35] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:35] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:36] Decode batch. #running-req: 1, #token: 683, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.16, #queue-req: 0, 
[2025-09-30 14:23:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:36] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:36] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.76, #queue-req: 0, 
[2025-09-30 14:23:36] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:23:36] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:23:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:37] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:37] Prefill batch. #new-seq: 1, #new-token: 497, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:37] Decode batch. #running-req: 1, #token: 585, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.58, #queue-req: 0, 
[2025-09-30 14:23:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:37] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:38] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.39, #queue-req: 0, 
[2025-09-30 14:23:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:38] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 567, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:38] Decode batch. #running-req: 1, #token: 589, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.45, #queue-req: 0, 
[2025-09-30 14:23:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:38] Prefill batch. #new-seq: 1, #new-token: 1091, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:38] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:39] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:39] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.86, #queue-req: 0, 
[2025-09-30 14:23:39] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:23:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:39] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:39] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.69, #queue-req: 0, 
[2025-09-30 14:23:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:39] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:40] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.50, #queue-req: 0, 
[2025-09-30 14:23:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:40] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 664, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.31, #queue-req: 0, 
[2025-09-30 14:23:41] Prefill batch. #new-seq: 1, #new-token: 1067, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:41] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:41] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.25, #queue-req: 0, 
[2025-09-30 14:23:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:41] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:42] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.51, #queue-req: 0, 
[2025-09-30 14:23:42] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:23:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:42] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.57, #queue-req: 0, 
[2025-09-30 14:23:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:42] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:43] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:43] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.89, #queue-req: 0, 
[2025-09-30 14:23:43] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:43] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:43] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.77, #queue-req: 0, 
[2025-09-30 14:23:44] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.70, #queue-req: 0, 
[2025-09-30 14:23:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:44] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:44] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:44] Decode batch. #running-req: 1, #token: 483, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.70, #queue-req: 0, 
[2025-09-30 14:23:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:45] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:45] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 464, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:45] Decode batch. #running-req: 1, #token: 467, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.96, #queue-req: 0, 
[2025-09-30 14:23:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:46] Prefill batch. #new-seq: 1, #new-token: 1042, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:46] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:46] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.62, #queue-req: 0, 
[2025-09-30 14:23:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:46] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:46] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.77, #queue-req: 0, 
[2025-09-30 14:23:46] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:23:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:47] Prefill batch. #new-seq: 1, #new-token: 1187, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:47] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:47] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.81, #queue-req: 0, 
[2025-09-30 14:23:47] Decode batch. #running-req: 1, #token: 758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:23:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:47] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:47] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 14:23:48] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:23:48] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:23:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:48] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:48] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:49] Prefill batch. #new-seq: 1, #new-token: 1159, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:49] Prefill batch. #new-seq: 1, #new-token: 618, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:49] Decode batch. #running-req: 1, #token: 786, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.49, #queue-req: 0, 
[2025-09-30 14:23:50] Decode batch. #running-req: 1, #token: 826, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 14:23:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:50] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:50] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.46, #queue-req: 0, 
[2025-09-30 14:23:50] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:23:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:50] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:51] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:51] Decode batch. #running-req: 1, #token: 711, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.00, #queue-req: 0, 
[2025-09-30 14:23:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:51] Prefill batch. #new-seq: 1, #new-token: 1217, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:51] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:52] Decode batch. #running-req: 1, #token: 804, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.70, #queue-req: 0, 
[2025-09-30 14:23:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:52] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:52] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.81, #queue-req: 0, 
[2025-09-30 14:23:52] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:23:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:53] Prefill batch. #new-seq: 1, #new-token: 1202, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:53] Prefill batch. #new-seq: 1, #new-token: 608, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:53] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.91, #queue-req: 0, 
[2025-09-30 14:23:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:53] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:53] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.07, #queue-req: 0, 
[2025-09-30 14:23:54] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:23:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:54] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:54] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:54] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.95, #queue-req: 0, 
[2025-09-30 14:23:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:55] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:55] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.23, #queue-req: 0, 
[2025-09-30 14:23:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:55] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 675, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:55] Prefill batch. #new-seq: 1, #new-token: 877, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:55] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:55] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.52, #queue-req: 0, 
[2025-09-30 14:23:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:56] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:56] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 14:23:56] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:23:56] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:23:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:57] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:57] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:57] Decode batch. #running-req: 1, #token: 359, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.84, #queue-req: 0, 
[2025-09-30 14:23:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:58] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:58] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:58] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.68, #queue-req: 0, 
[2025-09-30 14:23:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:58] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:58] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:23:58] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:23:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:59] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:59] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:59] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.14, #queue-req: 0, 
[2025-09-30 14:23:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:59] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:23:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 221, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:23:59] Decode batch. #running-req: 1, #token: 226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.44, #queue-req: 0, 
[2025-09-30 14:24:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:00] Prefill batch. #new-seq: 1, #new-token: 833, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:00] Prefill batch. #new-seq: 1, #new-token: 682, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:00] Decode batch. #running-req: 1, #token: 864, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.51, #queue-req: 0, 
[2025-09-30 14:24:01] Decode batch. #running-req: 1, #token: 904, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:24:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:01] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:01] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:24:01] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:24:02] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:24:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:02] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:02] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:02] Decode batch. #running-req: 1, #token: 761, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.41, #queue-req: 0, 
[2025-09-30 14:24:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:02] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:03] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.94, #queue-req: 0, 
[2025-09-30 14:24:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 751, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:03] Prefill batch. #new-seq: 1, #new-token: 1367, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:03] Prefill batch. #new-seq: 1, #new-token: 691, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:03] Decode batch. #running-req: 1, #token: 868, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.08, #queue-req: 0, 
[2025-09-30 14:24:04] Decode batch. #running-req: 1, #token: 908, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:24:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:04] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:04] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.39, #queue-req: 0, 
[2025-09-30 14:24:04] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:24:05] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:24:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:05] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:05] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:05] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.97, #queue-req: 0, 
[2025-09-30 14:24:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:06] Prefill batch. #new-seq: 1, #new-token: 1237, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:06] Prefill batch. #new-seq: 1, #new-token: 553, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:06] Decode batch. #running-req: 1, #token: 751, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.77, #queue-req: 0, 
[2025-09-30 14:24:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:06] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:06] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 14:24:07] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:24:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:07] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:07] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.55, #queue-req: 0, 
[2025-09-30 14:24:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:07] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:08] Prefill batch. #new-seq: 1, #new-token: 1241, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:08] Prefill batch. #new-seq: 1, #new-token: 690, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:08] Decode batch. #running-req: 1, #token: 860, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.78, #queue-req: 0, 
[2025-09-30 14:24:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:08] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:08] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.27, #queue-req: 0, 
[2025-09-30 14:24:09] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:24:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:09] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:09] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.76, #queue-req: 0, 
[2025-09-30 14:24:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:09] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:09] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 112.89, #queue-req: 0, 
[2025-09-30 14:24:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:10] Prefill batch. #new-seq: 1, #new-token: 1411, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:10] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:11] Decode batch. #running-req: 1, #token: 923, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.68, #queue-req: 0, 
[2025-09-30 14:24:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:11] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:11] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.05, #queue-req: 0, 
[2025-09-30 14:24:11] Decode batch. #running-req: 1, #token: 378, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:24:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:12] Prefill batch. #new-seq: 1, #new-token: 949, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:12] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:12] Decode batch. #running-req: 1, #token: 420, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.42, #queue-req: 0, 
[2025-09-30 14:24:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:12] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:12] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.81, #queue-req: 0, 
[2025-09-30 14:24:13] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:24:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:13] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:13] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:13] Decode batch. #running-req: 1, #token: 396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.04, #queue-req: 0, 
[2025-09-30 14:24:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:13] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:14] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.05, #queue-req: 0, 
[2025-09-30 14:24:14] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:24:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:14] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:14] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:14] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.46, #queue-req: 0, 
[2025-09-30 14:24:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:15] Prefill batch. #new-seq: 1, #new-token: 1717, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:15] Decode batch. #running-req: 1, #token: 2086, token usage: 0.03, cuda graph: True, gen throughput (token/s): 35.40, #queue-req: 0, 
[2025-09-30 14:24:16] Decode batch. #running-req: 1, #token: 2126, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:24:16] Decode batch. #running-req: 1, #token: 2166, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:24:16] Decode batch. #running-req: 1, #token: 2206, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:24:17] Decode batch. #running-req: 1, #token: 2246, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:24:17] Decode batch. #running-req: 1, #token: 2286, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:24:17] Decode batch. #running-req: 1, #token: 2326, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.96, #queue-req: 0, 
[2025-09-30 14:24:18] Decode batch. #running-req: 1, #token: 2366, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:24:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:18] Prefill batch. #new-seq: 1, #new-token: 1717, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:18] Decode batch. #running-req: 1, #token: 2060, token usage: 0.03, cuda graph: True, gen throughput (token/s): 98.19, #queue-req: 0, 
[2025-09-30 14:24:18] Decode batch. #running-req: 1, #token: 2100, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.35, #queue-req: 0, 
[2025-09-30 14:24:19] Decode batch. #running-req: 1, #token: 2140, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:24:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:19] Prefill batch. #new-seq: 1, #new-token: 753, #cached-token: 310, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:19] Decode batch. #running-req: 1, #token: 1092, token usage: 0.02, cuda graph: True, gen throughput (token/s): 113.54, #queue-req: 0, 
[2025-09-30 14:24:19] Decode batch. #running-req: 1, #token: 1132, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.92, #queue-req: 0, 
[2025-09-30 14:24:20] Decode batch. #running-req: 1, #token: 1172, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:24:20] Decode batch. #running-req: 1, #token: 1212, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:24:20] Decode batch. #running-req: 1, #token: 1252, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:24:21] Decode batch. #running-req: 1, #token: 1292, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.57, #queue-req: 0, 
[2025-09-30 14:24:21] Decode batch. #running-req: 1, #token: 1332, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 14:24:21] Decode batch. #running-req: 1, #token: 1372, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.21, #queue-req: 0, 
[2025-09-30 14:24:22] Decode batch. #running-req: 1, #token: 1412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:24:22] Decode batch. #running-req: 1, #token: 1452, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:24:22] Decode batch. #running-req: 1, #token: 1492, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:24:22] Decode batch. #running-req: 1, #token: 1532, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.00, #queue-req: 0, 
[2025-09-30 14:24:23] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.66, #queue-req: 0, 
[2025-09-30 14:24:23] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:24:23] Decode batch. #running-req: 1, #token: 1652, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:24:24] Decode batch. #running-req: 1, #token: 1692, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:24:24] Decode batch. #running-req: 1, #token: 1732, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:24:24] Decode batch. #running-req: 1, #token: 1772, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:24:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:25] Prefill batch. #new-seq: 1, #new-token: 508, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:25] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:25] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.21, #queue-req: 0, 
[2025-09-30 14:24:25] Decode batch. #running-req: 1, #token: 547, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.50, #queue-req: 0, 
[2025-09-30 14:24:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:26] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:26] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.40, #queue-req: 0, 
[2025-09-30 14:24:26] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:24:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:27] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:27] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:27] Decode batch. #running-req: 1, #token: 565, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.07, #queue-req: 0, 
[2025-09-30 14:24:27] Decode batch. #running-req: 1, #token: 605, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.98, #queue-req: 0, 
[2025-09-30 14:24:27] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.94, #queue-req: 0, 
[2025-09-30 14:24:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:27] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:28] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:24:28] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:24:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:28] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:28] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:29] Decode batch. #running-req: 1, #token: 406, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.29, #queue-req: 0, 
[2025-09-30 14:24:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:29] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:29] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:29] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:29] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.86, #queue-req: 0, 
[2025-09-30 14:24:30] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:24:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:30] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:30] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.29, #queue-req: 0, 
[2025-09-30 14:24:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:30] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:31] Prefill batch. #new-seq: 1, #new-token: 423, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:31] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:31] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.94, #queue-req: 0, 
[2025-09-30 14:24:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:31] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:31] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.25, #queue-req: 0, 
[2025-09-30 14:24:32] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:24:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:32] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:32] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:32] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 113.94, #queue-req: 0, 
[2025-09-30 14:24:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:32] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:32] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:24:33] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:24:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:33] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:33] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.16, #queue-req: 0, 
[2025-09-30 14:24:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:33] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:34] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:34] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:34] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.59, #queue-req: 0, 
[2025-09-30 14:24:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:34] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:34] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.96, #queue-req: 0, 
[2025-09-30 14:24:35] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:24:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:35] Prefill batch. #new-seq: 1, #new-token: 1218, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:36] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:36] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.48, #queue-req: 0, 
[2025-09-30 14:24:36] Decode batch. #running-req: 1, #token: 770, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:24:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:36] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:36] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.59, #queue-req: 0, 
[2025-09-30 14:24:37] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:24:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:37] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:37] Prefill batch. #new-seq: 1, #new-token: 553, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:37] Decode batch. #running-req: 1, #token: 647, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.20, #queue-req: 0, 
[2025-09-30 14:24:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:37] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:38] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 625, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:38] Decode batch. #running-req: 1, #token: 651, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.56, #queue-req: 0, 
[2025-09-30 14:24:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:38] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:38] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:38] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:39] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.98, #queue-req: 0, 
[2025-09-30 14:24:39] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:24:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:39] Prefill batch. #new-seq: 1, #new-token: 907, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:39] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:40] Decode batch. #running-req: 1, #token: 612, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.58, #queue-req: 0, 
[2025-09-30 14:24:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:40] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:40] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 14:24:40] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:24:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:41] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.82, #queue-req: 0, 
[2025-09-30 14:24:41] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:42] Prefill batch. #new-seq: 1, #new-token: 993, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:42] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:42] Decode batch. #running-req: 1, #token: 760, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.03, #queue-req: 0, 
[2025-09-30 14:24:42] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 14:24:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:42] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:42] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.65, #queue-req: 0, 
[2025-09-30 14:24:43] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:24:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:43] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:43] Prefill batch. #new-seq: 1, #new-token: 579, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:44] Prefill batch. #new-seq: 1, #new-token: 1039, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:44] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 35.91, #queue-req: 0, 
[2025-09-30 14:24:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:44] Prefill batch. #new-seq: 1, #new-token: 524, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:44] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.57, #queue-req: 0, 
[2025-09-30 14:24:44] Decode batch. #running-req: 1, #token: 758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:24:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:45] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:45] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 125.12, #queue-req: 0, 
[2025-09-30 14:24:45] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:24:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:45] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:45] Prefill batch. #new-seq: 1, #new-token: 460, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:46] Decode batch. #running-req: 1, #token: 553, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.66, #queue-req: 0, 
[2025-09-30 14:24:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:46] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:46] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:46] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.27, #queue-req: 0, 
[2025-09-30 14:24:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:47] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:47] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.52, #queue-req: 0, 
[2025-09-30 14:24:47] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:24:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:47] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:47] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:47] Decode batch. #running-req: 1, #token: 169, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.77, #queue-req: 0, 
[2025-09-30 14:24:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:48] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:48] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:48] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.11, #queue-req: 0, 
[2025-09-30 14:24:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:49] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:49] Decode batch. #running-req: 1, #token: 229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 14:24:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:49] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:49] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:49] Decode batch. #running-req: 1, #token: 157, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.58, #queue-req: 0, 
[2025-09-30 14:24:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:50] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:50] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:50] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:50] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.61, #queue-req: 0, 
[2025-09-30 14:24:50] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:24:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:51] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:51] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 68.90, #queue-req: 0, 
[2025-09-30 14:24:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:51] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:51] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:51] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:52] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.94, #queue-req: 0, 
[2025-09-30 14:24:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:52] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:52] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.10, #queue-req: 0, 
[2025-09-30 14:24:52] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:24:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:53] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:53] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:53] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.56, #queue-req: 0, 
[2025-09-30 14:24:53] Decode batch. #running-req: 1, #token: 349, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.44, #queue-req: 0, 
[2025-09-30 14:24:54] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0, 
[2025-09-30 14:24:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:54] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:54] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.52, #queue-req: 0, 
[2025-09-30 14:24:54] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:24:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:55] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:55] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:55] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.19, #queue-req: 0, 
[2025-09-30 14:24:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:55] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:55] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:56] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:56] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.83, #queue-req: 0, 
[2025-09-30 14:24:56] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:24:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:57] Prefill batch. #new-seq: 1, #new-token: 686, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:57] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:57] Decode batch. #running-req: 1, #token: 814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.37, #queue-req: 0, 
[2025-09-30 14:24:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:57] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:57] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.33, #queue-req: 0, 
[2025-09-30 14:24:57] Decode batch. #running-req: 1, #token: 336, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:24:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:58] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:58] Prefill batch. #new-seq: 1, #new-token: 629, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:58] Decode batch. #running-req: 1, #token: 719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.07, #queue-req: 0, 
[2025-09-30 14:24:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:58] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:59] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.78, #queue-req: 0, 
[2025-09-30 14:24:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 701, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:59] Prefill batch. #new-seq: 1, #new-token: 1234, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:24:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:24:59] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:00] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.30, #queue-req: 0, 
[2025-09-30 14:25:00] Decode batch. #running-req: 1, #token: 816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.09, #queue-req: 0, 
[2025-09-30 14:25:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:00] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:00] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.20, #queue-req: 0, 
[2025-09-30 14:25:00] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:25:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:01] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:01] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:01] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.12, #queue-req: 0, 
[2025-09-30 14:25:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:02] Prefill batch. #new-seq: 1, #new-token: 1202, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:02] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:02] Decode batch. #running-req: 1, #token: 780, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.63, #queue-req: 0, 
[2025-09-30 14:25:02] Decode batch. #running-req: 1, #token: 820, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.93, #queue-req: 0, 
[2025-09-30 14:25:03] Decode batch. #running-req: 1, #token: 860, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:25:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:03] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:03] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:25:03] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:25:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:03] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:03] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:04] Prefill batch. #new-seq: 1, #new-token: 1156, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:04] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:04] Decode batch. #running-req: 1, #token: 733, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.71, #queue-req: 0, 
[2025-09-30 14:25:05] Decode batch. #running-req: 1, #token: 773, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:25:05] Decode batch. #running-req: 1, #token: 813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 14:25:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:05] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:05] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.20, #queue-req: 0, 
[2025-09-30 14:25:06] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:25:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:06] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:06] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:06] Decode batch. #running-req: 1, #token: 641, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.96, #queue-req: 0, 
[2025-09-30 14:25:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:07] Prefill batch. #new-seq: 1, #new-token: 1073, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:07] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:07] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.89, #queue-req: 0, 
[2025-09-30 14:25:07] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:25:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:07] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:08] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.94, #queue-req: 0, 
[2025-09-30 14:25:08] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:25:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:09] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:09] Prefill batch. #new-seq: 1, #new-token: 513, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:09] Decode batch. #running-req: 1, #token: 588, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.37, #queue-req: 0, 
[2025-09-30 14:25:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:09] Prefill batch. #new-seq: 1, #new-token: 937, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:09] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:09] Decode batch. #running-req: 1, #token: 605, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.71, #queue-req: 0, 
[2025-09-30 14:25:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:10] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:10] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:25:10] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:25:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:10] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:10] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:10] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.80, #queue-req: 0, 
[2025-09-30 14:25:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:11] Prefill batch. #new-seq: 1, #new-token: 942, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:11] Prefill batch. #new-seq: 1, #new-token: 522, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:12] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.83, #queue-req: 0, 
[2025-09-30 14:25:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:12] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:12] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.37, #queue-req: 0, 
[2025-09-30 14:25:12] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:25:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:12] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:13] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.05, #queue-req: 0, 
[2025-09-30 14:25:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:13] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:13] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:13] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.61, #queue-req: 0, 
[2025-09-30 14:25:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 587, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:14] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 118.54, #queue-req: 0, 
[2025-09-30 14:25:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:14] Prefill batch. #new-seq: 1, #new-token: 1075, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:14] Prefill batch. #new-seq: 1, #new-token: 557, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:15] Decode batch. #running-req: 1, #token: 737, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.21, #queue-req: 0, 
[2025-09-30 14:25:15] Decode batch. #running-req: 1, #token: 777, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.36, #queue-req: 0, 
[2025-09-30 14:25:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:15] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:15] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.60, #queue-req: 0, 
[2025-09-30 14:25:16] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:25:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:16] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:16] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:16] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.28, #queue-req: 0, 
[2025-09-30 14:25:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:17] Prefill batch. #new-seq: 1, #new-token: 1146, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:17] Decode batch. #running-req: 1, #token: 1516, token usage: 0.02, cuda graph: True, gen throughput (token/s): 48.35, #queue-req: 0, 
[2025-09-30 14:25:17] Decode batch. #running-req: 1, #token: 1556, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.83, #queue-req: 0, 
[2025-09-30 14:25:18] Decode batch. #running-req: 1, #token: 1596, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.59, #queue-req: 0, 
[2025-09-30 14:25:18] Decode batch. #running-req: 1, #token: 1636, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:25:18] Decode batch. #running-req: 1, #token: 1676, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:25:19] Decode batch. #running-req: 1, #token: 1716, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:25:19] Decode batch. #running-req: 1, #token: 1756, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:25:19] Decode batch. #running-req: 1, #token: 1796, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:25:19] Decode batch. #running-req: 1, #token: 1836, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.02, #queue-req: 0, 
[2025-09-30 14:25:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:20] Prefill batch. #new-seq: 1, #new-token: 1146, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:20] Decode batch. #running-req: 1, #token: 1497, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.66, #queue-req: 0, 
[2025-09-30 14:25:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:20] Prefill batch. #new-seq: 1, #new-token: 947, #cached-token: 235, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:20] Decode batch. #running-req: 1, #token: 1187, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.07, #queue-req: 0, 
[2025-09-30 14:25:21] Decode batch. #running-req: 1, #token: 1227, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:25:21] Decode batch. #running-req: 1, #token: 1267, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:25:21] Decode batch. #running-req: 1, #token: 1307, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.37, #queue-req: 0, 
[2025-09-30 14:25:21] Decode batch. #running-req: 1, #token: 1347, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.23, #queue-req: 0, 
[2025-09-30 14:25:22] Decode batch. #running-req: 1, #token: 1387, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:25:22] Decode batch. #running-req: 1, #token: 1427, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:25:22] Decode batch. #running-req: 1, #token: 1467, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.01, #queue-req: 0, 
[2025-09-30 14:25:23] Decode batch. #running-req: 1, #token: 1507, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:25:23] Decode batch. #running-req: 1, #token: 1547, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.94, #queue-req: 0, 
[2025-09-30 14:25:23] Decode batch. #running-req: 1, #token: 1587, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:25:24] Decode batch. #running-req: 1, #token: 1627, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:25:24] Decode batch. #running-req: 1, #token: 1667, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:25:24] Decode batch. #running-req: 1, #token: 1707, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:25:25] Decode batch. #running-req: 1, #token: 1747, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:25:25] Decode batch. #running-req: 1, #token: 1787, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:25:25] Decode batch. #running-req: 1, #token: 1827, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:25:25] Decode batch. #running-req: 1, #token: 1867, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:25:26] Decode batch. #running-req: 1, #token: 1907, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:25:26] Decode batch. #running-req: 1, #token: 1947, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:25:26] Decode batch. #running-req: 1, #token: 1987, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:25:27] Decode batch. #running-req: 1, #token: 2027, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.73, #queue-req: 0, 
[2025-09-30 14:25:27] Decode batch. #running-req: 1, #token: 2067, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.50, #queue-req: 0, 
[2025-09-30 14:25:27] Decode batch. #running-req: 1, #token: 2107, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:25:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:28] Prefill batch. #new-seq: 1, #new-token: 1016, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:28] Prefill batch. #new-seq: 1, #new-token: 466, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:28] Decode batch. #running-req: 1, #token: 661, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.88, #queue-req: 0, 
[2025-09-30 14:25:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:28] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:29] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.73, #queue-req: 0, 
[2025-09-30 14:25:29] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:25:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:29] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:30] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 66.99, #queue-req: 0, 
[2025-09-30 14:25:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:30] Prefill batch. #new-seq: 1, #new-token: 462, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:30] Prefill batch. #new-seq: 1, #new-token: 788, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:30] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:30] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.30, #queue-req: 0, 
[2025-09-30 14:25:31] Decode batch. #running-req: 1, #token: 533, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.59, #queue-req: 0, 
[2025-09-30 14:25:31] Decode batch. #running-req: 1, #token: 573, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:25:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:31] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:31] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.18, #queue-req: 0, 
[2025-09-30 14:25:32] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:25:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:32] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:32] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:32] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.01, #queue-req: 0, 
[2025-09-30 14:25:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:33] Prefill batch. #new-seq: 1, #new-token: 727, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:33] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:33] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.42, #queue-req: 0, 
[2025-09-30 14:25:33] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:25:34] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.58, #queue-req: 0, 
[2025-09-30 14:25:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:34] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:34] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 125.66, #queue-req: 0, 
[2025-09-30 14:25:34] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:25:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:35] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:35] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:35] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.75, #queue-req: 0, 
[2025-09-30 14:25:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:35] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:35] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 473, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:36] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.05, #queue-req: 0, 
[2025-09-30 14:25:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:36] Prefill batch. #new-seq: 1, #new-token: 672, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:36] Decode batch. #running-req: 1, #token: 1048, token usage: 0.02, cuda graph: True, gen throughput (token/s): 49.30, #queue-req: 0, 
[2025-09-30 14:25:37] Decode batch. #running-req: 1, #token: 1088, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:25:37] Decode batch. #running-req: 1, #token: 1128, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:25:37] Decode batch. #running-req: 1, #token: 1168, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:25:38] Decode batch. #running-req: 1, #token: 1208, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:25:38] Decode batch. #running-req: 1, #token: 1248, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:25:38] Decode batch. #running-req: 1, #token: 1288, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.61, #queue-req: 0, 
[2025-09-30 14:25:39] Decode batch. #running-req: 1, #token: 1328, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.29, #queue-req: 0, 
[2025-09-30 14:25:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:39] Prefill batch. #new-seq: 1, #new-token: 672, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:39] Decode batch. #running-req: 1, #token: 1026, token usage: 0.02, cuda graph: True, gen throughput (token/s): 114.01, #queue-req: 0, 
[2025-09-30 14:25:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:39] Prefill batch. #new-seq: 1, #new-token: 1215, #cached-token: 179, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:39] Decode batch. #running-req: 1, #token: 1412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.85, #queue-req: 0, 
[2025-09-30 14:25:40] Decode batch. #running-req: 1, #token: 1452, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 14:25:40] Decode batch. #running-req: 1, #token: 1492, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:25:40] Decode batch. #running-req: 1, #token: 1532, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:25:41] Decode batch. #running-req: 1, #token: 1572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.65, #queue-req: 0, 
[2025-09-30 14:25:41] Decode batch. #running-req: 1, #token: 1612, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:25:41] Decode batch. #running-req: 1, #token: 1652, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:25:41] Decode batch. #running-req: 1, #token: 1692, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 14:25:42] Decode batch. #running-req: 1, #token: 1732, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:25:42] Decode batch. #running-req: 1, #token: 1772, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:25:42] Decode batch. #running-req: 1, #token: 1812, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.21, #queue-req: 0, 
[2025-09-30 14:25:43] Decode batch. #running-req: 1, #token: 1852, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:25:43] Decode batch. #running-req: 1, #token: 1892, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:25:43] Decode batch. #running-req: 1, #token: 1932, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:25:44] Decode batch. #running-req: 1, #token: 1972, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:25:44] Decode batch. #running-req: 1, #token: 2012, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:25:44] Decode batch. #running-req: 1, #token: 2052, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.73, #queue-req: 0, 
[2025-09-30 14:25:45] Decode batch. #running-req: 1, #token: 2092, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:25:45] Decode batch. #running-req: 1, #token: 2132, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:25:45] Decode batch. #running-req: 1, #token: 2172, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:25:46] Decode batch. #running-req: 1, #token: 2212, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:25:46] Decode batch. #running-req: 1, #token: 2252, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:25:46] Decode batch. #running-req: 1, #token: 2292, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:25:46] Decode batch. #running-req: 1, #token: 2332, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.81, #queue-req: 0, 
[2025-09-30 14:25:47] Decode batch. #running-req: 1, #token: 2372, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.63, #queue-req: 0, 
[2025-09-30 14:25:47] Decode batch. #running-req: 1, #token: 2412, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.63, #queue-req: 0, 
[2025-09-30 14:25:47] Decode batch. #running-req: 1, #token: 2452, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:25:48] Decode batch. #running-req: 1, #token: 2492, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:25:48] Decode batch. #running-req: 1, #token: 2532, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.52, #queue-req: 0, 
[2025-09-30 14:25:48] Decode batch. #running-req: 1, #token: 2572, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.40, #queue-req: 0, 
[2025-09-30 14:25:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:49] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:49] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:49] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-09-30 14:25:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:49] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:49] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.19, #queue-req: 0, 
[2025-09-30 14:25:50] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:25:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:50] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:50] Decode batch. #running-req: 1, #token: 341, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.70, #queue-req: 0, 
[2025-09-30 14:25:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:51] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 335, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:51] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.10, #queue-req: 0, 
[2025-09-30 14:25:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:52] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:52] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:52] Decode batch. #running-req: 1, #token: 459, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.42, #queue-req: 0, 
[2025-09-30 14:25:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:52] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:52] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.09, #queue-req: 0, 
[2025-09-30 14:25:52] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:25:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:53] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:53] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.05, #queue-req: 0, 
[2025-09-30 14:25:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:53] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:54] Prefill batch. #new-seq: 1, #new-token: 404, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:54] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:54] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 36.15, #queue-req: 0, 
[2025-09-30 14:25:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:54] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:54] Decode batch. #running-req: 1, #token: 214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:25:55] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.74, #queue-req: 0, 
[2025-09-30 14:25:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:55] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:55] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.03, #queue-req: 0, 
[2025-09-30 14:25:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:55] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:56] Prefill batch. #new-seq: 1, #new-token: 723, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:56] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:56] Decode batch. #running-req: 1, #token: 769, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.29, #queue-req: 0, 
[2025-09-30 14:25:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:56] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:56] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.53, #queue-req: 0, 
[2025-09-30 14:25:57] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:25:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:57] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:57] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:57] Decode batch. #running-req: 1, #token: 673, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.26, #queue-req: 0, 
[2025-09-30 14:25:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:58] Prefill batch. #new-seq: 1, #new-token: 956, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:58] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:58] Decode batch. #running-req: 1, #token: 557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.98, #queue-req: 0, 
[2025-09-30 14:25:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:58] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:58] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.21, #queue-req: 0, 
[2025-09-30 14:25:59] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:25:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:59] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:25:59] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:25:59] Decode batch. #running-req: 1, #token: 458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.08, #queue-req: 0, 
[2025-09-30 14:25:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:00] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:00] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 438, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:00] Decode batch. #running-req: 1, #token: 462, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.07, #queue-req: 0, 
[2025-09-30 14:26:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:00] Prefill batch. #new-seq: 1, #new-token: 616, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:01] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:01] Decode batch. #running-req: 1, #token: 449, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.92, #queue-req: 0, 
[2025-09-30 14:26:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:01] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:01] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.03, #queue-req: 0, 
[2025-09-30 14:26:01] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:26:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:02] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:02] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:02] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.50, #queue-req: 0, 
[2025-09-30 14:26:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:03] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:03] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:03] Decode batch. #running-req: 1, #token: 554, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.52, #queue-req: 0, 
[2025-09-30 14:26:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:03] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:03] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:26:04] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:26:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:04] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:04] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:04] Decode batch. #running-req: 1, #token: 460, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.81, #queue-req: 0, 
[2025-09-30 14:26:05] Decode batch. #running-req: 1, #token: 500, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.92, #queue-req: 0, 
[2025-09-30 14:26:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:05] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:05] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.12, #queue-req: 0, 
[2025-09-30 14:26:05] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:26:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:05] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:06] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:06] Decode batch. #running-req: 1, #token: 386, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.73, #queue-req: 0, 
[2025-09-30 14:26:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:06] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:06] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 361, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:07] Prefill batch. #new-seq: 1, #new-token: 732, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:07] Prefill batch. #new-seq: 1, #new-token: 443, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:07] Decode batch. #running-req: 1, #token: 611, token usage: 0.01, cuda graph: True, gen throughput (token/s): 28.67, #queue-req: 0, 
[2025-09-30 14:26:07] Decode batch. #running-req: 1, #token: 651, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.82, #queue-req: 0, 
[2025-09-30 14:26:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:08] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:08] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.16, #queue-req: 0, 
[2025-09-30 14:26:08] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:26:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:08] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:08] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:08] Decode batch. #running-req: 1, #token: 529, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.44, #queue-req: 0, 
[2025-09-30 14:26:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:09] Prefill batch. #new-seq: 1, #new-token: 931, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:09] Prefill batch. #new-seq: 1, #new-token: 493, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:10] Decode batch. #running-req: 1, #token: 677, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.40, #queue-req: 0, 
[2025-09-30 14:26:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:10] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:10] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.12, #queue-req: 0, 
[2025-09-30 14:26:10] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:26:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:10] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:11] Decode batch. #running-req: 1, #token: 111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.41, #queue-req: 0, 
[2025-09-30 14:26:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:11] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:11] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:11] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 562, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:11] Decode batch. #running-req: 1, #token: 565, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.48, #queue-req: 0, 
[2025-09-30 14:26:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:12] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:12] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:12] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.14, #queue-req: 0, 
[2025-09-30 14:26:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:12] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:13] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.50, #queue-req: 0, 
[2025-09-30 14:26:13] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:26:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:13] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:14] Decode batch. #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.78, #queue-req: 0, 
[2025-09-30 14:26:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:14] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:14] Prefill batch. #new-seq: 1, #new-token: 1061, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:14] Prefill batch. #new-seq: 1, #new-token: 476, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:14] Decode batch. #running-req: 1, #token: 640, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.18, #queue-req: 0, 
[2025-09-30 14:26:15] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.68, #queue-req: 0, 
[2025-09-30 14:26:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:15] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:15] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.65, #queue-req: 0, 
[2025-09-30 14:26:15] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:26:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:16] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:16] Decode batch. #running-req: 1, #token: 115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.55, #queue-req: 0, 
[2025-09-30 14:26:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:16] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:16] Decode batch. #running-req: 1, #token: 564, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.28, #queue-req: 0, 
[2025-09-30 14:26:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:17] Prefill batch. #new-seq: 1, #new-token: 964, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:17] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:17] Decode batch. #running-req: 1, #token: 686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.88, #queue-req: 0, 
[2025-09-30 14:26:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:17] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:18] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.21, #queue-req: 0, 
[2025-09-30 14:26:18] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:26:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:18] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:18] Decode batch. #running-req: 1, #token: 112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.91, #queue-req: 0, 
[2025-09-30 14:26:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:18] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:19] Prefill batch. #new-seq: 1, #new-token: 1027, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:19] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:19] Decode batch. #running-req: 1, #token: 704, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.99, #queue-req: 0, 
[2025-09-30 14:26:20] Decode batch. #running-req: 1, #token: 744, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.46, #queue-req: 0, 
[2025-09-30 14:26:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:20] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:20] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 14:26:20] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:26:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:21] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:21] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.16, #queue-req: 0, 
[2025-09-30 14:26:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:21] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:22] Prefill batch. #new-seq: 1, #new-token: 2369, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:22] Decode batch. #running-req: 1, #token: 2722, token usage: 0.04, cuda graph: True, gen throughput (token/s): 41.36, #queue-req: 0, 
[2025-09-30 14:26:22] Decode batch. #running-req: 1, #token: 2762, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:26:22] Decode batch. #running-req: 1, #token: 2802, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.01, #queue-req: 0, 
[2025-09-30 14:26:23] Decode batch. #running-req: 1, #token: 2842, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.71, #queue-req: 0, 
[2025-09-30 14:26:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:23] Prefill batch. #new-seq: 1, #new-token: 2369, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:23] Decode batch. #running-req: 1, #token: 2711, token usage: 0.04, cuda graph: True, gen throughput (token/s): 90.55, #queue-req: 0, 
[2025-09-30 14:26:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:23] Prefill batch. #new-seq: 1, #new-token: 1032, #cached-token: 421, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:24] Decode batch. #running-req: 1, #token: 1482, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.72, #queue-req: 0, 
[2025-09-30 14:26:24] Decode batch. #running-req: 1, #token: 1522, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:26:24] Decode batch. #running-req: 1, #token: 1562, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.82, #queue-req: 0, 
[2025-09-30 14:26:25] Decode batch. #running-req: 1, #token: 1602, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:26:25] Decode batch. #running-req: 1, #token: 1642, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:26:25] Decode batch. #running-req: 1, #token: 1682, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:26:25] Decode batch. #running-req: 1, #token: 1722, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:26:26] Decode batch. #running-req: 1, #token: 1762, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:26:26] Decode batch. #running-req: 1, #token: 1802, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.28, #queue-req: 0, 
[2025-09-30 14:26:26] Decode batch. #running-req: 1, #token: 1842, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:26:27] Decode batch. #running-req: 1, #token: 1882, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:26:27] Decode batch. #running-req: 1, #token: 1922, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:26:27] Decode batch. #running-req: 1, #token: 1962, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:26:28] Decode batch. #running-req: 1, #token: 2002, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:26:28] Decode batch. #running-req: 1, #token: 2042, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:26:28] Decode batch. #running-req: 1, #token: 2082, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.39, #queue-req: 0, 
[2025-09-30 14:26:29] Decode batch. #running-req: 1, #token: 2122, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:26:29] Decode batch. #running-req: 1, #token: 2162, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:26:29] Decode batch. #running-req: 1, #token: 2202, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:26:30] Decode batch. #running-req: 1, #token: 2242, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:26:30] Decode batch. #running-req: 1, #token: 2282, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:26:30] Decode batch. #running-req: 1, #token: 2322, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.96, #queue-req: 0, 
[2025-09-30 14:26:30] Decode batch. #running-req: 1, #token: 2362, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:26:31] Decode batch. #running-req: 1, #token: 2402, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.62, #queue-req: 0, 
[2025-09-30 14:26:31] Decode batch. #running-req: 1, #token: 2442, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:26:31] Decode batch. #running-req: 1, #token: 2482, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:26:32] Decode batch. #running-req: 1, #token: 2522, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.55, #queue-req: 0, 
[2025-09-30 14:26:32] Decode batch. #running-req: 1, #token: 2562, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.55, #queue-req: 0, 
[2025-09-30 14:26:32] Decode batch. #running-req: 1, #token: 2602, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:26:33] Decode batch. #running-req: 1, #token: 2642, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:26:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:33] Prefill batch. #new-seq: 1, #new-token: 1143, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:33] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:34] Decode batch. #running-req: 1, #token: 871, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.91, #queue-req: 0, 
[2025-09-30 14:26:34] Decode batch. #running-req: 1, #token: 911, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.86, #queue-req: 0, 
[2025-09-30 14:26:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:34] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:34] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.54, #queue-req: 0, 
[2025-09-30 14:26:35] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:26:35] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:26:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:35] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:35] Prefill batch. #new-seq: 1, #new-token: 608, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:35] Decode batch. #running-req: 1, #token: 697, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.20, #queue-req: 0, 
[2025-09-30 14:26:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:36] Prefill batch. #new-seq: 1, #new-token: 1188, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:36] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:36] Decode batch. #running-req: 1, #token: 771, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.46, #queue-req: 0, 
[2025-09-30 14:26:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:37] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:37] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.98, #queue-req: 0, 
[2025-09-30 14:26:37] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:26:37] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:26:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:37] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:38] Prefill batch. #new-seq: 1, #new-token: 578, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:38] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:38] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.58, #queue-req: 0, 
[2025-09-30 14:26:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:38] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 650, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:39] Prefill batch. #new-seq: 1, #new-token: 1202, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:39] Prefill batch. #new-seq: 1, #new-token: 626, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:39] Decode batch. #running-req: 1, #token: 812, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.36, #queue-req: 0, 
[2025-09-30 14:26:39] Decode batch. #running-req: 1, #token: 852, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.02, #queue-req: 0, 
[2025-09-30 14:26:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:40] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:40] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.29, #queue-req: 0, 
[2025-09-30 14:26:40] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:26:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:40] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:40] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:41] Decode batch. #running-req: 1, #token: 706, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.64, #queue-req: 0, 
[2025-09-30 14:26:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:41] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 694, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:42] Prefill batch. #new-seq: 1, #new-token: 1249, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:42] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:42] Decode batch. #running-req: 1, #token: 800, token usage: 0.01, cuda graph: True, gen throughput (token/s): 27.00, #queue-req: 0, 
[2025-09-30 14:26:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:42] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:42] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.17, #queue-req: 0, 
[2025-09-30 14:26:43] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:26:43] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:26:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:44] Prefill batch. #new-seq: 1, #new-token: 1371, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:44] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:44] Decode batch. #running-req: 1, #token: 936, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.06, #queue-req: 0, 
[2025-09-30 14:26:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:44] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:44] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.13, #queue-req: 0, 
[2025-09-30 14:26:45] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:26:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:45] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:45] Decode batch. #running-req: 1, #token: 108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.29, #queue-req: 0, 
[2025-09-30 14:26:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:45] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:46] Prefill batch. #new-seq: 1, #new-token: 1374, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:46] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:46] Decode batch. #running-req: 1, #token: 825, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.08, #queue-req: 0, 
[2025-09-30 14:26:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:46] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:46] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.22, #queue-req: 0, 
[2025-09-30 14:26:47] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:26:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:47] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:47] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.36, #queue-req: 0, 
[2025-09-30 14:26:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:47] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:48] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:48] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-09-30 14:26:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:48] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 700, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:49] Prefill batch. #new-seq: 1, #new-token: 1068, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:49] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:49] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.86, #queue-req: 0, 
[2025-09-30 14:26:49] Decode batch. #running-req: 1, #token: 662, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.88, #queue-req: 0, 
[2025-09-30 14:26:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:49] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:50] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:26:50] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:26:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:51] Prefill batch. #new-seq: 1, #new-token: 790, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:51] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:51] Decode batch. #running-req: 1, #token: 528, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.37, #queue-req: 0, 
[2025-09-30 14:26:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:51] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 131.12, #queue-req: 0, 
[2025-09-30 14:26:51] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:51] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.54, #queue-req: 0, 
[2025-09-30 14:26:52] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:26:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:52] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:52] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:52] Decode batch. #running-req: 1, #token: 432, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.24, #queue-req: 0, 
[2025-09-30 14:26:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:53] Prefill batch. #new-seq: 1, #new-token: 495, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:53] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:53] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.03, #queue-req: 0, 
[2025-09-30 14:26:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:53] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:54] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.88, #queue-req: 0, 
[2025-09-30 14:26:54] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:26:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:54] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:54] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.94, #queue-req: 0, 
[2025-09-30 14:26:54] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:55] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:55] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:55] Decode batch. #running-req: 1, #token: 412, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.25, #queue-req: 0, 
[2025-09-30 14:26:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:56] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:56] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.87, #queue-req: 0, 
[2025-09-30 14:26:56] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:26:56] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:26:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:56] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:56] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:57] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.89, #queue-req: 0, 
[2025-09-30 14:26:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:57] Prefill batch. #new-seq: 1, #new-token: 662, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:58] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:58] Decode batch. #running-req: 1, #token: 675, token usage: 0.01, cuda graph: True, gen throughput (token/s): 33.95, #queue-req: 0, 
[2025-09-30 14:26:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:58] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:58] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.69, #queue-req: 0, 
[2025-09-30 14:26:58] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:26:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:59] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:26:59] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:26:59] Decode batch. #running-req: 1, #token: 507, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.04, #queue-req: 0, 
[2025-09-30 14:26:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:00] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:00] Decode batch. #running-req: 1, #token: 894, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.80, #queue-req: 0, 
[2025-09-30 14:27:00] Decode batch. #running-req: 1, #token: 934, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.55, #queue-req: 0, 
[2025-09-30 14:27:01] Decode batch. #running-req: 1, #token: 974, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.47, #queue-req: 0, 
[2025-09-30 14:27:01] Decode batch. #running-req: 1, #token: 1014, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:27:01] Decode batch. #running-req: 1, #token: 1054, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.09, #queue-req: 0, 
[2025-09-30 14:27:02] Decode batch. #running-req: 1, #token: 1094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 14:27:02] Decode batch. #running-req: 1, #token: 1134, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:27:02] Decode batch. #running-req: 1, #token: 1174, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:27:02] Decode batch. #running-req: 1, #token: 1214, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:27:03] Decode batch. #running-req: 1, #token: 1254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.73, #queue-req: 0, 
[2025-09-30 14:27:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:03] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:03] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.25, #queue-req: 0, 
[2025-09-30 14:27:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:03] Prefill batch. #new-seq: 1, #new-token: 1615, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:03] Decode batch. #running-req: 1, #token: 1779, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.90, #queue-req: 0, 
[2025-09-30 14:27:04] Decode batch. #running-req: 1, #token: 1819, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 14:27:04] Decode batch. #running-req: 1, #token: 1859, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:27:04] Decode batch. #running-req: 1, #token: 1899, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:27:05] Decode batch. #running-req: 1, #token: 1939, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:27:05] Decode batch. #running-req: 1, #token: 1979, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:27:05] Decode batch. #running-req: 1, #token: 2019, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.75, #queue-req: 0, 
[2025-09-30 14:27:06] Decode batch. #running-req: 1, #token: 2059, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.70, #queue-req: 0, 
[2025-09-30 14:27:06] Decode batch. #running-req: 1, #token: 2099, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:27:06] Decode batch. #running-req: 1, #token: 2139, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:27:07] Decode batch. #running-req: 1, #token: 2179, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:27:07] Decode batch. #running-req: 1, #token: 2219, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:27:07] Decode batch. #running-req: 1, #token: 2259, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:27:08] Decode batch. #running-req: 1, #token: 2299, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:27:08] Decode batch. #running-req: 1, #token: 2339, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.71, #queue-req: 0, 
[2025-09-30 14:27:08] Decode batch. #running-req: 1, #token: 2379, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.71, #queue-req: 0, 
[2025-09-30 14:27:09] Decode batch. #running-req: 1, #token: 2419, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.54, #queue-req: 0, 
[2025-09-30 14:27:09] Decode batch. #running-req: 1, #token: 2459, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.49, #queue-req: 0, 
[2025-09-30 14:27:09] Decode batch. #running-req: 1, #token: 2499, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.50, #queue-req: 0, 
[2025-09-30 14:27:09] Decode batch. #running-req: 1, #token: 2539, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.49, #queue-req: 0, 
[2025-09-30 14:27:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:10] Prefill batch. #new-seq: 1, #new-token: 880, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:10] Prefill batch. #new-seq: 1, #new-token: 451, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:10] Decode batch. #running-req: 1, #token: 632, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.71, #queue-req: 0, 
[2025-09-30 14:27:11] Decode batch. #running-req: 1, #token: 672, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.79, #queue-req: 0, 
[2025-09-30 14:27:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:11] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:11] Decode batch. #running-req: 1, #token: 276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:27:11] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:27:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:11] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:11] Prefill batch. #new-seq: 1, #new-token: 447, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:12] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.86, #queue-req: 0, 
[2025-09-30 14:27:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:12] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 517, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:12] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-09-30 14:27:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:13] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:13] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:13] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.92, #queue-req: 0, 
[2025-09-30 14:27:14] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.10, #queue-req: 0, 
[2025-09-30 14:27:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:14] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:14] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.58, #queue-req: 0, 
[2025-09-30 14:27:14] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:27:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:14] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:15] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:15] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.56, #queue-req: 0, 
[2025-09-30 14:27:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:16] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:16] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:16] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 34.55, #queue-req: 0, 
[2025-09-30 14:27:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:16] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:16] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.11, #queue-req: 0, 
[2025-09-30 14:27:16] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:27:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:17] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:17] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:17] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.18, #queue-req: 0, 
[2025-09-30 14:27:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:18] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:18] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:18] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 34.91, #queue-req: 0, 
[2025-09-30 14:27:18] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:18] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.65, #queue-req: 0, 
[2025-09-30 14:27:19] Decode batch. #running-req: 1, #token: 300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:27:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:19] Prefill batch. #new-seq: 1, #new-token: 390, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:19] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:19] Decode batch. #running-req: 1, #token: 448, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.97, #queue-req: 0, 
[2025-09-30 14:27:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:20] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:20] Decode batch. #running-req: 1, #token: 223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.64, #queue-req: 0, 
[2025-09-30 14:27:20] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.66, #queue-req: 0, 
[2025-09-30 14:27:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:21] Prefill batch. #new-seq: 1, #new-token: 571, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:21] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:21] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.63, #queue-req: 0, 
[2025-09-30 14:27:21] Decode batch. #running-req: 1, #token: 527, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.61, #queue-req: 0, 
[2025-09-30 14:27:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:22] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:22] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.58, #queue-req: 0, 
[2025-09-30 14:27:22] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:27:22] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:27:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:23] Prefill batch. #new-seq: 1, #new-token: 1930, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:23] Decode batch. #running-req: 1, #token: 2308, token usage: 0.04, cuda graph: True, gen throughput (token/s): 41.23, #queue-req: 0, 
[2025-09-30 14:27:24] Decode batch. #running-req: 1, #token: 2348, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:27:24] Decode batch. #running-req: 1, #token: 2388, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:27:24] Decode batch. #running-req: 1, #token: 2428, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.63, #queue-req: 0, 
[2025-09-30 14:27:25] Decode batch. #running-req: 1, #token: 2468, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.62, #queue-req: 0, 
[2025-09-30 14:27:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:25] Prefill batch. #new-seq: 1, #new-token: 1930, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:25] Decode batch. #running-req: 1, #token: 2273, token usage: 0.04, cuda graph: True, gen throughput (token/s): 95.98, #queue-req: 0, 
[2025-09-30 14:27:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:25] Prefill batch. #new-seq: 1, #new-token: 875, #cached-token: 292, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:25] Decode batch. #running-req: 1, #token: 1173, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.37, #queue-req: 0, 
[2025-09-30 14:27:26] Decode batch. #running-req: 1, #token: 1213, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:27:26] Decode batch. #running-req: 1, #token: 1253, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:27:26] Decode batch. #running-req: 1, #token: 1293, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 14:27:27] Decode batch. #running-req: 1, #token: 1333, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:27:27] Decode batch. #running-req: 1, #token: 1373, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 14:27:27] Decode batch. #running-req: 1, #token: 1413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:27:27] Decode batch. #running-req: 1, #token: 1453, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.01, #queue-req: 0, 
[2025-09-30 14:27:28] Decode batch. #running-req: 1, #token: 1493, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:27:28] Decode batch. #running-req: 1, #token: 1533, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:27:28] Decode batch. #running-req: 1, #token: 1573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.60, #queue-req: 0, 
[2025-09-30 14:27:29] Decode batch. #running-req: 1, #token: 1613, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:27:29] Decode batch. #running-req: 1, #token: 1653, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:27:29] Decode batch. #running-req: 1, #token: 1693, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:27:30] Decode batch. #running-req: 1, #token: 1733, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:27:30] Decode batch. #running-req: 1, #token: 1773, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:27:30] Decode batch. #running-req: 1, #token: 1813, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 14:27:31] Decode batch. #running-req: 1, #token: 1853, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:27:31] Decode batch. #running-req: 1, #token: 1893, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:27:31] Decode batch. #running-req: 1, #token: 1933, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:27:32] Decode batch. #running-req: 1, #token: 1973, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:27:32] Decode batch. #running-req: 1, #token: 2013, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.76, #queue-req: 0, 
[2025-09-30 14:27:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:32] Prefill batch. #new-seq: 1, #new-token: 515, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:32] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:33] Decode batch. #running-req: 1, #token: 400, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.73, #queue-req: 0, 
[2025-09-30 14:27:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:33] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:33] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.68, #queue-req: 0, 
[2025-09-30 14:27:33] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:27:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:34] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:34] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:34] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.39, #queue-req: 0, 
[2025-09-30 14:27:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:35] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:35] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:35] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.96, #queue-req: 0, 
[2025-09-30 14:27:35] Decode batch. #running-req: 1, #token: 533, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.48, #queue-req: 0, 
[2025-09-30 14:27:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:35] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:35] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.20, #queue-req: 0, 
[2025-09-30 14:27:36] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:27:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:36] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:36] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:36] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.89, #queue-req: 0, 
[2025-09-30 14:27:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:37] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:37] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:37] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.12, #queue-req: 0, 
[2025-09-30 14:27:38] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.48, #queue-req: 0, 
[2025-09-30 14:27:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:38] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.30, #queue-req: 0, 
[2025-09-30 14:27:38] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:38] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.45, #queue-req: 0, 
[2025-09-30 14:27:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:38] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:39] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:39] Decode batch. #running-req: 1, #token: 203, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.68, #queue-req: 0, 
[2025-09-30 14:27:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:39] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:39] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:40] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.99, #queue-req: 0, 
[2025-09-30 14:27:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:40] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:40] Decode batch. #running-req: 1, #token: 598, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.24, #queue-req: 0, 
[2025-09-30 14:27:41] Decode batch. #running-req: 1, #token: 638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.63, #queue-req: 0, 
[2025-09-30 14:27:41] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.45, #queue-req: 0, 
[2025-09-30 14:27:41] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.33, #queue-req: 0, 
[2025-09-30 14:27:42] Decode batch. #running-req: 1, #token: 758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.25, #queue-req: 0, 
[2025-09-30 14:27:42] Decode batch. #running-req: 1, #token: 798, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.85, #queue-req: 0, 
[2025-09-30 14:27:42] Decode batch. #running-req: 1, #token: 838, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.72, #queue-req: 0, 
[2025-09-30 14:27:43] Decode batch. #running-req: 1, #token: 878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.60, #queue-req: 0, 
[2025-09-30 14:27:43] Decode batch. #running-req: 1, #token: 918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.56, #queue-req: 0, 
[2025-09-30 14:27:43] Decode batch. #running-req: 1, #token: 958, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.51, #queue-req: 0, 
[2025-09-30 14:27:43] Decode batch. #running-req: 1, #token: 998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.47, #queue-req: 0, 
[2025-09-30 14:27:44] Decode batch. #running-req: 1, #token: 1038, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.32, #queue-req: 0, 
[2025-09-30 14:27:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:44] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:44] Decode batch. #running-req: 1, #token: 558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.24, #queue-req: 0, 
[2025-09-30 14:27:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:44] Prefill batch. #new-seq: 1, #new-token: 1297, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:44] Decode batch. #running-req: 1, #token: 1441, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.76, #queue-req: 0, 
[2025-09-30 14:27:45] Decode batch. #running-req: 1, #token: 1481, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:27:45] Decode batch. #running-req: 1, #token: 1521, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:27:45] Decode batch. #running-req: 1, #token: 1561, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.77, #queue-req: 0, 
[2025-09-30 14:27:46] Decode batch. #running-req: 1, #token: 1601, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:27:46] Decode batch. #running-req: 1, #token: 1641, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:27:46] Decode batch. #running-req: 1, #token: 1681, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 14:27:47] Decode batch. #running-req: 1, #token: 1721, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:27:47] Decode batch. #running-req: 1, #token: 1761, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:27:47] Decode batch. #running-req: 1, #token: 1801, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.34, #queue-req: 0, 
[2025-09-30 14:27:48] Decode batch. #running-req: 1, #token: 1841, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:27:48] Decode batch. #running-req: 1, #token: 1881, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:27:48] Decode batch. #running-req: 1, #token: 1921, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:27:48] Decode batch. #running-req: 1, #token: 1961, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:27:49] Decode batch. #running-req: 1, #token: 2001, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:27:49] Decode batch. #running-req: 1, #token: 2041, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:27:49] Decode batch. #running-req: 1, #token: 2081, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.36, #queue-req: 0, 
[2025-09-30 14:27:50] Decode batch. #running-req: 1, #token: 2121, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:27:50] Decode batch. #running-req: 1, #token: 2161, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.17, #queue-req: 0, 
[2025-09-30 14:27:50] Decode batch. #running-req: 1, #token: 2201, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:27:51] Decode batch. #running-req: 1, #token: 2241, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.17, #queue-req: 0, 
[2025-09-30 14:27:51] Decode batch. #running-req: 1, #token: 2281, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:27:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:52] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:52] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.75, #queue-req: 0, 
[2025-09-30 14:27:52] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:52] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.65, #queue-req: 0, 
[2025-09-30 14:27:53] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.91, #queue-req: 0, 
[2025-09-30 14:27:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:53] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:53] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:27:53] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:27:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:54] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:54] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.81, #queue-req: 0, 
[2025-09-30 14:27:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:54] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:55] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:55] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 32.67, #queue-req: 0, 
[2025-09-30 14:27:55] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:55] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:55] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 108.56, #queue-req: 0, 
[2025-09-30 14:27:55] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:27:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:56] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:56] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.28, #queue-req: 0, 
[2025-09-30 14:27:56] Prefill batch. #new-seq: 1, #new-token: 656, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:57] Prefill batch. #new-seq: 1, #new-token: 959, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:57] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:57] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.77, #queue-req: 0, 
[2025-09-30 14:27:57] Decode batch. #running-req: 1, #token: 522, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.77, #queue-req: 0, 
[2025-09-30 14:27:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:57] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:58] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.85, #queue-req: 0, 
[2025-09-30 14:27:58] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:27:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:58] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:58] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:58] Decode batch. #running-req: 1, #token: 389, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.09, #queue-req: 0, 
[2025-09-30 14:27:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:59] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:27:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 373, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:27:59] Decode batch. #running-req: 1, #token: 393, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.52, #queue-req: 0, 
[2025-09-30 14:27:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:00] Prefill batch. #new-seq: 1, #new-token: 814, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:00] Prefill batch. #new-seq: 1, #new-token: 516, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:00] Decode batch. #running-req: 1, #token: 711, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.69, #queue-req: 0, 
[2025-09-30 14:28:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:00] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:01] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 14:28:01] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:28:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:01] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:01] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:01] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 107.41, #queue-req: 0, 
[2025-09-30 14:28:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:02] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:02] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 583, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:02] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.94, #queue-req: 0, 
[2025-09-30 14:28:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:03] Prefill batch. #new-seq: 1, #new-token: 1055, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:03] Prefill batch. #new-seq: 1, #new-token: 545, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:03] Decode batch. #running-req: 1, #token: 735, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.80, #queue-req: 0, 
[2025-09-30 14:28:03] Decode batch. #running-req: 1, #token: 775, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.45, #queue-req: 0, 
[2025-09-30 14:28:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:04] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:04] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.35, #queue-req: 0, 
[2025-09-30 14:28:04] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:28:04] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:28:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:05] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:05] Prefill batch. #new-seq: 1, #new-token: 541, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:05] Decode batch. #running-req: 1, #token: 622, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.15, #queue-req: 0, 
[2025-09-30 14:28:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:06] Prefill batch. #new-seq: 1, #new-token: 947, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:06] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:06] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.45, #queue-req: 0, 
[2025-09-30 14:28:06] Decode batch. #running-req: 1, #token: 635, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.88, #queue-req: 0, 
[2025-09-30 14:28:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:06] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:07] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:28:07] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:28:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:07] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:07] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:08] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.90, #queue-req: 0, 
[2025-09-30 14:28:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:08] Prefill batch. #new-seq: 1, #new-token: 817, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:08] Prefill batch. #new-seq: 1, #new-token: 415, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:09] Decode batch. #running-req: 1, #token: 611, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.09, #queue-req: 0, 
[2025-09-30 14:28:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:09] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:09] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.38, #queue-req: 0, 
[2025-09-30 14:28:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:09] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:09] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.51, #queue-req: 0, 
[2025-09-30 14:28:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:09] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:10] Prefill batch. #new-seq: 1, #new-token: 1107, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:10] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:11] Decode batch. #running-req: 1, #token: 874, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.87, #queue-req: 0, 
[2025-09-30 14:28:11] Decode batch. #running-req: 1, #token: 914, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:28:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:11] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:11] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.05, #queue-req: 0, 
[2025-09-30 14:28:11] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:28:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:12] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:12] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.88, #queue-req: 0, 
[2025-09-30 14:28:12] Prefill batch. #new-seq: 1, #new-token: 692, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:13] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:13] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.90, #queue-req: 0, 
[2025-09-30 14:28:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:13] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 766, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:14] Prefill batch. #new-seq: 1, #new-token: 1553, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:14] Decode batch. #running-req: 1, #token: 1907, token usage: 0.03, cuda graph: True, gen throughput (token/s): 40.97, #queue-req: 0, 
[2025-09-30 14:28:14] Decode batch. #running-req: 1, #token: 1947, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:28:14] Decode batch. #running-req: 1, #token: 1987, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:28:15] Decode batch. #running-req: 1, #token: 2027, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:28:15] Decode batch. #running-req: 1, #token: 2067, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.59, #queue-req: 0, 
[2025-09-30 14:28:15] Decode batch. #running-req: 1, #token: 2107, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:28:16] Decode batch. #running-req: 1, #token: 2147, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:28:16] Decode batch. #running-req: 1, #token: 2187, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:28:16] Decode batch. #running-req: 1, #token: 2227, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:28:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:16] Prefill batch. #new-seq: 1, #new-token: 1553, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:17] Decode batch. #running-req: 1, #token: 1899, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.70, #queue-req: 0, 
[2025-09-30 14:28:17] Decode batch. #running-req: 1, #token: 1939, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.91, #queue-req: 0, 
[2025-09-30 14:28:17] Decode batch. #running-req: 1, #token: 1979, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:28:18] Decode batch. #running-req: 1, #token: 2019, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:28:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:18] Prefill batch. #new-seq: 1, #new-token: 1214, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:18] Decode batch. #running-req: 1, #token: 1359, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.07, #queue-req: 0, 
[2025-09-30 14:28:18] Decode batch. #running-req: 1, #token: 1399, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.16, #queue-req: 0, 
[2025-09-30 14:28:19] Decode batch. #running-req: 1, #token: 1439, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:28:19] Decode batch. #running-req: 1, #token: 1479, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:28:19] Decode batch. #running-req: 1, #token: 1519, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:28:20] Decode batch. #running-req: 1, #token: 1559, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.83, #queue-req: 0, 
[2025-09-30 14:28:20] Decode batch. #running-req: 1, #token: 1599, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:28:20] Decode batch. #running-req: 1, #token: 1639, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:28:20] Decode batch. #running-req: 1, #token: 1679, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:28:21] Decode batch. #running-req: 1, #token: 1719, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:28:21] Decode batch. #running-req: 1, #token: 1759, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:28:21] Decode batch. #running-req: 1, #token: 1799, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.36, #queue-req: 0, 
[2025-09-30 14:28:22] Decode batch. #running-req: 1, #token: 1839, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.94, #queue-req: 0, 
[2025-09-30 14:28:22] Decode batch. #running-req: 1, #token: 1879, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.93, #queue-req: 0, 
[2025-09-30 14:28:22] Decode batch. #running-req: 1, #token: 1919, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:28:23] Decode batch. #running-req: 1, #token: 1959, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:28:23] Decode batch. #running-req: 1, #token: 1999, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:28:23] Decode batch. #running-req: 1, #token: 2039, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.70, #queue-req: 0, 
[2025-09-30 14:28:24] Decode batch. #running-req: 1, #token: 2079, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.44, #queue-req: 0, 
[2025-09-30 14:28:24] Decode batch. #running-req: 1, #token: 2119, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:28:24] Decode batch. #running-req: 1, #token: 2159, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:28:25] Decode batch. #running-req: 1, #token: 2199, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:28:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:25] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 127.12, #queue-req: 0, 
[2025-09-30 14:28:25] Prefill batch. #new-seq: 1, #new-token: 1280, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:26] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:26] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:26] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 36.85, #queue-req: 0, 
[2025-09-30 14:28:26] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:28:27] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:28:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:27] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:27] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:28] Prefill batch. #new-seq: 1, #new-token: 1286, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:28] Prefill batch. #new-seq: 1, #new-token: 702, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:28] Decode batch. #running-req: 1, #token: 881, token usage: 0.01, cuda graph: True, gen throughput (token/s): 29.18, #queue-req: 0, 
[2025-09-30 14:28:28] Decode batch. #running-req: 1, #token: 921, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.81, #queue-req: 0, 
[2025-09-30 14:28:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:28] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:29] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.82, #queue-req: 0, 
[2025-09-30 14:28:29] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:28:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:29] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:29] Prefill batch. #new-seq: 1, #new-token: 698, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:29] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 98.94, #queue-req: 0, 
[2025-09-30 14:28:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:30] Prefill batch. #new-seq: 1, #new-token: 1353, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:30] Prefill batch. #new-seq: 1, #new-token: 658, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:30] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:31] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 30.51, #queue-req: 0, 
[2025-09-30 14:28:31] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:28:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:31] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:31] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.13, #queue-req: 0, 
[2025-09-30 14:28:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:31] Prefill batch. #new-seq: 1, #new-token: 654, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:32] Prefill batch. #new-seq: 1, #new-token: 1283, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:32] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:33] Decode batch. #running-req: 1, #token: 802, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.26, #queue-req: 0, 
[2025-09-30 14:28:33] Decode batch. #running-req: 1, #token: 842, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.94, #queue-req: 0, 
[2025-09-30 14:28:33] Decode batch. #running-req: 1, #token: 882, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:28:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:33] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:33] Decode batch. #running-req: 1, #token: 306, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.23, #queue-req: 0, 
[2025-09-30 14:28:34] Decode batch. #running-req: 1, #token: 346, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:28:34] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.03, #queue-req: 0, 
[2025-09-30 14:28:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:35] Prefill batch. #new-seq: 1, #new-token: 629, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:35] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.82, #queue-req: 0, 
[2025-09-30 14:28:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:35] Prefill batch. #new-seq: 1, #new-token: 799, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:35] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:36] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.16, #queue-req: 0, 
[2025-09-30 14:28:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:36] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:36] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.68, #queue-req: 0, 
[2025-09-30 14:28:36] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:28:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:37] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:37] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:37] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 59.97, #queue-req: 0, 
[2025-09-30 14:28:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:38] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:38] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:38] Prefill batch. #new-seq: 1, #new-token: 2664, #cached-token: 0, token usage: 0.06, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:38] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:38] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 27.46, #queue-req: 0, 
[2025-09-30 14:28:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:39] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:39] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.65, #queue-req: 0, 
[2025-09-30 14:28:39] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:28:39] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:28:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:39] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:40] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.07, #queue-req: 0, 
[2025-09-30 14:28:40] Prefill batch. #new-seq: 1, #new-token: 632, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:40] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:40] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.13, #queue-req: 0, 
[2025-09-30 14:28:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:40] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:40] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.33, #queue-req: 0, 
[2025-09-30 14:28:41] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:28:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:41] Prefill batch. #new-seq: 1, #new-token: 393, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:41] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:41] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.43, #queue-req: 0, 
[2025-09-30 14:28:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:41] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:41] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.43, #queue-req: 0, 
[2025-09-30 14:28:42] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:28:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:42] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:42] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 108.49, #queue-req: 0, 
[2025-09-30 14:28:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:42] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:42] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:42] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:43] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.68, #queue-req: 0, 
[2025-09-30 14:28:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:43] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:43] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.32, #queue-req: 0, 
[2025-09-30 14:28:43] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:28:43] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:28:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:44] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:44] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:44] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.36, #queue-req: 0, 
[2025-09-30 14:28:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:44] Prefill batch. #new-seq: 1, #new-token: 1466, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:44] Decode batch. #running-req: 1, #token: 1832, token usage: 0.03, cuda graph: True, gen throughput (token/s): 94.53, #queue-req: 0, 
[2025-09-30 14:28:45] Decode batch. #running-req: 1, #token: 1872, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:28:45] Decode batch. #running-req: 1, #token: 1912, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.77, #queue-req: 0, 
[2025-09-30 14:28:45] Decode batch. #running-req: 1, #token: 1952, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:28:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:45] Prefill batch. #new-seq: 1, #new-token: 1466, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:46] Decode batch. #running-req: 1, #token: 1810, token usage: 0.03, cuda graph: True, gen throughput (token/s): 102.07, #queue-req: 0, 
[2025-09-30 14:28:46] Decode batch. #running-req: 1, #token: 1850, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:28:46] Decode batch. #running-req: 1, #token: 1890, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.91, #queue-req: 0, 
[2025-09-30 14:28:47] Decode batch. #running-req: 1, #token: 1930, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.91, #queue-req: 0, 
[2025-09-30 14:28:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:47] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:47] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:47] Decode batch. #running-req: 1, #token: 365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.63, #queue-req: 0, 
[2025-09-30 14:28:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:47] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:47] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.40, #queue-req: 0, 
[2025-09-30 14:28:48] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:28:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:48] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:48] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:48] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.13, #queue-req: 0, 
[2025-09-30 14:28:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:48] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:48] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:48] Decode batch. #running-req: 1, #token: 395, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.48, #queue-req: 0, 
[2025-09-30 14:28:49] Decode batch. #running-req: 1, #token: 435, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.05, #queue-req: 0, 
[2025-09-30 14:28:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:49] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:49] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:28:49] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:28:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:50] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:50] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.91, #queue-req: 0, 
[2025-09-30 14:28:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:50] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:50] Prefill batch. #new-seq: 1, #new-token: 865, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:50] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.70, #queue-req: 0, 
[2025-09-30 14:28:50] Prefill batch. #new-seq: 1, #new-token: 676, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:50] Decode batch. #running-req: 1, #token: 878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.74, #queue-req: 0, 
[2025-09-30 14:28:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:51] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:51] Decode batch. #running-req: 1, #token: 420, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.13, #queue-req: 0, 
[2025-09-30 14:28:51] Decode batch. #running-req: 1, #token: 460, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.83, #queue-req: 0, 
[2025-09-30 14:28:51] Decode batch. #running-req: 1, #token: 500, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.59, #queue-req: 0, 
[2025-09-30 14:28:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:51] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:52] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:52] Decode batch. #running-req: 1, #token: 756, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.13, #queue-req: 0, 
[2025-09-30 14:28:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:52] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:52] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 740, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:52] Decode batch. #running-req: 1, #token: 765, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.39, #queue-req: 0, 
[2025-09-30 14:28:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:52] Prefill batch. #new-seq: 1, #new-token: 1262, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:52] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:53] Decode batch. #running-req: 1, #token: 790, token usage: 0.01, cuda graph: True, gen throughput (token/s): 93.45, #queue-req: 0, 
[2025-09-30 14:28:53] Decode batch. #running-req: 1, #token: 830, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:28:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:53] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:53] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.41, #queue-req: 0, 
[2025-09-30 14:28:53] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:28:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:54] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:54] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:54] Decode batch. #running-req: 1, #token: 664, token usage: 0.01, cuda graph: True, gen throughput (token/s): 92.98, #queue-req: 0, 
[2025-09-30 14:28:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:54] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:54] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:55] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.07, #queue-req: 0, 
[2025-09-30 14:28:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:55] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.51, #queue-req: 0, 
[2025-09-30 14:28:55] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:55] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.27, #queue-req: 0, 
[2025-09-30 14:28:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:56] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:56] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.94, #queue-req: 0, 
[2025-09-30 14:28:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:56] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:56] Prefill batch. #new-seq: 1, #new-token: 784, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:56] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:56] Decode batch. #running-req: 1, #token: 869, token usage: 0.01, cuda graph: True, gen throughput (token/s): 85.20, #queue-req: 0, 
[2025-09-30 14:28:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:56] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:56] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.14, #queue-req: 0, 
[2025-09-30 14:28:57] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:28:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:57] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:57] Prefill batch. #new-seq: 1, #new-token: 692, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:57] Decode batch. #running-req: 1, #token: 781, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.64, #queue-req: 0, 
[2025-09-30 14:28:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:57] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:57] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 764, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:58] Decode batch. #running-req: 1, #token: 791, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.86, #queue-req: 0, 
[2025-09-30 14:28:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:58] Prefill batch. #new-seq: 1, #new-token: 1137, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:58] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:58] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:58] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 91.61, #queue-req: 0, 
[2025-09-30 14:28:58] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:28:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:59] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:59] Prefill batch. #new-seq: 1, #new-token: 444, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:59] Decode batch. #running-req: 1, #token: 519, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.64, #queue-req: 0, 
[2025-09-30 14:28:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:59] Prefill batch. #new-seq: 1, #new-token: 945, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:28:59] Prefill batch. #new-seq: 1, #new-token: 503, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:28:59] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.84, #queue-req: 0, 
[2025-09-30 14:28:59] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:29:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:00] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:00] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.06, #queue-req: 0, 
[2025-09-30 14:29:00] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:29:00] Decode batch. #running-req: 1, #token: 384, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.08, #queue-req: 0, 
[2025-09-30 14:29:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:01] Prefill batch. #new-seq: 1, #new-token: 909, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:01] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:01] Decode batch. #running-req: 1, #token: 593, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.56, #queue-req: 0, 
[2025-09-30 14:29:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:01] Prefill batch. #new-seq: 1, #new-token: 59, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:01] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.88, #queue-req: 0, 
[2025-09-30 14:29:01] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:29:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:02] Prefill batch. #new-seq: 1, #new-token: 1138, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:02] Prefill batch. #new-seq: 1, #new-token: 732, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:02] Decode batch. #running-req: 1, #token: 903, token usage: 0.01, cuda graph: True, gen throughput (token/s): 89.41, #queue-req: 0, 
[2025-09-30 14:29:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:02] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:02] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.88, #queue-req: 0, 
[2025-09-30 14:29:03] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:29:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:03] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:03] Prefill batch. #new-seq: 1, #new-token: 728, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:03] Decode batch. #running-req: 1, #token: 806, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.35, #queue-req: 0, 
[2025-09-30 14:29:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:03] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:03] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 106.10, #queue-req: 0, 
[2025-09-30 14:29:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 802, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:04] Prefill batch. #new-seq: 1, #new-token: 1228, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:04] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:04] Decode batch. #running-req: 1, #token: 678, token usage: 0.01, cuda graph: True, gen throughput (token/s): 86.15, #queue-req: 0, 
[2025-09-30 14:29:04] Decode batch. #running-req: 1, #token: 718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:29:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:04] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:04] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:29:05] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:29:05] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.11, #queue-req: 0, 
[2025-09-30 14:29:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:05] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:05] Prefill batch. #new-seq: 1, #new-token: 803, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:05] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:05] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:06] Decode batch. #running-req: 1, #token: 4603, token usage: 0.07, cuda graph: True, gen throughput (token/s): 43.42, #queue-req: 0, 
[2025-09-30 14:29:06] Decode batch. #running-req: 1, #token: 4643, token usage: 0.07, cuda graph: True, gen throughput (token/s): 120.74, #queue-req: 0, 
[2025-09-30 14:29:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:06] Prefill batch. #new-seq: 1, #new-token: 3860, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:07] Decode batch. #running-req: 1, #token: 4069, token usage: 0.06, cuda graph: True, gen throughput (token/s): 75.24, #queue-req: 0, 
[2025-09-30 14:29:07] Decode batch. #running-req: 1, #token: 4109, token usage: 0.06, cuda graph: True, gen throughput (token/s): 122.70, #queue-req: 0, 
[2025-09-30 14:29:07] Decode batch. #running-req: 1, #token: 4149, token usage: 0.06, cuda graph: True, gen throughput (token/s): 122.37, #queue-req: 0, 
[2025-09-30 14:29:08] Decode batch. #running-req: 1, #token: 4189, token usage: 0.07, cuda graph: True, gen throughput (token/s): 122.37, #queue-req: 0, 
[2025-09-30 14:29:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:08] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:08] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:08] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:08] Decode batch. #running-req: 1, #token: 4489, token usage: 0.07, cuda graph: True, gen throughput (token/s): 64.16, #queue-req: 0, 
[2025-09-30 14:29:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:09] Prefill batch. #new-seq: 1, #new-token: 4096, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:09] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 0, token usage: 0.07, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:09] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:09] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.40, #queue-req: 0, 
[2025-09-30 14:29:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:09] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:09] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.96, #queue-req: 0, 
[2025-09-30 14:29:10] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:29:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:10] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:10] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:10] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:10] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:10] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.95, #queue-req: 0, 
[2025-09-30 14:29:11] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.22, #queue-req: 0, 
[2025-09-30 14:29:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:11] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:11] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.89, #queue-req: 0, 
[2025-09-30 14:29:11] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.65, #queue-req: 0, 
[2025-09-30 14:29:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:11] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:11] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:12] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.90, #queue-req: 0, 
[2025-09-30 14:29:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:12] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:12] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:12] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 82.11, #queue-req: 0, 
[2025-09-30 14:29:12] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.51, #queue-req: 0, 
[2025-09-30 14:29:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:13] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:13] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.37, #queue-req: 0, 
[2025-09-30 14:29:13] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:29:13] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:29:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:13] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:13] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:14] Decode batch. #running-req: 1, #token: 195, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.14, #queue-req: 0, 
[2025-09-30 14:29:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:14] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:14] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:14] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:14] Prefill batch. #new-seq: 1, #new-token: 506, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:14] Decode batch. #running-req: 1, #token: 660, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.84, #queue-req: 0, 
[2025-09-30 14:29:15] Decode batch. #running-req: 1, #token: 700, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.63, #queue-req: 0, 
[2025-09-30 14:29:15] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:29:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:15] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:15] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 14:29:15] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:29:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:16] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:16] Prefill batch. #new-seq: 1, #new-token: 402, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:16] Decode batch. #running-req: 1, #token: 488, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.91, #queue-req: 0, 
[2025-09-30 14:29:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:16] Prefill batch. #new-seq: 1, #new-token: 1009, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:16] Prefill batch. #new-seq: 1, #new-token: 609, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:16] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.78, #queue-req: 0, 
[2025-09-30 14:29:17] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:29:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:17] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:17] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.69, #queue-req: 0, 
[2025-09-30 14:29:17] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:29:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:18] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:18] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:18] Decode batch. #running-req: 1, #token: 682, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.54, #queue-req: 0, 
[2025-09-30 14:29:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:18] Prefill batch. #new-seq: 1, #new-token: 854, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:18] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:18] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.62, #queue-req: 0, 
[2025-09-30 14:29:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:18] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:19] Decode batch. #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:29:19] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0, 
[2025-09-30 14:29:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:19] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:19] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.35, #queue-req: 0, 
[2025-09-30 14:29:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:20] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:20] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:20] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 76.32, #queue-req: 0, 
[2025-09-30 14:29:20] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.46, #queue-req: 0, 
[2025-09-30 14:29:20] Decode batch. #running-req: 1, #token: 378, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0, 
[2025-09-30 14:29:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:20] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:21] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.17, #queue-req: 0, 
[2025-09-30 14:29:21] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:29:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:21] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:21] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:22] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:22] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:22] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.71, #queue-req: 0, 
[2025-09-30 14:29:22] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.46, #queue-req: 0, 
[2025-09-30 14:29:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:22] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:22] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.03, #queue-req: 0, 
[2025-09-30 14:29:23] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:29:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:23] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:23] Decode batch. #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.54, #queue-req: 0, 
[2025-09-30 14:29:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:23] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:23] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:23] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.35, #queue-req: 0, 
[2025-09-30 14:29:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:23] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:24] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:24] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:24] Decode batch. #running-req: 1, #token: 404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.44, #queue-req: 0, 
[2025-09-30 14:29:24] Decode batch. #running-req: 1, #token: 444, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.20, #queue-req: 0, 
[2025-09-30 14:29:24] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.07, #queue-req: 0, 
[2025-09-30 14:29:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:25] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:25] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 14:29:25] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:29:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:25] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:26] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:26] Decode batch. #running-req: 1, #token: 395, token usage: 0.01, cuda graph: True, gen throughput (token/s): 76.49, #queue-req: 0, 
[2025-09-30 14:29:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:26] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:26] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.62, #queue-req: 0, 
[2025-09-30 14:29:26] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:29:27] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:29:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:27] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:27] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:27] Decode batch. #running-req: 1, #token: 313, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.08, #queue-req: 0, 
[2025-09-30 14:29:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:27] Prefill batch. #new-seq: 1, #new-token: 459, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:27] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:27] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.04, #queue-req: 0, 
[2025-09-30 14:29:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:28] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:28] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.48, #queue-req: 0, 
[2025-09-30 14:29:28] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:29:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:28] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:28] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.68, #queue-req: 0, 
[2025-09-30 14:29:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:28] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:29] Prefill batch. #new-seq: 1, #new-token: 532, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:29] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 179, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:29] Decode batch. #running-req: 1, #token: 481, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.30, #queue-req: 0, 
[2025-09-30 14:29:29] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.67, #queue-req: 0, 
[2025-09-30 14:29:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:29] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:30] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.34, #queue-req: 0, 
[2025-09-30 14:29:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:30] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 94, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:30] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.35, #queue-req: 0, 
[2025-09-30 14:29:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:30] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:30] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 122.63, #queue-req: 0, 
[2025-09-30 14:29:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:30] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:31] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:29:31] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:29:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:31] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:31] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.63, #queue-req: 0, 
[2025-09-30 14:29:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:31] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:32] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:32] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:32] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.76, #queue-req: 0, 
[2025-09-30 14:29:32] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.00, #queue-req: 0, 
[2025-09-30 14:29:32] Decode batch. #running-req: 1, #token: 527, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.63, #queue-req: 0, 
[2025-09-30 14:29:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:32] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:33] Decode batch. #running-req: 1, #token: 346, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.81, #queue-req: 0, 
[2025-09-30 14:29:33] Decode batch. #running-req: 1, #token: 386, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:29:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:33] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:33] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:33] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.45, #queue-req: 0, 
[2025-09-30 14:29:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:34] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:34] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.76, #queue-req: 0, 
[2025-09-30 14:29:34] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.87, #queue-req: 0, 
[2025-09-30 14:29:34] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.70, #queue-req: 0, 
[2025-09-30 14:29:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:34] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:34] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:35] Prefill batch. #new-seq: 1, #new-token: 537, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:35] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:35] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.79, #queue-req: 0, 
[2025-09-30 14:29:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:35] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:35] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:29:35] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:29:36] Decode batch. #running-req: 1, #token: 360, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:29:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:36] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:36] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:36] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 116.31, #queue-req: 0, 
[2025-09-30 14:29:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:36] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:36] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.26, #queue-req: 0, 
[2025-09-30 14:29:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:37] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:37] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.33, #queue-req: 0, 
[2025-09-30 14:29:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:37] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:37] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:37] Decode batch. #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 90.17, #queue-req: 0, 
[2025-09-30 14:29:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:37] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 235, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:38] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.30, #queue-req: 0, 
[2025-09-30 14:29:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:38] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:38] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:38] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.12, #queue-req: 0, 
[2025-09-30 14:29:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:38] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:38] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.12, #queue-req: 0, 
[2025-09-30 14:29:39] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:29:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:39] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:39] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 116.87, #queue-req: 0, 
[2025-09-30 14:29:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:39] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:39] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:39] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:39] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 80.34, #queue-req: 0, 
[2025-09-30 14:29:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:40] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:40] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:29:40] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:29:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:40] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:29:40] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:41] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:41] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:41] Decode batch. #running-req: 1, #token: 329, token usage: 0.01, cuda graph: True, gen throughput (token/s): 78.30, #queue-req: 0, 
[2025-09-30 14:29:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:41] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:41] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:29:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:41] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:42] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.44, #queue-req: 0, 
[2025-09-30 14:29:42] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:42] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:42] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:42] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 87.64, #queue-req: 0, 
[2025-09-30 14:29:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:42] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:42] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 14:29:43] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:29:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:43] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:43] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.36, #queue-req: 0, 
[2025-09-30 14:29:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:43] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:43] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:43] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:43] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.79, #queue-req: 0, 
[2025-09-30 14:29:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:44] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:44] Decode batch. #running-req: 1, #token: 235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:29:44] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:29:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:44] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:45] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:45] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 87.89, #queue-req: 0, 
[2025-09-30 14:29:45] Decode batch. #running-req: 1, #token: 380, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.33, #queue-req: 0, 
[2025-09-30 14:29:45] Decode batch. #running-req: 1, #token: 420, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.27, #queue-req: 0, 
[2025-09-30 14:29:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:45] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:45] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.27, #queue-req: 0, 
[2025-09-30 14:29:46] Decode batch. #running-req: 1, #token: 301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:29:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:46] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:46] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:46] Decode batch. #running-req: 1, #token: 217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 99.52, #queue-req: 0, 
[2025-09-30 14:29:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:46] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:46] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:47] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 91.90, #queue-req: 0, 
[2025-09-30 14:29:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:47] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:47] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.25, #queue-req: 0, 
[2025-09-30 14:29:47] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:29:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:48] Prefill batch. #new-seq: 1, #new-token: 902, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:48] Prefill batch. #new-seq: 1, #new-token: 706, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:48] Decode batch. #running-req: 1, #token: 877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.81, #queue-req: 0, 
[2025-09-30 14:29:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:48] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:48] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.74, #queue-req: 0, 
[2025-09-30 14:29:48] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:29:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:49] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:29:49] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:49] Prefill batch. #new-seq: 1, #new-token: 702, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:49] Prefill batch. #new-seq: 1, #new-token: 1356, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:49] Prefill batch. #new-seq: 1, #new-token: 657, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:49] Decode batch. #running-req: 1, #token: 827, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.26, #queue-req: 0, 
[2025-09-30 14:29:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:49] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:50] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.75, #queue-req: 0, 
[2025-09-30 14:29:50] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:29:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:50] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:50] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:50] Decode batch. #running-req: 1, #token: 730, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.63, #queue-req: 0, 
[2025-09-30 14:29:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:51] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 724, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:51] Decode batch. #running-req: 1, #token: 740, token usage: 0.01, cuda graph: True, gen throughput (token/s): 90.07, #queue-req: 0, 
[2025-09-30 14:29:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:51] Prefill batch. #new-seq: 1, #new-token: 1269, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:51] Prefill batch. #new-seq: 1, #new-token: 619, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:51] Decode batch. #running-req: 1, #token: 808, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.70, #queue-req: 0, 
[2025-09-30 14:29:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:51] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:52] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.25, #queue-req: 0, 
[2025-09-30 14:29:52] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:29:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:52] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:52] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:52] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 93.90, #queue-req: 0, 
[2025-09-30 14:29:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:52] Prefill batch. #new-seq: 1, #new-token: 1954, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:53] Decode batch. #running-req: 1, #token: 2022, token usage: 0.03, cuda graph: True, gen throughput (token/s): 76.79, #queue-req: 0, 
[2025-09-30 14:29:53] Decode batch. #running-req: 1, #token: 2062, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.52, #queue-req: 0, 
[2025-09-30 14:29:54] Decode batch. #running-req: 1, #token: 2102, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:29:54] Decode batch. #running-req: 1, #token: 2142, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:29:54] Decode batch. #running-req: 1, #token: 2182, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.08, #queue-req: 0, 
[2025-09-30 14:29:54] Decode batch. #running-req: 1, #token: 2222, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.11, #queue-req: 0, 
[2025-09-30 14:29:55] Decode batch. #running-req: 1, #token: 2262, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 14:29:55] Decode batch. #running-req: 1, #token: 2302, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.08, #queue-req: 0, 
[2025-09-30 14:29:55] Decode batch. #running-req: 1, #token: 2342, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:29:56] Decode batch. #running-req: 1, #token: 2382, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:29:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:29:56] Prefill batch. #new-seq: 1, #new-token: 1934, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:29:56] Decode batch. #running-req: 1, #token: 1965, token usage: 0.03, cuda graph: True, gen throughput (token/s): 96.37, #queue-req: 0, 
[2025-09-30 14:29:56] Decode batch. #running-req: 1, #token: 2005, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:29:57] Decode batch. #running-req: 1, #token: 2045, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:29:57] Decode batch. #running-req: 1, #token: 2085, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.36, #queue-req: 0, 
[2025-09-30 14:29:57] Decode batch. #running-req: 1, #token: 2125, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:29:58] Decode batch. #running-req: 1, #token: 2165, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:29:58] Decode batch. #running-req: 1, #token: 2205, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:29:58] Decode batch. #running-req: 1, #token: 2245, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:29:59] Decode batch. #running-req: 1, #token: 2285, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:29:59] Decode batch. #running-req: 1, #token: 2325, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.95, #queue-req: 0, 
[2025-09-30 14:29:59] Decode batch. #running-req: 1, #token: 2365, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.70, #queue-req: 0, 
[2025-09-30 14:30:00] Decode batch. #running-req: 1, #token: 2405, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:30:00] Decode batch. #running-req: 1, #token: 2445, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:30:00] Decode batch. #running-req: 1, #token: 2485, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:30:01] Decode batch. #running-req: 1, #token: 2525, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:30:01] Decode batch. #running-req: 1, #token: 2565, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.53, #queue-req: 0, 
[2025-09-30 14:30:01] Decode batch. #running-req: 1, #token: 2605, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:30:01] Decode batch. #running-req: 1, #token: 2645, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:30:02] Decode batch. #running-req: 1, #token: 2685, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:30:02] Decode batch. #running-req: 1, #token: 2725, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:30:02] Decode batch. #running-req: 1, #token: 2765, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:30:03] Decode batch. #running-req: 1, #token: 2805, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:30:03] Decode batch. #running-req: 1, #token: 2845, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.60, #queue-req: 0, 
[2025-09-30 14:30:03] Decode batch. #running-req: 1, #token: 2885, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.44, #queue-req: 0, 
[2025-09-30 14:30:04] Decode batch. #running-req: 1, #token: 2925, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:30:04] Decode batch. #running-req: 1, #token: 2965, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:30:04] Decode batch. #running-req: 1, #token: 3005, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:30:05] Decode batch. #running-req: 1, #token: 3045, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:30:05] Decode batch. #running-req: 1, #token: 3085, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.20, #queue-req: 0, 
[2025-09-30 14:30:05] Decode batch. #running-req: 1, #token: 3125, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 14:30:06] Decode batch. #running-req: 1, #token: 3165, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:30:06] Decode batch. #running-req: 1, #token: 3205, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:30:06] Decode batch. #running-req: 1, #token: 3245, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:30:07] Decode batch. #running-req: 1, #token: 3285, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:30:07] Decode batch. #running-req: 1, #token: 3325, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 14:30:07] Decode batch. #running-req: 1, #token: 3365, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.28, #queue-req: 0, 
[2025-09-30 14:30:08] Decode batch. #running-req: 1, #token: 3405, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:30:08] Decode batch. #running-req: 1, #token: 3445, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:30:08] Decode batch. #running-req: 1, #token: 3485, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:30:09] Decode batch. #running-req: 1, #token: 3525, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.16, #queue-req: 0, 
[2025-09-30 14:30:09] Decode batch. #running-req: 1, #token: 3565, token usage: 0.06, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:30:09] Decode batch. #running-req: 1, #token: 3605, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.87, #queue-req: 0, 
[2025-09-30 14:30:09] Decode batch. #running-req: 1, #token: 3645, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.63, #queue-req: 0, 
[2025-09-30 14:30:10] Decode batch. #running-req: 1, #token: 3685, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.59, #queue-req: 0, 
[2025-09-30 14:30:10] Decode batch. #running-req: 1, #token: 3725, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:30:10] Decode batch. #running-req: 1, #token: 3765, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.56, #queue-req: 0, 
[2025-09-30 14:30:11] Decode batch. #running-req: 1, #token: 3805, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.56, #queue-req: 0, 
[2025-09-30 14:30:11] Decode batch. #running-req: 1, #token: 3845, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.49, #queue-req: 0, 
[2025-09-30 14:30:11] Decode batch. #running-req: 1, #token: 3885, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.03, #queue-req: 0, 
[2025-09-30 14:30:12] Decode batch. #running-req: 1, #token: 3925, token usage: 0.06, cuda graph: True, gen throughput (token/s): 123.00, #queue-req: 0, 
[2025-09-30 14:30:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:12] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:12] Decode batch. #running-req: 1, #token: 629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 110.00, #queue-req: 0, 
[2025-09-30 14:30:12] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.43, #queue-req: 0, 
[2025-09-30 14:30:13] Decode batch. #running-req: 1, #token: 709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.29, #queue-req: 0, 
[2025-09-30 14:30:13] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:30:13] Decode batch. #running-req: 1, #token: 789, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.88, #queue-req: 0, 
[2025-09-30 14:30:14] Decode batch. #running-req: 1, #token: 829, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.62, #queue-req: 0, 
[2025-09-30 14:30:14] Decode batch. #running-req: 1, #token: 869, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.50, #queue-req: 0, 
[2025-09-30 14:30:14] Decode batch. #running-req: 1, #token: 909, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.52, #queue-req: 0, 
[2025-09-30 14:30:15] Decode batch. #running-req: 1, #token: 949, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.42, #queue-req: 0, 
[2025-09-30 14:30:15] Decode batch. #running-req: 1, #token: 989, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.38, #queue-req: 0, 
[2025-09-30 14:30:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:15] Prefill batch. #new-seq: 1, #new-token: 1213, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:15] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:15] Decode batch. #running-req: 1, #token: 786, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.54, #queue-req: 0, 
[2025-09-30 14:30:16] Decode batch. #running-req: 1, #token: 826, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.95, #queue-req: 0, 
[2025-09-30 14:30:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:16] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:16] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 14:30:16] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:30:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:16] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:17] Prefill batch. #new-seq: 1, #new-token: 596, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:17] Decode batch. #running-req: 1, #token: 689, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.72, #queue-req: 0, 
[2025-09-30 14:30:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:17] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 668, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:17] Prefill batch. #new-seq: 1, #new-token: 1363, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:18] Prefill batch. #new-seq: 1, #new-token: 750, #cached-token: 182, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:18] Decode batch. #running-req: 1, #token: 936, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.67, #queue-req: 0, 
[2025-09-30 14:30:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:18] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 215, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:18] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.39, #queue-req: 0, 
[2025-09-30 14:30:18] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:30:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:19] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.12, #queue-req: 0, 
[2025-09-30 14:30:19] Prefill batch. #new-seq: 1, #new-token: 1489, #cached-token: 97, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:19] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 237, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 272, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:19] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.90, #queue-req: 0, 
[2025-09-30 14:30:19] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:30:20] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:30:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:20] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:20] Prefill batch. #new-seq: 1, #new-token: 722, #cached-token: 92, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:20] Decode batch. #running-req: 1, #token: 826, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.93, #queue-req: 0, 
[2025-09-30 14:30:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:20] Prefill batch. #new-seq: 1, #new-token: 1316, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:21] Prefill batch. #new-seq: 1, #new-token: 651, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:21] Decode batch. #running-req: 1, #token: 841, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.15, #queue-req: 0, 
[2025-09-30 14:30:21] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:30:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:21] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:21] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 14:30:22] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:30:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:22] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:22] Prefill batch. #new-seq: 1, #new-token: 647, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:22] Decode batch. #running-req: 1, #token: 729, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.27, #queue-req: 0, 
[2025-09-30 14:30:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:22] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:23] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.52, #queue-req: 0, 
[2025-09-30 14:30:23] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 719, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:23] Prefill batch. #new-seq: 1, #new-token: 904, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:23] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:23] Decode batch. #running-req: 1, #token: 431, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.53, #queue-req: 0, 
[2025-09-30 14:30:23] Decode batch. #running-req: 1, #token: 471, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.05, #queue-req: 0, 
[2025-09-30 14:30:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:24] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:24] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.61, #queue-req: 0, 
[2025-09-30 14:30:24] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:30:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:24] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:24] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:24] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.38, #queue-req: 0, 
[2025-09-30 14:30:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:25] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:25] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:25] Decode batch. #running-req: 1, #token: 541, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.39, #queue-req: 0, 
[2025-09-30 14:30:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:25] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:25] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:30:26] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:30:26] Decode batch. #running-req: 1, #token: 375, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:30:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:26] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:26] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:26] Decode batch. #running-req: 1, #token: 436, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.55, #queue-req: 0, 
[2025-09-30 14:30:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:27] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:27] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:27] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 77.65, #queue-req: 0, 
[2025-09-30 14:30:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:27] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:27] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.11, #queue-req: 0, 
[2025-09-30 14:30:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:28] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:28] Prefill batch. #new-seq: 1, #new-token: 229, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:28] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.81, #queue-req: 0, 
[2025-09-30 14:30:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:28] Prefill batch. #new-seq: 1, #new-token: 618, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:28] Prefill batch. #new-seq: 1, #new-token: 392, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:28] Decode batch. #running-req: 1, #token: 571, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.32, #queue-req: 0, 
[2025-09-30 14:30:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:28] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:29] Decode batch. #running-req: 1, #token: 426, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.65, #queue-req: 0, 
[2025-09-30 14:30:29] Decode batch. #running-req: 1, #token: 466, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.77, #queue-req: 0, 
[2025-09-30 14:30:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:29] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:29] Prefill batch. #new-seq: 1, #new-token: 387, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:29] Decode batch. #running-req: 1, #token: 463, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.72, #queue-req: 0, 
[2025-09-30 14:30:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:30] Prefill batch. #new-seq: 1, #new-token: 764, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:30] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:30] Decode batch. #running-req: 1, #token: 558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.90, #queue-req: 0, 
[2025-09-30 14:30:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:30] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:30] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:30:31] Decode batch. #running-req: 1, #token: 338, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:30:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:31] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:31] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:31] Decode batch. #running-req: 1, #token: 457, token usage: 0.01, cuda graph: True, gen throughput (token/s): 81.07, #queue-req: 0, 
[2025-09-30 14:30:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:31] Prefill batch. #new-seq: 1, #new-token: 781, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:31] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:32] Decode batch. #running-req: 1, #token: 592, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.60, #queue-req: 0, 
[2025-09-30 14:30:32] Decode batch. #running-req: 1, #token: 632, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.94, #queue-req: 0, 
[2025-09-30 14:30:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:32] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:32] Decode batch. #running-req: 1, #token: 330, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.75, #queue-req: 0, 
[2025-09-30 14:30:33] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:30:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:33] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:33] Prefill batch. #new-seq: 1, #new-token: 421, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:33] Decode batch. #running-req: 1, #token: 584, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.29, #queue-req: 0, 
[2025-09-30 14:30:33] Decode batch. #running-req: 1, #token: 624, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:30:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:33] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:34] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 14:30:34] Decode batch. #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.41, #queue-req: 0, 
[2025-09-30 14:30:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:34] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:34] Prefill batch. #new-seq: 1, #new-token: 417, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:34] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.18, #queue-req: 0, 
[2025-09-30 14:30:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:35] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:35] Prefill batch. #new-seq: 1, #new-token: 279, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:35] Decode batch. #running-req: 1, #token: 453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.16, #queue-req: 0, 
[2025-09-30 14:30:35] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.92, #queue-req: 0, 
[2025-09-30 14:30:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:35] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:36] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 14:30:36] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:30:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:36] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:36] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.58, #queue-req: 0, 
[2025-09-30 14:30:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:36] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:37] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.41, #queue-req: 0, 
[2025-09-30 14:30:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:37] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:37] Prefill batch. #new-seq: 1, #new-token: 382, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:37] Decode batch. #running-req: 1, #token: 581, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.56, #queue-req: 0, 
[2025-09-30 14:30:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:37] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:37] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.15, #queue-req: 0, 
[2025-09-30 14:30:38] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:30:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:38] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:38] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:38] Decode batch. #running-req: 1, #token: 466, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.90, #queue-req: 0, 
[2025-09-30 14:30:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:38] Prefill batch. #new-seq: 1, #new-token: 593, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:39] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:39] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.80, #queue-req: 0, 
[2025-09-30 14:30:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:39] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.09, #queue-req: 0, 
[2025-09-30 14:30:39] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:39] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:39] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.55, #queue-req: 0, 
[2025-09-30 14:30:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:39] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:40] Prefill batch. #new-seq: 1, #new-token: 502, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:40] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:40] Decode batch. #running-req: 1, #token: 526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 70.59, #queue-req: 0, 
[2025-09-30 14:30:40] Decode batch. #running-req: 1, #token: 566, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.17, #queue-req: 0, 
[2025-09-30 14:30:41] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.10, #queue-req: 0, 
[2025-09-30 14:30:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:41] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:41] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 14:30:41] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:30:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:41] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:42] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.74, #queue-req: 0, 
[2025-09-30 14:30:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:42] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:42] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:42] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:42] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.45, #queue-req: 0, 
[2025-09-30 14:30:43] Decode batch. #running-req: 1, #token: 397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.36, #queue-req: 0, 
[2025-09-30 14:30:43] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.23, #queue-req: 0, 
[2025-09-30 14:30:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:43] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:43] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:30:43] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:30:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:44] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:44] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:44] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.43, #queue-req: 0, 
[2025-09-30 14:30:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:44] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:44] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:44] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.41, #queue-req: 0, 
[2025-09-30 14:30:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:45] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:45] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.53, #queue-req: 0, 
[2025-09-30 14:30:45] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:30:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:45] Prefill batch. #new-seq: 1, #new-token: 741, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:45] Prefill batch. #new-seq: 1, #new-token: 598, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:45] Decode batch. #running-req: 1, #token: 796, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.19, #queue-req: 0, 
[2025-09-30 14:30:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:46] Prefill batch. #new-seq: 1, #new-token: 58, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:46] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.85, #queue-req: 0, 
[2025-09-30 14:30:46] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:30:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:46] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:46] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.75, #queue-req: 0, 
[2025-09-30 14:30:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:46] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:47] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 664, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:47] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.06, #queue-req: 0, 
[2025-09-30 14:30:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:47] Prefill batch. #new-seq: 1, #new-token: 755, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:47] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:48] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 72.36, #queue-req: 0, 
[2025-09-30 14:30:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:48] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:48] Decode batch. #running-req: 1, #token: 230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.65, #queue-req: 0, 
[2025-09-30 14:30:48] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:30:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:48] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:48] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:49] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.05, #queue-req: 0, 
[2025-09-30 14:30:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:49] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:49] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:49] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.88, #queue-req: 0, 
[2025-09-30 14:30:49] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.40, #queue-req: 0, 
[2025-09-30 14:30:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:49] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:50] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.09, #queue-req: 0, 
[2025-09-30 14:30:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:50] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:50] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.80, #queue-req: 0, 
[2025-09-30 14:30:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:50] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:50] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:51] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.94, #queue-req: 0, 
[2025-09-30 14:30:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 221, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:51] Prefill batch. #new-seq: 1, #new-token: 748, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:51] Prefill batch. #new-seq: 1, #new-token: 600, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:51] Decode batch. #running-req: 1, #token: 769, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.27, #queue-req: 0, 
[2025-09-30 14:30:51] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 14:30:52] Decode batch. #running-req: 1, #token: 849, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.03, #queue-req: 0, 
[2025-09-30 14:30:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:52] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:52] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.60, #queue-req: 0, 
[2025-09-30 14:30:52] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:30:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:53] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:53] Prefill batch. #new-seq: 1, #new-token: 594, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:53] Decode batch. #running-req: 1, #token: 680, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.10, #queue-req: 0, 
[2025-09-30 14:30:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:53] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:53] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:53] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.89, #queue-req: 0, 
[2025-09-30 14:30:54] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.12, #queue-req: 0, 
[2025-09-30 14:30:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:54] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:54] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.45, #queue-req: 0, 
[2025-09-30 14:30:54] Decode batch. #running-req: 1, #token: 268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:30:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:55] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:55] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.51, #queue-req: 0, 
[2025-09-30 14:30:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:55] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:55] Prefill batch. #new-seq: 1, #new-token: 473, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:55] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:55] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.08, #queue-req: 0, 
[2025-09-30 14:30:56] Decode batch. #running-req: 1, #token: 491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.94, #queue-req: 0, 
[2025-09-30 14:30:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:56] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:56] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.30, #queue-req: 0, 
[2025-09-30 14:30:56] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:30:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:57] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:57] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:57] Decode batch. #running-req: 1, #token: 356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.80, #queue-req: 0, 
[2025-09-30 14:30:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:57] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:57] Decode batch. #running-req: 1, #token: 109, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.34, #queue-req: 0, 
[2025-09-30 14:30:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:57] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 342, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:58] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:58] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:58] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.24, #queue-req: 0, 
[2025-09-30 14:30:58] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.80, #queue-req: 0, 
[2025-09-30 14:30:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:58] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:59] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.12, #queue-req: 0, 
[2025-09-30 14:30:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:59] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:59] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:59] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 83.07, #queue-req: 0, 
[2025-09-30 14:30:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:30:59] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:30:59] Decode batch. #running-req: 1, #token: 226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.11, #queue-req: 0, 
[2025-09-30 14:31:00] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:31:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:00] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:00] Decode batch. #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.42, #queue-req: 0, 
[2025-09-30 14:31:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:00] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:01] Prefill batch. #new-seq: 1, #new-token: 556, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:01] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:01] Decode batch. #running-req: 1, #token: 491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.80, #queue-req: 0, 
[2025-09-30 14:31:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:01] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:01] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:31:01] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:31:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:02] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:02] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:02] Decode batch. #running-req: 1, #token: 539, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.42, #queue-req: 0, 
[2025-09-30 14:31:02] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.89, #queue-req: 0, 
[2025-09-30 14:31:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:02] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:03] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:31:03] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:31:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:03] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:03] Prefill batch. #new-seq: 1, #new-token: 351, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:04] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:04] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:04] Decode batch. #running-req: 1, #token: 383, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.08, #queue-req: 0, 
[2025-09-30 14:31:04] Decode batch. #running-req: 1, #token: 423, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.23, #queue-req: 0, 
[2025-09-30 14:31:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:04] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:04] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.72, #queue-req: 0, 
[2025-09-30 14:31:05] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:31:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:05] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:05] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:05] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.52, #queue-req: 0, 
[2025-09-30 14:31:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:05] Prefill batch. #new-seq: 1, #new-token: 434, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:06] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:06] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.60, #queue-req: 0, 
[2025-09-30 14:31:06] Decode batch. #running-req: 1, #token: 491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.90, #queue-req: 0, 
[2025-09-30 14:31:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:06] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:06] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.76, #queue-req: 0, 
[2025-09-30 14:31:07] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:31:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:07] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:07] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:07] Decode batch. #running-req: 1, #token: 366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.17, #queue-req: 0, 
[2025-09-30 14:31:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:07] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:08] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:31:08] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:31:08] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:31:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:08] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:08] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:09] Decode batch. #running-req: 1, #token: 409, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.71, #queue-req: 0, 
[2025-09-30 14:31:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:09] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:09] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.47, #queue-req: 0, 
[2025-09-30 14:31:09] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:31:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:10] Prefill batch. #new-seq: 1, #new-token: 1774, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:10] Decode batch. #running-req: 1, #token: 2130, token usage: 0.03, cuda graph: True, gen throughput (token/s): 60.62, #queue-req: 0, 
[2025-09-30 14:31:10] Decode batch. #running-req: 1, #token: 2170, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:31:11] Decode batch. #running-req: 1, #token: 2210, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:31:11] Decode batch. #running-req: 1, #token: 2250, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:31:11] Decode batch. #running-req: 1, #token: 2290, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:31:12] Decode batch. #running-req: 1, #token: 2330, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.93, #queue-req: 0, 
[2025-09-30 14:31:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:12] Prefill batch. #new-seq: 1, #new-token: 1774, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:12] Decode batch. #running-req: 1, #token: 2096, token usage: 0.03, cuda graph: True, gen throughput (token/s): 97.54, #queue-req: 0, 
[2025-09-30 14:31:12] Decode batch. #running-req: 1, #token: 2136, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:31:13] Decode batch. #running-req: 1, #token: 2176, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:31:13] Decode batch. #running-req: 1, #token: 2216, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:31:13] Decode batch. #running-req: 1, #token: 2256, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:31:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:13] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:14] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 115.36, #queue-req: 0, 
[2025-09-30 14:31:14] Decode batch. #running-req: 1, #token: 808, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.81, #queue-req: 0, 
[2025-09-30 14:31:14] Decode batch. #running-req: 1, #token: 848, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.74, #queue-req: 0, 
[2025-09-30 14:31:15] Decode batch. #running-req: 1, #token: 888, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.63, #queue-req: 0, 
[2025-09-30 14:31:15] Decode batch. #running-req: 1, #token: 928, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.52, #queue-req: 0, 
[2025-09-30 14:31:15] Decode batch. #running-req: 1, #token: 968, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.44, #queue-req: 0, 
[2025-09-30 14:31:15] Decode batch. #running-req: 1, #token: 1008, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:31:16] Decode batch. #running-req: 1, #token: 1048, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.16, #queue-req: 0, 
[2025-09-30 14:31:16] Decode batch. #running-req: 1, #token: 1088, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.97, #queue-req: 0, 
[2025-09-30 14:31:16] Decode batch. #running-req: 1, #token: 1128, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:31:17] Decode batch. #running-req: 1, #token: 1168, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:31:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:17] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:17] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:17] Decode batch. #running-req: 1, #token: 421, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.85, #queue-req: 0, 
[2025-09-30 14:31:18] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.04, #queue-req: 0, 
[2025-09-30 14:31:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:18] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:18] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.15, #queue-req: 0, 
[2025-09-30 14:31:18] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:31:18] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:31:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:19] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:19] Decode batch. #running-req: 1, #token: 331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.53, #queue-req: 0, 
[2025-09-30 14:31:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:19] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:20] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:20] Decode batch. #running-req: 1, #token: 483, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.31, #queue-req: 0, 
[2025-09-30 14:31:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:20] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:20] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.03, #queue-req: 0, 
[2025-09-30 14:31:20] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:31:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:21] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.16, #queue-req: 0, 
[2025-09-30 14:31:21] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:21] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:21] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.10, #queue-req: 0, 
[2025-09-30 14:31:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:21] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:22] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:31:22] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:31:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:22] Prefill batch. #new-seq: 1, #new-token: 815, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:22] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:23] Decode batch. #running-req: 1, #token: 645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.20, #queue-req: 0, 
[2025-09-30 14:31:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:23] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:23] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.81, #queue-req: 0, 
[2025-09-30 14:31:23] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:31:23] Decode batch. #running-req: 1, #token: 320, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:31:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:24] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:24] Prefill batch. #new-seq: 1, #new-token: 468, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:24] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.74, #queue-req: 0, 
[2025-09-30 14:31:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:24] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 540, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:24] Decode batch. #running-req: 1, #token: 561, token usage: 0.01, cuda graph: True, gen throughput (token/s): 68.21, #queue-req: 0, 
[2025-09-30 14:31:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:25] Prefill batch. #new-seq: 1, #new-token: 803, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:25] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:25] Decode batch. #running-req: 1, #token: 533, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.58, #queue-req: 0, 
[2025-09-30 14:31:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:25] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:25] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:31:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:26] Prefill batch. #new-seq: 1, #new-token: 1048, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:26] Prefill batch. #new-seq: 1, #new-token: 718, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:26] Decode batch. #running-req: 1, #token: 888, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.41, #queue-req: 0, 
[2025-09-30 14:31:26] Decode batch. #running-req: 1, #token: 928, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:31:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:26] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:26] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.41, #queue-req: 0, 
[2025-09-30 14:31:27] Decode batch. #running-req: 1, #token: 402, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.11, #queue-req: 0, 
[2025-09-30 14:31:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:27] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:27] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.10, #queue-req: 0, 
[2025-09-30 14:31:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:27] Prefill batch. #new-seq: 1, #new-token: 714, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:27] Decode batch. #running-req: 1, #token: 809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.41, #queue-req: 0, 
[2025-09-30 14:31:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:28] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:28] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 786, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:28] Prefill batch. #new-seq: 1, #new-token: 1195, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:28] Prefill batch. #new-seq: 1, #new-token: 485, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:28] Decode batch. #running-req: 1, #token: 648, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.94, #queue-req: 0, 
[2025-09-30 14:31:29] Decode batch. #running-req: 1, #token: 688, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.79, #queue-req: 0, 
[2025-09-30 14:31:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:29] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:29] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:31:29] Decode batch. #running-req: 1, #token: 372, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 14:31:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:30] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:30] Prefill batch. #new-seq: 1, #new-token: 481, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:30] Decode batch. #running-req: 1, #token: 567, token usage: 0.01, cuda graph: True, gen throughput (token/s): 80.24, #queue-req: 0, 
[2025-09-30 14:31:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:30] Prefill batch. #new-seq: 1, #new-token: 1018, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:30] Prefill batch. #new-seq: 1, #new-token: 597, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:30] Decode batch. #running-req: 1, #token: 776, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.77, #queue-req: 0, 
[2025-09-30 14:31:31] Decode batch. #running-req: 1, #token: 816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.04, #queue-req: 0, 
[2025-09-30 14:31:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:31] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:31] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.29, #queue-req: 0, 
[2025-09-30 14:31:31] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:31:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:32] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:32] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 86.64, #queue-req: 0, 
[2025-09-30 14:31:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:32] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:32] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:32] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:32] Decode batch. #running-req: 1, #token: 634, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.85, #queue-req: 0, 
[2025-09-30 14:31:33] Decode batch. #running-req: 1, #token: 674, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.82, #queue-req: 0, 
[2025-09-30 14:31:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:33] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:33] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.46, #queue-req: 0, 
[2025-09-30 14:31:33] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:31:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:34] Prefill batch. #new-seq: 1, #new-token: 750, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:34] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:34] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.86, #queue-req: 0, 
[2025-09-30 14:31:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:34] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:34] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.42, #queue-req: 0, 
[2025-09-30 14:31:35] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:31:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:35] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:35] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:35] Decode batch. #running-req: 1, #token: 377, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.78, #queue-req: 0, 
[2025-09-30 14:31:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:35] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:36] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 367, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:36] Decode batch. #running-req: 1, #token: 385, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.56, #queue-req: 0, 
[2025-09-30 14:31:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:36] Prefill batch. #new-seq: 1, #new-token: 630, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:36] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:36] Decode batch. #running-req: 1, #token: 527, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.48, #queue-req: 0, 
[2025-09-30 14:31:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:37] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:37] Decode batch. #running-req: 1, #token: 407, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.74, #queue-req: 0, 
[2025-09-30 14:31:37] Decode batch. #running-req: 1, #token: 447, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.98, #queue-req: 0, 
[2025-09-30 14:31:37] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.75, #queue-req: 0, 
[2025-09-30 14:31:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:37] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:37] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:38] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:38] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.25, #queue-req: 0, 
[2025-09-30 14:31:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:38] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 402, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:38] Decode batch. #running-req: 1, #token: 442, token usage: 0.01, cuda graph: True, gen throughput (token/s): 117.85, #queue-req: 0, 
[2025-09-30 14:31:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:39] Prefill batch. #new-seq: 1, #new-token: 660, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:39] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:39] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.54, #queue-req: 0, 
[2025-09-30 14:31:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:39] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:39] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.73, #queue-req: 0, 
[2025-09-30 14:31:40] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:31:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:40] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.54, #queue-req: 0, 
[2025-09-30 14:31:40] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:40] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:40] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 397, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:41] Decode batch. #running-req: 1, #token: 412, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.11, #queue-req: 0, 
[2025-09-30 14:31:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:41] Prefill batch. #new-seq: 1, #new-token: 585, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:41] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:41] Decode batch. #running-req: 1, #token: 455, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.10, #queue-req: 0, 
[2025-09-30 14:31:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:41] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:42] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.72, #queue-req: 0, 
[2025-09-30 14:31:42] Decode batch. #running-req: 1, #token: 328, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:31:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:42] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:42] Decode batch. #running-req: 1, #token: 346, token usage: 0.01, cuda graph: True, gen throughput (token/s): 109.69, #queue-req: 0, 
[2025-09-30 14:31:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:43] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:43] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 327, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:43] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.39, #queue-req: 0, 
[2025-09-30 14:31:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:43] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:43] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 216, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:43] Decode batch. #running-req: 1, #token: 462, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.01, #queue-req: 0, 
[2025-09-30 14:31:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:44] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 249, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:44] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.88, #queue-req: 0, 
[2025-09-30 14:31:44] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:31:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:44] Prefill batch. #new-seq: 1, #new-token: 453, #cached-token: 131, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:44] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:45] Decode batch. #running-req: 1, #token: 436, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.34, #queue-req: 0, 
[2025-09-30 14:31:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:45] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:45] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 14:31:45] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.20, #queue-req: 0, 
[2025-09-30 14:31:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:46] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:46] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:46] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:46] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:46] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.12, #queue-req: 0, 
[2025-09-30 14:31:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:46] Prefill batch. #new-seq: 1, #new-token: 51, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:47] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.83, #queue-req: 0, 
[2025-09-30 14:31:47] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:31:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:47] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:47] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:47] Decode batch. #running-req: 1, #token: 200, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.19, #queue-req: 0, 
[2025-09-30 14:31:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:48] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:48] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:48] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.55, #queue-req: 0, 
[2025-09-30 14:31:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:48] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:48] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 14:31:49] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:31:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:49] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:49] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.37, #queue-req: 0, 
[2025-09-30 14:31:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:49] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:50] Prefill batch. #new-seq: 1, #new-token: 1001, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:50] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:50] Decode batch. #running-req: 1, #token: 974, token usage: 0.02, cuda graph: True, gen throughput (token/s): 45.17, #queue-req: 0, 
[2025-09-30 14:31:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:50] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:50] Decode batch. #running-req: 1, #token: 316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.89, #queue-req: 0, 
[2025-09-30 14:31:50] Decode batch. #running-req: 1, #token: 356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.22, #queue-req: 0, 
[2025-09-30 14:31:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:51] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:51] Prefill batch. #new-seq: 1, #new-token: 800, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:51] Decode batch. #running-req: 1, #token: 895, token usage: 0.01, cuda graph: True, gen throughput (token/s): 95.48, #queue-req: 0, 
[2025-09-30 14:31:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:51] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:51] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 874, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:52] Decode batch. #running-req: 1, #token: 896, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.54, #queue-req: 0, 
[2025-09-30 14:31:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:52] Prefill batch. #new-seq: 1, #new-token: 1597, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:52] Prefill batch. #new-seq: 1, #new-token: 834, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:52] Decode batch. #running-req: 1, #token: 1021, token usage: 0.02, cuda graph: True, gen throughput (token/s): 55.62, #queue-req: 0, 
[2025-09-30 14:31:53] Decode batch. #running-req: 1, #token: 1061, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.36, #queue-req: 0, 
[2025-09-30 14:31:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:53] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:53] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.06, #queue-req: 0, 
[2025-09-30 14:31:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:54] Prefill batch. #new-seq: 1, #new-token: 1571, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:54] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.36, #queue-req: 0, 
[2025-09-30 14:31:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:54] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:54] Decode batch. #running-req: 1, #token: 982, token usage: 0.02, cuda graph: True, gen throughput (token/s): 112.80, #queue-req: 0, 
[2025-09-30 14:31:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:54] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:54] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.41, #queue-req: 0, 
[2025-09-30 14:31:55] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:31:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:55] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:55] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.42, #queue-req: 0, 
[2025-09-30 14:31:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:55] Prefill batch. #new-seq: 1, #new-token: 776, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:56] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:56] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 847, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:56] Decode batch. #running-req: 1, #token: 850, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.34, #queue-req: 0, 
[2025-09-30 14:31:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:56] Prefill batch. #new-seq: 1, #new-token: 1331, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:56] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:56] Decode batch. #running-req: 1, #token: 752, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.96, #queue-req: 0, 
[2025-09-30 14:31:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:57] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:57] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.21, #queue-req: 0, 
[2025-09-30 14:31:57] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:31:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:57] Decode batch. #running-req: 1, #token: 105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.14, #queue-req: 0, 
[2025-09-30 14:31:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:57] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:58] Prefill batch. #new-seq: 1, #new-token: 1023, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:58] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:58] Decode batch. #running-req: 1, #token: 696, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.57, #queue-req: 0, 
[2025-09-30 14:31:59] Decode batch. #running-req: 1, #token: 736, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.56, #queue-req: 0, 
[2025-09-30 14:31:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:31:59] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 130.33, #queue-req: 0, 
[2025-09-30 14:31:59] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:31:59] Decode batch. #running-req: 1, #token: 376, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:31:59] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.99, #queue-req: 0, 
[2025-09-30 14:32:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:00] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:00] Decode batch. #running-req: 1, #token: 118, token usage: 0.00, cuda graph: True, gen throughput (token/s): 77.04, #queue-req: 0, 
[2025-09-30 14:32:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:00] Prefill batch. #new-seq: 1, #new-token: 467, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:01] Prefill batch. #new-seq: 1, #new-token: 775, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:01] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:01] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.48, #queue-req: 0, 
[2025-09-30 14:32:01] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.92, #queue-req: 0, 
[2025-09-30 14:32:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:01] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:01] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 124.19, #queue-req: 0, 
[2025-09-30 14:32:02] Decode batch. #running-req: 1, #token: 397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.17, #queue-req: 0, 
[2025-09-30 14:32:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:02] Prefill batch. #new-seq: 1, #new-token: 779, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:02] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:02] Decode batch. #running-req: 1, #token: 672, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.68, #queue-req: 0, 
[2025-09-30 14:32:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:02] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:03] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.73, #queue-req: 0, 
[2025-09-30 14:32:03] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:32:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:03] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:03] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:03] Decode batch. #running-req: 1, #token: 546, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.64, #queue-req: 0, 
[2025-09-30 14:32:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 543, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:04] Decode batch. #running-req: 1, #token: 548, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.35, #queue-req: 0, 
[2025-09-30 14:32:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:04] Prefill batch. #new-seq: 1, #new-token: 974, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:04] Prefill batch. #new-seq: 1, #new-token: 505, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:04] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.65, #queue-req: 0, 
[2025-09-30 14:32:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:05] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:05] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 14:32:05] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:32:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:05] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:05] Prefill batch. #new-seq: 1, #new-token: 501, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:05] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.91, #queue-req: 0, 
[2025-09-30 14:32:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:06] Prefill batch. #new-seq: 1, #new-token: 928, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:06] Prefill batch. #new-seq: 1, #new-token: 430, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:06] Decode batch. #running-req: 1, #token: 613, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.86, #queue-req: 0, 
[2025-09-30 14:32:07] Decode batch. #running-req: 1, #token: 653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.76, #queue-req: 0, 
[2025-09-30 14:32:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:07] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:07] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 14:32:07] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:32:08] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:32:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:08] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:08] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:08] Decode batch. #running-req: 1, #token: 511, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.38, #queue-req: 0, 
[2025-09-30 14:32:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:08] Prefill batch. #new-seq: 1, #new-token: 911, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:08] Prefill batch. #new-seq: 1, #new-token: 486, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:09] Decode batch. #running-req: 1, #token: 673, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.95, #queue-req: 0, 
[2025-09-30 14:32:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:09] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:09] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.83, #queue-req: 0, 
[2025-09-30 14:32:09] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:32:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:09] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:09] Prefill batch. #new-seq: 1, #new-token: 482, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:10] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:10] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 65.76, #queue-req: 0, 
[2025-09-30 14:32:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 555, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:10] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 121.92, #queue-req: 0, 
[2025-09-30 14:32:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:11] Prefill batch. #new-seq: 1, #new-token: 1047, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:11] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:11] Decode batch. #running-req: 1, #token: 764, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.95, #queue-req: 0, 
[2025-09-30 14:32:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:11] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:11] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:32:12] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:32:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:12] Prefill batch. #new-seq: 1, #new-token: 850, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:12] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:12] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.42, #queue-req: 0, 
[2025-09-30 14:32:13] Decode batch. #running-req: 1, #token: 501, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.92, #queue-req: 0, 
[2025-09-30 14:32:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:13] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:13] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.50, #queue-req: 0, 
[2025-09-30 14:32:13] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:32:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:14] Prefill batch. #new-seq: 1, #new-token: 526, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:14] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:14] Decode batch. #running-req: 1, #token: 435, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.90, #queue-req: 0, 
[2025-09-30 14:32:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:14] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.50, #queue-req: 0, 
[2025-09-30 14:32:14] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.63, #queue-req: 0, 
[2025-09-30 14:32:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:15] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:15] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:15] Decode batch. #running-req: 1, #token: 327, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.38, #queue-req: 0, 
[2025-09-30 14:32:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:15] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:15] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 313, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:15] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.66, #queue-req: 0, 
[2025-09-30 14:32:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:16] Prefill batch. #new-seq: 1, #new-token: 547, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:16] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:16] Decode batch. #running-req: 1, #token: 559, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.91, #queue-req: 0, 
[2025-09-30 14:32:16] Decode batch. #running-req: 1, #token: 599, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.00, #queue-req: 0, 
[2025-09-30 14:32:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:17] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:17] Decode batch. #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:32:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:17] Prefill batch. #new-seq: 1, #new-token: 566, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:17] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 209, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:18] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.04, #queue-req: 0, 
[2025-09-30 14:32:18] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.23, #queue-req: 0, 
[2025-09-30 14:32:18] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.07, #queue-req: 0, 
[2025-09-30 14:32:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:18] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:18] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 14:32:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:19] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:19] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 100.60, #queue-req: 0, 
[2025-09-30 14:32:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:19] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:19] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:20] Decode batch. #running-req: 1, #token: 451, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.36, #queue-req: 0, 
[2025-09-30 14:32:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:20] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:20] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.62, #queue-req: 0, 
[2025-09-30 14:32:20] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:32:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:21] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:21] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:21] Decode batch. #running-req: 1, #token: 335, token usage: 0.01, cuda graph: True, gen throughput (token/s): 71.22, #queue-req: 0, 
[2025-09-30 14:32:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:21] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:21] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:21] Decode batch. #running-req: 1, #token: 356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.79, #queue-req: 0, 
[2025-09-30 14:32:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:21] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:22] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.84, #queue-req: 0, 
[2025-09-30 14:32:22] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:32:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:22] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:22] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:22] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.57, #queue-req: 0, 
[2025-09-30 14:32:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:23] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:23] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 231, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:23] Prefill batch. #new-seq: 1, #new-token: 963, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:24] Decode batch. #running-req: 1, #token: 1005, token usage: 0.02, cuda graph: True, gen throughput (token/s): 37.00, #queue-req: 0, 
[2025-09-30 14:32:24] Decode batch. #running-req: 1, #token: 1045, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.10, #queue-req: 0, 
[2025-09-30 14:32:24] Decode batch. #running-req: 1, #token: 1085, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.87, #queue-req: 0, 
[2025-09-30 14:32:24] Decode batch. #running-req: 1, #token: 1125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:32:25] Decode batch. #running-req: 1, #token: 1165, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.84, #queue-req: 0, 
[2025-09-30 14:32:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:25] Prefill batch. #new-seq: 1, #new-token: 943, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:25] Decode batch. #running-req: 1, #token: 998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.20, #queue-req: 0, 
[2025-09-30 14:32:25] Decode batch. #running-req: 1, #token: 1038, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.31, #queue-req: 0, 
[2025-09-30 14:32:26] Decode batch. #running-req: 1, #token: 1078, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.98, #queue-req: 0, 
[2025-09-30 14:32:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:26] Prefill batch. #new-seq: 1, #new-token: 758, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:26] Decode batch. #running-req: 1, #token: 819, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.20, #queue-req: 0, 
[2025-09-30 14:32:26] Decode batch. #running-req: 1, #token: 859, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.69, #queue-req: 0, 
[2025-09-30 14:32:27] Decode batch. #running-req: 1, #token: 899, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.64, #queue-req: 0, 
[2025-09-30 14:32:27] Decode batch. #running-req: 1, #token: 939, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.42, #queue-req: 0, 
[2025-09-30 14:32:27] Decode batch. #running-req: 1, #token: 979, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.39, #queue-req: 0, 
[2025-09-30 14:32:28] Decode batch. #running-req: 1, #token: 1019, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.37, #queue-req: 0, 
[2025-09-30 14:32:28] Decode batch. #running-req: 1, #token: 1059, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.05, #queue-req: 0, 
[2025-09-30 14:32:28] Decode batch. #running-req: 1, #token: 1099, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.90, #queue-req: 0, 
[2025-09-30 14:32:29] Decode batch. #running-req: 1, #token: 1139, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:32:29] Decode batch. #running-req: 1, #token: 1179, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:32:29] Decode batch. #running-req: 1, #token: 1219, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:32:29] Decode batch. #running-req: 1, #token: 1259, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:32:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:30] Prefill batch. #new-seq: 1, #new-token: 326, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:30] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:30] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 64.70, #queue-req: 0, 
[2025-09-30 14:32:30] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.32, #queue-req: 0, 
[2025-09-30 14:32:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:31] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:31] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 14:32:31] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.64, #queue-req: 0, 
[2025-09-30 14:32:31] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:32:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:31] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:32] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.48, #queue-req: 0, 
[2025-09-30 14:32:32] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:32] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:33] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.38, #queue-req: 0, 
[2025-09-30 14:32:33] Decode batch. #running-req: 1, #token: 595, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.05, #queue-req: 0, 
[2025-09-30 14:32:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:33] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:33] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.95, #queue-req: 0, 
[2025-09-30 14:32:33] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:32:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:34] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:34] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 231, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:34] Decode batch. #running-req: 1, #token: 374, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.98, #queue-req: 0, 
[2025-09-30 14:32:34] Decode batch. #running-req: 1, #token: 414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.28, #queue-req: 0, 
[2025-09-30 14:32:35] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.06, #queue-req: 0, 
[2025-09-30 14:32:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:35] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:35] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.83, #queue-req: 0, 
[2025-09-30 14:32:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:35] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:32:36] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:36] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:36] Prefill batch. #new-seq: 1, #new-token: 1006, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:36] Decode batch. #running-req: 1, #token: 1349, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.75, #queue-req: 0, 
[2025-09-30 14:32:37] Decode batch. #running-req: 1, #token: 1389, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.12, #queue-req: 0, 
[2025-09-30 14:32:37] Decode batch. #running-req: 1, #token: 1429, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:32:37] Decode batch. #running-req: 1, #token: 1469, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:32:38] Decode batch. #running-req: 1, #token: 1509, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:32:38] Decode batch. #running-req: 1, #token: 1549, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.93, #queue-req: 0, 
[2025-09-30 14:32:38] Decode batch. #running-req: 1, #token: 1589, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.59, #queue-req: 0, 
[2025-09-30 14:32:39] Decode batch. #running-req: 1, #token: 1629, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:32:39] Decode batch. #running-req: 1, #token: 1669, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:32:39] Decode batch. #running-req: 1, #token: 1709, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:32:39] Decode batch. #running-req: 1, #token: 1749, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 14:32:40] Decode batch. #running-req: 1, #token: 1789, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:32:40] Decode batch. #running-req: 1, #token: 1829, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.02, #queue-req: 0, 
[2025-09-30 14:32:40] Decode batch. #running-req: 1, #token: 1869, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:32:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:41] Prefill batch. #new-seq: 1, #new-token: 1006, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:41] Decode batch. #running-req: 1, #token: 1336, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.27, #queue-req: 0, 
[2025-09-30 14:32:41] Decode batch. #running-req: 1, #token: 1376, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.21, #queue-req: 0, 
[2025-09-30 14:32:41] Decode batch. #running-req: 1, #token: 1416, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 14:32:42] Decode batch. #running-req: 1, #token: 1456, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.21, #queue-req: 0, 
[2025-09-30 14:32:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:42] Prefill batch. #new-seq: 1, #new-token: 917, #cached-token: 238, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:42] Decode batch. #running-req: 1, #token: 1191, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.45, #queue-req: 0, 
[2025-09-30 14:32:42] Decode batch. #running-req: 1, #token: 1231, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.82, #queue-req: 0, 
[2025-09-30 14:32:43] Decode batch. #running-req: 1, #token: 1271, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.78, #queue-req: 0, 
[2025-09-30 14:32:43] Decode batch. #running-req: 1, #token: 1311, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.38, #queue-req: 0, 
[2025-09-30 14:32:43] Decode batch. #running-req: 1, #token: 1351, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.31, #queue-req: 0, 
[2025-09-30 14:32:44] Decode batch. #running-req: 1, #token: 1391, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.19, #queue-req: 0, 
[2025-09-30 14:32:44] Decode batch. #running-req: 1, #token: 1431, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:32:44] Decode batch. #running-req: 1, #token: 1471, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:32:45] Decode batch. #running-req: 1, #token: 1511, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:32:45] Decode batch. #running-req: 1, #token: 1551, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.88, #queue-req: 0, 
[2025-09-30 14:32:45] Decode batch. #running-req: 1, #token: 1591, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:32:45] Decode batch. #running-req: 1, #token: 1631, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:32:46] Decode batch. #running-req: 1, #token: 1671, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:32:46] Decode batch. #running-req: 1, #token: 1711, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:32:46] Decode batch. #running-req: 1, #token: 1751, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:32:47] Decode batch. #running-req: 1, #token: 1791, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:32:47] Decode batch. #running-req: 1, #token: 1831, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.03, #queue-req: 0, 
[2025-09-30 14:32:47] Decode batch. #running-req: 1, #token: 1871, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.98, #queue-req: 0, 
[2025-09-30 14:32:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:48] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:48] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:48] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.37, #queue-req: 0, 
[2025-09-30 14:32:48] Decode batch. #running-req: 1, #token: 522, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.63, #queue-req: 0, 
[2025-09-30 14:32:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:49] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:49] Decode batch. #running-req: 1, #token: 248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.34, #queue-req: 0, 
[2025-09-30 14:32:49] Decode batch. #running-req: 1, #token: 288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:32:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:50] Prefill batch. #new-seq: 1, #new-token: 383, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:50] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:50] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 62.10, #queue-req: 0, 
[2025-09-30 14:32:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:50] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:50] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:32:50] Decode batch. #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:32:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:51] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:51] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 65.86, #queue-req: 0, 
[2025-09-30 14:32:51] Decode batch. #running-req: 1, #token: 513, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.49, #queue-req: 0, 
[2025-09-30 14:32:51] Decode batch. #running-req: 1, #token: 553, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.00, #queue-req: 0, 
[2025-09-30 14:32:52] Decode batch. #running-req: 1, #token: 593, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.81, #queue-req: 0, 
[2025-09-30 14:32:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:52] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:52] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:32:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:52] Prefill batch. #new-seq: 1, #new-token: 897, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:52] Decode batch. #running-req: 1, #token: 1113, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.79, #queue-req: 0, 
[2025-09-30 14:32:53] Decode batch. #running-req: 1, #token: 1153, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.88, #queue-req: 0, 
[2025-09-30 14:32:53] Decode batch. #running-req: 1, #token: 1193, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.83, #queue-req: 0, 
[2025-09-30 14:32:53] Decode batch. #running-req: 1, #token: 1233, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.72, #queue-req: 0, 
[2025-09-30 14:32:54] Decode batch. #running-req: 1, #token: 1273, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.75, #queue-req: 0, 
[2025-09-30 14:32:54] Decode batch. #running-req: 1, #token: 1313, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.36, #queue-req: 0, 
[2025-09-30 14:32:54] Decode batch. #running-req: 1, #token: 1353, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.22, #queue-req: 0, 
[2025-09-30 14:32:55] Decode batch. #running-req: 1, #token: 1393, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 14:32:55] Decode batch. #running-req: 1, #token: 1433, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:32:55] Decode batch. #running-req: 1, #token: 1473, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:32:56] Decode batch. #running-req: 1, #token: 1513, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:32:56] Decode batch. #running-req: 1, #token: 1553, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.87, #queue-req: 0, 
[2025-09-30 14:32:56] Decode batch. #running-req: 1, #token: 1593, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:32:56] Decode batch. #running-req: 1, #token: 1633, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:32:57] Decode batch. #running-req: 1, #token: 1673, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:32:57] Decode batch. #running-req: 1, #token: 1713, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.54, #queue-req: 0, 
[2025-09-30 14:32:57] Decode batch. #running-req: 1, #token: 1753, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:32:58] Decode batch. #running-req: 1, #token: 1793, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:32:58] Decode batch. #running-req: 1, #token: 1833, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.03, #queue-req: 0, 
[2025-09-30 14:32:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:58] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:58] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:59] Decode batch. #running-req: 1, #token: 521, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.19, #queue-req: 0, 
[2025-09-30 14:32:59] Decode batch. #running-req: 1, #token: 561, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.24, #queue-req: 0, 
[2025-09-30 14:32:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:32:59] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:32:59] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:33:00] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:33:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:00] Prefill batch. #new-seq: 1, #new-token: 2833, #cached-token: 341, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:00] Decode batch. #running-req: 1, #token: 3189, token usage: 0.05, cuda graph: True, gen throughput (token/s): 55.17, #queue-req: 0, 
[2025-09-30 14:33:01] Decode batch. #running-req: 1, #token: 3229, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:33:01] Decode batch. #running-req: 1, #token: 3269, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.77, #queue-req: 0, 
[2025-09-30 14:33:01] Decode batch. #running-req: 1, #token: 3309, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:33:02] Decode batch. #running-req: 1, #token: 3349, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.45, #queue-req: 0, 
[2025-09-30 14:33:02] Decode batch. #running-req: 1, #token: 3389, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:33:02] Decode batch. #running-req: 1, #token: 3429, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.16, #queue-req: 0, 
[2025-09-30 14:33:02] Decode batch. #running-req: 1, #token: 3469, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.22, #queue-req: 0, 
[2025-09-30 14:33:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:03] Prefill batch. #new-seq: 1, #new-token: 2833, #cached-token: 321, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:03] Decode batch. #running-req: 1, #token: 3168, token usage: 0.05, cuda graph: True, gen throughput (token/s): 84.21, #queue-req: 0, 
[2025-09-30 14:33:03] Decode batch. #running-req: 1, #token: 3208, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:33:04] Decode batch. #running-req: 1, #token: 3248, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:33:04] Decode batch. #running-req: 1, #token: 3288, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:33:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:04] Prefill batch. #new-seq: 1, #new-token: 1037, #cached-token: 193, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:04] Decode batch. #running-req: 1, #token: 1240, token usage: 0.02, cuda graph: True, gen throughput (token/s): 104.72, #queue-req: 0, 
[2025-09-30 14:33:05] Decode batch. #running-req: 1, #token: 1280, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.68, #queue-req: 0, 
[2025-09-30 14:33:05] Decode batch. #running-req: 1, #token: 1320, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.33, #queue-req: 0, 
[2025-09-30 14:33:05] Decode batch. #running-req: 1, #token: 1360, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:33:06] Decode batch. #running-req: 1, #token: 1400, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.21, #queue-req: 0, 
[2025-09-30 14:33:06] Decode batch. #running-req: 1, #token: 1440, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:33:06] Decode batch. #running-req: 1, #token: 1480, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.02, #queue-req: 0, 
[2025-09-30 14:33:06] Decode batch. #running-req: 1, #token: 1520, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.03, #queue-req: 0, 
[2025-09-30 14:33:07] Decode batch. #running-req: 1, #token: 1560, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.77, #queue-req: 0, 
[2025-09-30 14:33:07] Decode batch. #running-req: 1, #token: 1600, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.53, #queue-req: 0, 
[2025-09-30 14:33:07] Decode batch. #running-req: 1, #token: 1640, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:33:08] Decode batch. #running-req: 1, #token: 1680, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 14:33:08] Decode batch. #running-req: 1, #token: 1720, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:33:08] Decode batch. #running-req: 1, #token: 1760, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.40, #queue-req: 0, 
[2025-09-30 14:33:09] Decode batch. #running-req: 1, #token: 1800, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.34, #queue-req: 0, 
[2025-09-30 14:33:09] Decode batch. #running-req: 1, #token: 1840, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.94, #queue-req: 0, 
[2025-09-30 14:33:09] Decode batch. #running-req: 1, #token: 1880, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:33:10] Decode batch. #running-req: 1, #token: 1920, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:33:10] Decode batch. #running-req: 1, #token: 1960, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:33:10] Decode batch. #running-req: 1, #token: 2000, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:33:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:11] Prefill batch. #new-seq: 1, #new-token: 689, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:11] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:11] Decode batch. #running-req: 1, #token: 542, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.24, #queue-req: 0, 
[2025-09-30 14:33:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:11] Prefill batch. #new-seq: 1, #new-token: 48, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:11] Decode batch. #running-req: 1, #token: 257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.91, #queue-req: 0, 
[2025-09-30 14:33:12] Decode batch. #running-req: 1, #token: 297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:33:12] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:33:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:12] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:12] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:12] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.49, #queue-req: 0, 
[2025-09-30 14:33:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:13] Prefill batch. #new-seq: 1, #new-token: 759, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:13] Prefill batch. #new-seq: 1, #new-token: 416, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:13] Decode batch. #running-req: 1, #token: 603, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.09, #queue-req: 0, 
[2025-09-30 14:33:13] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.91, #queue-req: 0, 
[2025-09-30 14:33:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:13] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:14] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.56, #queue-req: 0, 
[2025-09-30 14:33:14] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:33:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:14] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:14] Prefill batch. #new-seq: 1, #new-token: 410, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:14] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.41, #queue-req: 0, 
[2025-09-30 14:33:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:15] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:15] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 481, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:15] Decode batch. #running-req: 1, #token: 495, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.50, #queue-req: 0, 
[2025-09-30 14:33:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:15] Prefill batch. #new-seq: 1, #new-token: 807, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:15] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:16] Decode batch. #running-req: 1, #token: 587, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.84, #queue-req: 0, 
[2025-09-30 14:33:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:16] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:16] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.45, #queue-req: 0, 
[2025-09-30 14:33:16] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.44, #queue-req: 0, 
[2025-09-30 14:33:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:17] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:17] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 81.01, #queue-req: 0, 
[2025-09-30 14:33:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:17] Prefill batch. #new-seq: 1, #new-token: 395, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:17] Prefill batch. #new-seq: 1, #new-token: 911, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:17] Prefill batch. #new-seq: 1, #new-token: 517, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:17] Decode batch. #running-req: 1, #token: 694, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.76, #queue-req: 0, 
[2025-09-30 14:33:18] Decode batch. #running-req: 1, #token: 734, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.54, #queue-req: 0, 
[2025-09-30 14:33:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:18] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:18] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.14, #queue-req: 0, 
[2025-09-30 14:33:18] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:33:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:19] Prefill batch. #new-seq: 1, #new-token: 790, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:19] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:19] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.59, #queue-req: 0, 
[2025-09-30 14:33:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:19] Decode batch. #running-req: 1, #token: 218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:33:20] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.75, #queue-req: 0, 
[2025-09-30 14:33:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:20] Prefill batch. #new-seq: 1, #new-token: 808, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:20] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:20] Decode batch. #running-req: 1, #token: 708, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.43, #queue-req: 0, 
[2025-09-30 14:33:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:20] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:21] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.75, #queue-req: 0, 
[2025-09-30 14:33:21] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:33:21] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:33:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:21] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:21] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:22] Decode batch. #running-req: 1, #token: 608, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.39, #queue-req: 0, 
[2025-09-30 14:33:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:22] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:22] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 601, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:22] Decode batch. #running-req: 1, #token: 610, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.99, #queue-req: 0, 
[2025-09-30 14:33:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:23] Prefill batch. #new-seq: 1, #new-token: 963, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:23] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:23] Decode batch. #running-req: 1, #token: 615, token usage: 0.01, cuda graph: True, gen throughput (token/s): 61.92, #queue-req: 0, 
[2025-09-30 14:33:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:23] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:23] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:33:23] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:33:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:24] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:24] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.34, #queue-req: 0, 
[2025-09-30 14:33:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:24] Prefill batch. #new-seq: 1, #new-token: 431, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:24] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:24] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 504, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:24] Decode batch. #running-req: 1, #token: 530, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.34, #queue-req: 0, 
[2025-09-30 14:33:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:25] Prefill batch. #new-seq: 1, #new-token: 809, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:25] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:25] Decode batch. #running-req: 1, #token: 580, token usage: 0.01, cuda graph: True, gen throughput (token/s): 62.93, #queue-req: 0, 
[2025-09-30 14:33:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:25] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:25] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.09, #queue-req: 0, 
[2025-09-30 14:33:26] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:33:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:26] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:26] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:26] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.12, #queue-req: 0, 
[2025-09-30 14:33:27] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.54, #queue-req: 0, 
[2025-09-30 14:33:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:27] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:27] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:27] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.81, #queue-req: 0, 
[2025-09-30 14:33:27] Decode batch. #running-req: 1, #token: 515, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.80, #queue-req: 0, 
[2025-09-30 14:33:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:28] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:28] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.79, #queue-req: 0, 
[2025-09-30 14:33:28] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:33:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:28] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:33:29] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:29] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:29] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:29] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:29] Decode batch. #running-req: 1, #token: 382, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.85, #queue-req: 0, 
[2025-09-30 14:33:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:29] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:30] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.35, #queue-req: 0, 
[2025-09-30 14:33:30] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:33:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:30] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:30] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:30] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.96, #queue-req: 0, 
[2025-09-30 14:33:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:31] Prefill batch. #new-seq: 1, #new-token: 389, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:31] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:31] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.47, #queue-req: 0, 
[2025-09-30 14:33:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:31] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:31] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 14:33:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:32] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:32] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:32] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.54, #queue-req: 0, 
[2025-09-30 14:33:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:32] Prefill batch. #new-seq: 1, #new-token: 900, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:32] Prefill batch. #new-seq: 1, #new-token: 725, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:32] Decode batch. #running-req: 1, #token: 916, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.81, #queue-req: 0, 
[2025-09-30 14:33:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:32] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:33] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.52, #queue-req: 0, 
[2025-09-30 14:33:33] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:33:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:33] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:33] Prefill batch. #new-seq: 1, #new-token: 721, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:34] Prefill batch. #new-seq: 1, #new-token: 1310, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:34] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:34] Decode batch. #running-req: 1, #token: 759, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.42, #queue-req: 0, 
[2025-09-30 14:33:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:34] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:34] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.46, #queue-req: 0, 
[2025-09-30 14:33:35] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:33:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:35] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:35] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:35] Decode batch. #running-req: 1, #token: 662, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.90, #queue-req: 0, 
[2025-09-30 14:33:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:35] Prefill batch. #new-seq: 1, #new-token: 1129, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:35] Prefill batch. #new-seq: 1, #new-token: 546, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:36] Decode batch. #running-req: 1, #token: 741, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.36, #queue-req: 0, 
[2025-09-30 14:33:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:36] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:36] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.02, #queue-req: 0, 
[2025-09-30 14:33:36] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:33:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:37] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:37] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:37] Decode batch. #running-req: 1, #token: 619, token usage: 0.01, cuda graph: True, gen throughput (token/s): 106.69, #queue-req: 0, 
[2025-09-30 14:33:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:37] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:37] Prefill batch. #new-seq: 1, #new-token: 504, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:38] Decode batch. #running-req: 1, #token: 685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-09-30 14:33:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:38] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:38] Decode batch. #running-req: 1, #token: 263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:33:38] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.32, #queue-req: 0, 
[2025-09-30 14:33:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:39] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:39] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:39] Decode batch. #running-req: 1, #token: 588, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.78, #queue-req: 0, 
[2025-09-30 14:33:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:39] Prefill batch. #new-seq: 1, #new-token: 1098, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:39] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:39] Decode batch. #running-req: 1, #token: 824, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.62, #queue-req: 0, 
[2025-09-30 14:33:40] Decode batch. #running-req: 1, #token: 864, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.99, #queue-req: 0, 
[2025-09-30 14:33:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:40] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:40] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.63, #queue-req: 0, 
[2025-09-30 14:33:40] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:33:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:41] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:41] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:41] Prefill batch. #new-seq: 1, #new-token: 906, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:41] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:41] Decode batch. #running-req: 1, #token: 482, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.86, #queue-req: 0, 
[2025-09-30 14:33:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:42] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:42] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.97, #queue-req: 0, 
[2025-09-30 14:33:42] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.43, #queue-req: 0, 
[2025-09-30 14:33:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:43] Prefill batch. #new-seq: 1, #new-token: 424, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:43] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:43] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.75, #queue-req: 0, 
[2025-09-30 14:33:43] Decode batch. #running-req: 1, #token: 334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.42, #queue-req: 0, 
[2025-09-30 14:33:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:43] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:43] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.04, #queue-req: 0, 
[2025-09-30 14:33:44] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:33:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:44] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:44] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:44] Decode batch. #running-req: 1, #token: 195, token usage: 0.00, cuda graph: True, gen throughput (token/s): 103.76, #queue-req: 0, 
[2025-09-30 14:33:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:45] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:45] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:45] Decode batch. #running-req: 1, #token: 433, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.28, #queue-req: 0, 
[2025-09-30 14:33:45] Decode batch. #running-req: 1, #token: 473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.98, #queue-req: 0, 
[2025-09-30 14:33:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:46] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:46] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.71, #queue-req: 0, 
[2025-09-30 14:33:46] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:33:46] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:33:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:47] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:47] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 217, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:47] Decode batch. #running-req: 1, #token: 493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.40, #queue-req: 0, 
[2025-09-30 14:33:47] Decode batch. #running-req: 1, #token: 533, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.54, #queue-req: 0, 
[2025-09-30 14:33:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:48] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:48] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.56, #queue-req: 0, 
[2025-09-30 14:33:48] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:33:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:49] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:49] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:49] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.04, #queue-req: 0, 
[2025-09-30 14:33:49] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.83, #queue-req: 0, 
[2025-09-30 14:33:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:49] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:49] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.13, #queue-req: 0, 
[2025-09-30 14:33:50] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:33:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:50] Prefill batch. #new-seq: 1, #new-token: 1686, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:51] Decode batch. #running-req: 1, #token: 2061, token usage: 0.03, cuda graph: True, gen throughput (token/s): 46.75, #queue-req: 0, 
[2025-09-30 14:33:51] Decode batch. #running-req: 1, #token: 2101, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:33:51] Decode batch. #running-req: 1, #token: 2141, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:33:52] Decode batch. #running-req: 1, #token: 2181, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:33:52] Decode batch. #running-req: 1, #token: 2221, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.12, #queue-req: 0, 
[2025-09-30 14:33:52] Decode batch. #running-req: 1, #token: 2261, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.14, #queue-req: 0, 
[2025-09-30 14:33:53] Decode batch. #running-req: 1, #token: 2301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:33:53] Decode batch. #running-req: 1, #token: 2341, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.75, #queue-req: 0, 
[2025-09-30 14:33:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:53] Prefill batch. #new-seq: 1, #new-token: 1686, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:53] Decode batch. #running-req: 1, #token: 2032, token usage: 0.03, cuda graph: True, gen throughput (token/s): 97.89, #queue-req: 0, 
[2025-09-30 14:33:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:33:53] Prefill batch. #new-seq: 1, #new-token: 1014, #cached-token: 193, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:33:54] Decode batch. #running-req: 1, #token: 1241, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.23, #queue-req: 0, 
[2025-09-30 14:33:54] Decode batch. #running-req: 1, #token: 1281, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:33:54] Decode batch. #running-req: 1, #token: 1321, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.18, #queue-req: 0, 
[2025-09-30 14:33:55] Decode batch. #running-req: 1, #token: 1361, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.26, #queue-req: 0, 
[2025-09-30 14:33:55] Decode batch. #running-req: 1, #token: 1401, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:33:55] Decode batch. #running-req: 1, #token: 1441, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:33:55] Decode batch. #running-req: 1, #token: 1481, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.06, #queue-req: 0, 
[2025-09-30 14:33:56] Decode batch. #running-req: 1, #token: 1521, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:33:56] Decode batch. #running-req: 1, #token: 1561, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.72, #queue-req: 0, 
[2025-09-30 14:33:56] Decode batch. #running-req: 1, #token: 1601, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:33:57] Decode batch. #running-req: 1, #token: 1641, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:33:57] Decode batch. #running-req: 1, #token: 1681, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:33:57] Decode batch. #running-req: 1, #token: 1721, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.38, #queue-req: 0, 
[2025-09-30 14:33:58] Decode batch. #running-req: 1, #token: 1761, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.38, #queue-req: 0, 
[2025-09-30 14:33:58] Decode batch. #running-req: 1, #token: 1801, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.29, #queue-req: 0, 
[2025-09-30 14:33:58] Decode batch. #running-req: 1, #token: 1841, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:33:59] Decode batch. #running-req: 1, #token: 1881, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:33:59] Decode batch. #running-req: 1, #token: 1921, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:33:59] Decode batch. #running-req: 1, #token: 1961, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:34:00] Decode batch. #running-req: 1, #token: 2001, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:34:00] Decode batch. #running-req: 1, #token: 2041, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:34:00] Decode batch. #running-req: 1, #token: 2081, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.45, #queue-req: 0, 
[2025-09-30 14:34:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:01] Prefill batch. #new-seq: 1, #new-token: 869, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:01] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:01] Decode batch. #running-req: 1, #token: 749, token usage: 0.01, cuda graph: True, gen throughput (token/s): 52.29, #queue-req: 0, 
[2025-09-30 14:34:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:01] Prefill batch. #new-seq: 1, #new-token: 42, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:01] Decode batch. #running-req: 1, #token: 269, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.99, #queue-req: 0, 
[2025-09-30 14:34:02] Decode batch. #running-req: 1, #token: 309, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.24, #queue-req: 0, 
[2025-09-30 14:34:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:02] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:02] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.27, #queue-req: 0, 
[2025-09-30 14:34:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:02] Prefill batch. #new-seq: 1, #new-token: 563, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:03] Prefill batch. #new-seq: 1, #new-token: 992, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:03] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:03] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.45, #queue-req: 0, 
[2025-09-30 14:34:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:03] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:03] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:34:04] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:34:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:04] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:04] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:04] Decode batch. #running-req: 1, #token: 516, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.60, #queue-req: 0, 
[2025-09-30 14:34:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 499, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:05] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.63, #queue-req: 0, 
[2025-09-30 14:34:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:05] Prefill batch. #new-seq: 1, #new-token: 867, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:05] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:05] Decode batch. #running-req: 1, #token: 661, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.17, #queue-req: 0, 
[2025-09-30 14:34:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:05] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:06] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.38, #queue-req: 0, 
[2025-09-30 14:34:06] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:34:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:06] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:06] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.34, #queue-req: 0, 
[2025-09-30 14:34:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:06] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:07] Prefill batch. #new-seq: 1, #new-token: 839, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:07] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:07] Decode batch. #running-req: 1, #token: 580, token usage: 0.01, cuda graph: True, gen throughput (token/s): 55.12, #queue-req: 0, 
[2025-09-30 14:34:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:07] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:07] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.42, #queue-req: 0, 
[2025-09-30 14:34:08] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:34:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:08] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:08] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:08] Decode batch. #running-req: 1, #token: 462, token usage: 0.01, cuda graph: True, gen throughput (token/s): 74.37, #queue-req: 0, 
[2025-09-30 14:34:09] Decode batch. #running-req: 1, #token: 502, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.89, #queue-req: 0, 
[2025-09-30 14:34:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:09] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:09] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:34:09] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:34:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:09] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:09] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:10] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.53, #queue-req: 0, 
[2025-09-30 14:34:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:10] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:10] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 296, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:10] Decode batch. #running-req: 1, #token: 321, token usage: 0.01, cuda graph: True, gen throughput (token/s): 60.00, #queue-req: 0, 
[2025-09-30 14:34:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:11] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:11] Prefill batch. #new-seq: 1, #new-token: 411, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:11] Decode batch. #running-req: 1, #token: 606, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.49, #queue-req: 0, 
[2025-09-30 14:34:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:11] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:11] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.03, #queue-req: 0, 
[2025-09-30 14:34:12] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.57, #queue-req: 0, 
[2025-09-30 14:34:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:12] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:12] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.35, #queue-req: 0, 
[2025-09-30 14:34:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:12] Prefill batch. #new-seq: 1, #new-token: 407, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:13] Prefill batch. #new-seq: 1, #new-token: 840, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:13] Prefill batch. #new-seq: 1, #new-token: 435, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:13] Decode batch. #running-req: 1, #token: 609, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.64, #queue-req: 0, 
[2025-09-30 14:34:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:13] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:13] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:34:13] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:34:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:14] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:14] Prefill batch. #new-seq: 1, #new-token: 431, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:14] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.56, #queue-req: 0, 
[2025-09-30 14:34:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:14] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 503, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:14] Decode batch. #running-req: 1, #token: 508, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.49, #queue-req: 0, 
[2025-09-30 14:34:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:15] Prefill batch. #new-seq: 1, #new-token: 1136, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:15] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:15] Decode batch. #running-req: 1, #token: 889, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.14, #queue-req: 0, 
[2025-09-30 14:34:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:15] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:15] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.35, #queue-req: 0, 
[2025-09-30 14:34:16] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:34:16] Decode batch. #running-req: 1, #token: 339, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:34:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:16] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:16] Prefill batch. #new-seq: 1, #new-token: 704, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:17] Decode batch. #running-req: 1, #token: 782, token usage: 0.01, cuda graph: True, gen throughput (token/s): 98.19, #queue-req: 0, 
[2025-09-30 14:34:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:17] Prefill batch. #new-seq: 1, #new-token: 1236, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:17] Prefill batch. #new-seq: 1, #new-token: 533, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:17] Decode batch. #running-req: 1, #token: 717, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.42, #queue-req: 0, 
[2025-09-30 14:34:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:17] Prefill batch. #new-seq: 1, #new-token: 57, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:18] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:34:18] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:34:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:18] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:18] Prefill batch. #new-seq: 1, #new-token: 529, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:18] Decode batch. #running-req: 1, #token: 615, token usage: 0.01, cuda graph: True, gen throughput (token/s): 100.42, #queue-req: 0, 
[2025-09-30 14:34:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:19] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 602, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:19] Decode batch. #running-req: 1, #token: 612, token usage: 0.01, cuda graph: True, gen throughput (token/s): 58.88, #queue-req: 0, 
[2025-09-30 14:34:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:20] Prefill batch. #new-seq: 1, #new-token: 1009, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:20] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:20] Decode batch. #running-req: 1, #token: 669, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.29, #queue-req: 0, 
[2025-09-30 14:34:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:20] Prefill batch. #new-seq: 1, #new-token: 46, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:20] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.58, #queue-req: 0, 
[2025-09-30 14:34:20] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:34:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:21] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:21] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:21] Decode batch. #running-req: 1, #token: 555, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.30, #queue-req: 0, 
[2025-09-30 14:34:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:21] Prefill batch. #new-seq: 1, #new-token: 1012, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:22] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:22] Decode batch. #running-req: 1, #token: 743, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.77, #queue-req: 0, 
[2025-09-30 14:34:22] Decode batch. #running-req: 1, #token: 783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.21, #queue-req: 0, 
[2025-09-30 14:34:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:22] Prefill batch. #new-seq: 1, #new-token: 60, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:22] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.61, #queue-req: 0, 
[2025-09-30 14:34:23] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:34:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:23] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:23] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:23] Decode batch. #running-req: 1, #token: 618, token usage: 0.01, cuda graph: True, gen throughput (token/s): 69.84, #queue-req: 0, 
[2025-09-30 14:34:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:24] Prefill batch. #new-seq: 1, #new-token: 1176, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:24] Prefill batch. #new-seq: 1, #new-token: 646, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:24] Decode batch. #running-req: 1, #token: 833, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.63, #queue-req: 0, 
[2025-09-30 14:34:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:24] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:24] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.55, #queue-req: 0, 
[2025-09-30 14:34:25] Decode batch. #running-req: 1, #token: 355, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.21, #queue-req: 0, 
[2025-09-30 14:34:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:25] Prefill batch. #new-seq: 1, #new-token: 747, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:25] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:25] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 57.67, #queue-req: 0, 
[2025-09-30 14:34:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:25] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:26] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.85, #queue-req: 0, 
[2025-09-30 14:34:26] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:34:26] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:34:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:26] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:26] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:27] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:27] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.56, #queue-req: 0, 
[2025-09-30 14:34:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:27] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:27] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:27] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 115.34, #queue-req: 0, 
[2025-09-30 14:34:28] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.65, #queue-req: 0, 
[2025-09-30 14:34:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:28] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:28] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:28] Decode batch. #running-req: 1, #token: 182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 109.10, #queue-req: 0, 
[2025-09-30 14:34:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:29] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:29] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:29] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.93, #queue-req: 0, 
[2025-09-30 14:34:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:29] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:29] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.25, #queue-req: 0, 
[2025-09-30 14:34:30] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:34:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:30] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:30] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:30] Decode batch. #running-req: 1, #token: 231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 112.01, #queue-req: 0, 
[2025-09-30 14:34:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:30] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:30] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 228, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:31] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.69, #queue-req: 0, 
[2025-09-30 14:34:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:31] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:31] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:31] Decode batch. #running-req: 1, #token: 352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 59.50, #queue-req: 0, 
[2025-09-30 14:34:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:31] Prefill batch. #new-seq: 1, #new-token: 53, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:32] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.15, #queue-req: 0, 
[2025-09-30 14:34:32] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:34:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:32] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:32] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:32] Decode batch. #running-req: 1, #token: 245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.91, #queue-req: 0, 
[2025-09-30 14:34:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:33] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:33] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:33] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.77, #queue-req: 0, 
[2025-09-30 14:34:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:33] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:33] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.18, #queue-req: 0, 
[2025-09-30 14:34:34] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:34:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:34] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:34] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.88, #queue-req: 0, 
[2025-09-30 14:34:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:34] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:35] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:35] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:35] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.65, #queue-req: 0, 
[2025-09-30 14:34:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:35] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:35] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.74, #queue-req: 0, 
[2025-09-30 14:34:36] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:34:36] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:34:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:36] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:36] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:36] Decode batch. #running-req: 1, #token: 228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 108.08, #queue-req: 0, 
[2025-09-30 14:34:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:37] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:37] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:37] Decode batch. #running-req: 1, #token: 357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.11, #queue-req: 0, 
[2025-09-30 14:34:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:37] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:37] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.96, #queue-req: 0, 
[2025-09-30 14:34:38] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:34:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:38] Prefill batch. #new-seq: 1, #new-token: 441, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:38] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:38] Decode batch. #running-req: 1, #token: 454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.54, #queue-req: 0, 
[2025-09-30 14:34:39] Decode batch. #running-req: 1, #token: 494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.95, #queue-req: 0, 
[2025-09-30 14:34:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:39] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:39] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.90, #queue-req: 0, 
[2025-09-30 14:34:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:39] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:39] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:39] Decode batch. #running-req: 1, #token: 369, token usage: 0.01, cuda graph: True, gen throughput (token/s): 104.50, #queue-req: 0, 
[2025-09-30 14:34:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:40] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:40] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:40] Decode batch. #running-req: 1, #token: 436, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.93, #queue-req: 0, 
[2025-09-30 14:34:41] Decode batch. #running-req: 1, #token: 476, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.97, #queue-req: 0, 
[2025-09-30 14:34:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:41] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.44, #queue-req: 0, 
[2025-09-30 14:34:41] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:34:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:42] Prefill batch. #new-seq: 1, #new-token: 397, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:42] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:42] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.55, #queue-req: 0, 
[2025-09-30 14:34:42] Decode batch. #running-req: 1, #token: 510, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.85, #queue-req: 0, 
[2025-09-30 14:34:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:42] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:43] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.71, #queue-req: 0, 
[2025-09-30 14:34:43] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.51, #queue-req: 0, 
[2025-09-30 14:34:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:43] Prefill batch. #new-seq: 1, #new-token: 484, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:43] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:44] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.96, #queue-req: 0, 
[2025-09-30 14:34:44] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.64, #queue-req: 0, 
[2025-09-30 14:34:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:44] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:44] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.73, #queue-req: 0, 
[2025-09-30 14:34:44] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:34:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:45] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:45] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:45] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.31, #queue-req: 0, 
[2025-09-30 14:34:45] Prefill batch. #new-seq: 1, #new-token: 674, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:45] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:46] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:46] Decode batch. #running-req: 1, #token: 241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.54, #queue-req: 0, 
[2025-09-30 14:34:46] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:34:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:46] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:47] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:47] Decode batch. #running-req: 1, #token: 461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 73.57, #queue-req: 0, 
[2025-09-30 14:34:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:47] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:47] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:47] Decode batch. #running-req: 1, #token: 421, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.04, #queue-req: 0, 
[2025-09-30 14:34:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:47] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:48] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:34:48] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:34:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:48] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:48] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 120.76, #queue-req: 0, 
[2025-09-30 14:34:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:48] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:49] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:49] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 304, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:49] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 54.09, #queue-req: 0, 
[2025-09-30 14:34:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:49] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:50] Decode batch. #running-req: 1, #token: 1147, token usage: 0.02, cuda graph: True, gen throughput (token/s): 58.57, #queue-req: 0, 
[2025-09-30 14:34:50] Decode batch. #running-req: 1, #token: 1187, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.77, #queue-req: 0, 
[2025-09-30 14:34:50] Decode batch. #running-req: 1, #token: 1227, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:34:51] Decode batch. #running-req: 1, #token: 1267, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.70, #queue-req: 0, 
[2025-09-30 14:34:51] Decode batch. #running-req: 1, #token: 1307, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.37, #queue-req: 0, 
[2025-09-30 14:34:51] Decode batch. #running-req: 1, #token: 1347, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:34:52] Decode batch. #running-req: 1, #token: 1387, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:34:52] Decode batch. #running-req: 1, #token: 1427, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:34:52] Decode batch. #running-req: 1, #token: 1467, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:34:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:52] Prefill batch. #new-seq: 1, #new-token: 769, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:52] Decode batch. #running-req: 1, #token: 1107, token usage: 0.02, cuda graph: True, gen throughput (token/s): 111.33, #queue-req: 0, 
[2025-09-30 14:34:53] Decode batch. #running-req: 1, #token: 1147, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:34:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:34:53] Prefill batch. #new-seq: 1, #new-token: 1031, #cached-token: 371, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:34:53] Decode batch. #running-req: 1, #token: 1430, token usage: 0.02, cuda graph: True, gen throughput (token/s): 108.29, #queue-req: 0, 
[2025-09-30 14:34:53] Decode batch. #running-req: 1, #token: 1470, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:34:54] Decode batch. #running-req: 1, #token: 1510, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.07, #queue-req: 0, 
[2025-09-30 14:34:54] Decode batch. #running-req: 1, #token: 1550, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.97, #queue-req: 0, 
[2025-09-30 14:34:54] Decode batch. #running-req: 1, #token: 1590, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.65, #queue-req: 0, 
[2025-09-30 14:34:55] Decode batch. #running-req: 1, #token: 1630, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.58, #queue-req: 0, 
[2025-09-30 14:34:55] Decode batch. #running-req: 1, #token: 1670, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.47, #queue-req: 0, 
[2025-09-30 14:34:55] Decode batch. #running-req: 1, #token: 1710, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:34:56] Decode batch. #running-req: 1, #token: 1750, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.41, #queue-req: 0, 
[2025-09-30 14:34:56] Decode batch. #running-req: 1, #token: 1790, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.44, #queue-req: 0, 
[2025-09-30 14:34:56] Decode batch. #running-req: 1, #token: 1830, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:34:57] Decode batch. #running-req: 1, #token: 1870, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:34:57] Decode batch. #running-req: 1, #token: 1910, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.85, #queue-req: 0, 
[2025-09-30 14:34:57] Decode batch. #running-req: 1, #token: 1950, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:34:58] Decode batch. #running-req: 1, #token: 1990, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:34:58] Decode batch. #running-req: 1, #token: 2030, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:34:58] Decode batch. #running-req: 1, #token: 2070, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.54, #queue-req: 0, 
[2025-09-30 14:34:58] Decode batch. #running-req: 1, #token: 2110, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:34:59] Decode batch. #running-req: 1, #token: 2150, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.34, #queue-req: 0, 
[2025-09-30 14:34:59] Decode batch. #running-req: 1, #token: 2190, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:34:59] Decode batch. #running-req: 1, #token: 2230, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.27, #queue-req: 0, 
[2025-09-30 14:35:00] Decode batch. #running-req: 1, #token: 2270, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:35:00] Decode batch. #running-req: 1, #token: 2310, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:35:00] Decode batch. #running-req: 1, #token: 2350, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.78, #queue-req: 0, 
[2025-09-30 14:35:01] Decode batch. #running-req: 1, #token: 2390, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:35:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:01] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:01] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:01] Decode batch. #running-req: 1, #token: 492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.63, #queue-req: 0, 
[2025-09-30 14:35:02] Decode batch. #running-req: 1, #token: 532, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.57, #queue-req: 0, 
[2025-09-30 14:35:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:02] Prefill batch. #new-seq: 1, #new-token: 47, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:02] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.76, #queue-req: 0, 
[2025-09-30 14:35:02] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:35:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:03] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:03] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:03] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 111.03, #queue-req: 0, 
[2025-09-30 14:35:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:03] Prefill batch. #new-seq: 1, #new-token: 679, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:03] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:04] Decode batch. #running-req: 1, #token: 617, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.39, #queue-req: 0, 
[2025-09-30 14:35:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:04] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:04] Decode batch. #running-req: 1, #token: 236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.92, #queue-req: 0, 
[2025-09-30 14:35:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:04] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:04] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.14, #queue-req: 0, 
[2025-09-30 14:35:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:04] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:05] Prefill batch. #new-seq: 1, #new-token: 735, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:05] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:05] Decode batch. #running-req: 1, #token: 490, token usage: 0.01, cuda graph: True, gen throughput (token/s): 53.22, #queue-req: 0, 
[2025-09-30 14:35:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:05] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:05] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.20, #queue-req: 0, 
[2025-09-30 14:35:06] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:35:06] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:35:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:06] Prefill batch. #new-seq: 1, #new-token: 758, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:06] Prefill batch. #new-seq: 1, #new-token: 509, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:06] Decode batch. #running-req: 1, #token: 693, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.78, #queue-req: 0, 
[2025-09-30 14:35:07] Decode batch. #running-req: 1, #token: 733, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.57, #queue-req: 0, 
[2025-09-30 14:35:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:07] Prefill batch. #new-seq: 1, #new-token: 50, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:07] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:35:07] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:35:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:08] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:08] Decode batch. #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.07, #queue-req: 0, 
[2025-09-30 14:35:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:08] Prefill batch. #new-seq: 1, #new-token: 448, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:08] Prefill batch. #new-seq: 1, #new-token: 577, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:08] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:09] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 52.71, #queue-req: 0, 
[2025-09-30 14:35:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:09] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:09] Decode batch. #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:35:09] Decode batch. #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.67, #queue-req: 0, 
[2025-09-30 14:35:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:10] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:35:10] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:10] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:10] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:10] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:10] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.69, #queue-req: 0, 
[2025-09-30 14:35:11] Decode batch. #running-req: 1, #token: 354, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.48, #queue-req: 0, 
[2025-09-30 14:35:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:11] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:11] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:35:11] Decode batch. #running-req: 1, #token: 318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:35:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:12] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:12] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:12] Decode batch. #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.71, #queue-req: 0, 
[2025-09-30 14:35:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:12] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:12] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 214, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:13] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 55.41, #queue-req: 0, 
[2025-09-30 14:35:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:13] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:13] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:13] Decode batch. #running-req: 1, #token: 371, token usage: 0.01, cuda graph: True, gen throughput (token/s): 57.38, #queue-req: 0, 
[2025-09-30 14:35:14] Decode batch. #running-req: 1, #token: 411, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.34, #queue-req: 0, 
[2025-09-30 14:35:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:14] Decode batch. #running-req: 1, #token: 233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.16, #queue-req: 0, 
[2025-09-30 14:35:14] Decode batch. #running-req: 1, #token: 273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:35:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:14] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:14] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:15] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 104.62, #queue-req: 0, 
[2025-09-30 14:35:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:15] Prefill batch. #new-seq: 1, #new-token: 639, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:15] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:15] Prefill batch. #new-seq: 1, #new-token: 49, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:15] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.92, #queue-req: 0, 
[2025-09-30 14:35:16] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:35:16] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:35:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:16] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:16] Prefill batch. #new-seq: 1, #new-token: 494, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:16] Decode batch. #running-req: 1, #token: 578, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.83, #queue-req: 0, 
[2025-09-30 14:35:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:17] Prefill batch. #new-seq: 1, #new-token: 900, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:17] Prefill batch. #new-seq: 1, #new-token: 408, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:17] Decode batch. #running-req: 1, #token: 591, token usage: 0.01, cuda graph: True, gen throughput (token/s): 42.17, #queue-req: 0, 
[2025-09-30 14:35:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:18] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:18] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.92, #queue-req: 0, 
[2025-09-30 14:35:18] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:35:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:19] Prefill batch. #new-seq: 1, #new-token: 1042, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:19] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.73, #queue-req: 0, 
[2025-09-30 14:35:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:19] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:19] Prefill batch. #new-seq: 1, #new-token: 38, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:19] Decode batch. #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.68, #queue-req: 0, 
[2025-09-30 14:35:19] Decode batch. #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.42, #queue-req: 0, 
[2025-09-30 14:35:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:20] Prefill batch. #new-seq: 1, #new-token: 1307, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:20] Prefill batch. #new-seq: 1, #new-token: 671, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:20] Decode batch. #running-req: 1, #token: 845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.17, #queue-req: 0, 
[2025-09-30 14:35:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:20] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:21] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.98, #queue-req: 0, 
[2025-09-30 14:35:21] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:35:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:21] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:21] Prefill batch. #new-seq: 1, #new-token: 669, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:21] Decode batch. #running-req: 1, #token: 760, token usage: 0.01, cuda graph: True, gen throughput (token/s): 97.85, #queue-req: 0, 
[2025-09-30 14:35:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:22] Prefill batch. #new-seq: 1, #new-token: 1052, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:22] Decode batch. #running-req: 1, #token: 1423, token usage: 0.02, cuda graph: True, gen throughput (token/s): 43.13, #queue-req: 0, 
[2025-09-30 14:35:23] Decode batch. #running-req: 1, #token: 1463, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.09, #queue-req: 0, 
[2025-09-30 14:35:23] Decode batch. #running-req: 1, #token: 1503, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:35:23] Decode batch. #running-req: 1, #token: 1543, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.99, #queue-req: 0, 
[2025-09-30 14:35:23] Decode batch. #running-req: 1, #token: 1583, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.58, #queue-req: 0, 
[2025-09-30 14:35:24] Decode batch. #running-req: 1, #token: 1623, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.52, #queue-req: 0, 
[2025-09-30 14:35:24] Decode batch. #running-req: 1, #token: 1663, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:35:24] Decode batch. #running-req: 1, #token: 1703, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.51, #queue-req: 0, 
[2025-09-30 14:35:25] Decode batch. #running-req: 1, #token: 1743, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.42, #queue-req: 0, 
[2025-09-30 14:35:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:25] Prefill batch. #new-seq: 1, #new-token: 1052, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:25] Decode batch. #running-req: 1, #token: 1402, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.44, #queue-req: 0, 
[2025-09-30 14:35:25] Decode batch. #running-req: 1, #token: 1442, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:35:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:26] Prefill batch. #new-seq: 1, #new-token: 1140, #cached-token: 330, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:26] Decode batch. #running-req: 1, #token: 1498, token usage: 0.02, cuda graph: True, gen throughput (token/s): 106.75, #queue-req: 0, 
[2025-09-30 14:35:26] Decode batch. #running-req: 1, #token: 1538, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:35:26] Decode batch. #running-req: 1, #token: 1578, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.58, #queue-req: 0, 
[2025-09-30 14:35:27] Decode batch. #running-req: 1, #token: 1618, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:35:27] Decode batch. #running-req: 1, #token: 1658, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.57, #queue-req: 0, 
[2025-09-30 14:35:27] Decode batch. #running-req: 1, #token: 1698, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.48, #queue-req: 0, 
[2025-09-30 14:35:28] Decode batch. #running-req: 1, #token: 1738, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.45, #queue-req: 0, 
[2025-09-30 14:35:28] Decode batch. #running-req: 1, #token: 1778, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:35:28] Decode batch. #running-req: 1, #token: 1818, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.10, #queue-req: 0, 
[2025-09-30 14:35:29] Decode batch. #running-req: 1, #token: 1858, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.91, #queue-req: 0, 
[2025-09-30 14:35:29] Decode batch. #running-req: 1, #token: 1898, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:35:29] Decode batch. #running-req: 1, #token: 1938, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:35:30] Decode batch. #running-req: 1, #token: 1978, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:35:30] Decode batch. #running-req: 1, #token: 2018, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.80, #queue-req: 0, 
[2025-09-30 14:35:30] Decode batch. #running-req: 1, #token: 2058, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.72, #queue-req: 0, 
[2025-09-30 14:35:30] Decode batch. #running-req: 1, #token: 2098, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:35:31] Decode batch. #running-req: 1, #token: 2138, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:35:31] Decode batch. #running-req: 1, #token: 2178, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:35:31] Decode batch. #running-req: 1, #token: 2218, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:35:32] Decode batch. #running-req: 1, #token: 2258, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:35:32] Decode batch. #running-req: 1, #token: 2298, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:35:32] Decode batch. #running-req: 1, #token: 2338, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.85, #queue-req: 0, 
[2025-09-30 14:35:33] Decode batch. #running-req: 1, #token: 2378, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.76, #queue-req: 0, 
[2025-09-30 14:35:33] Decode batch. #running-req: 1, #token: 2418, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.74, #queue-req: 0, 
[2025-09-30 14:35:33] Decode batch. #running-req: 1, #token: 2458, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:35:34] Decode batch. #running-req: 1, #token: 2498, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:35:34] Decode batch. #running-req: 1, #token: 2538, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:35:34] Decode batch. #running-req: 1, #token: 2578, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.43, #queue-req: 0, 
[2025-09-30 14:35:35] Decode batch. #running-req: 1, #token: 2618, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:35:35] Decode batch. #running-req: 1, #token: 2658, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.12, #queue-req: 0, 
[2025-09-30 14:35:35] Decode batch. #running-req: 1, #token: 2698, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.05, #queue-req: 0, 
[2025-09-30 14:35:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:36] Prefill batch. #new-seq: 1, #new-token: 1459, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:36] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:36] Decode batch. #running-req: 1, #token: 976, token usage: 0.02, cuda graph: True, gen throughput (token/s): 45.70, #queue-req: 0, 
[2025-09-30 14:35:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:36] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:36] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.00, #queue-req: 0, 
[2025-09-30 14:35:37] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:35:37] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.26, #queue-req: 0, 
[2025-09-30 14:35:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:38] Prefill batch. #new-seq: 1, #new-token: 1381, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:38] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:38] Decode batch. #running-req: 1, #token: 777, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.98, #queue-req: 0, 
[2025-09-30 14:35:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:38] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:38] Decode batch. #running-req: 1, #token: 234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.35, #queue-req: 0, 
[2025-09-30 14:35:38] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:35:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:39] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:39] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.68, #queue-req: 0, 
[2025-09-30 14:35:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:39] Prefill batch. #new-seq: 1, #new-token: 588, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:40] Prefill batch. #new-seq: 1, #new-token: 711, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:40] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:40] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.96, #queue-req: 0, 
[2025-09-30 14:35:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:40] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:40] Decode batch. #running-req: 1, #token: 221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.93, #queue-req: 0, 
[2025-09-30 14:35:40] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:35:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:41] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:41] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:41] Decode batch. #running-req: 1, #token: 197, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.11, #queue-req: 0, 
[2025-09-30 14:35:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:42] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:42] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:42] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.51, #queue-req: 0, 
[2025-09-30 14:35:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:42] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:42] Decode batch. #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.68, #queue-req: 0, 
[2025-09-30 14:35:42] Decode batch. #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:35:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:43] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:43] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:43] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 105.68, #queue-req: 0, 
[2025-09-30 14:35:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:43] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:43] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:44] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.92, #queue-req: 0, 
[2025-09-30 14:35:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:44] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:44] Decode batch. #running-req: 1, #token: 244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.57, #queue-req: 0, 
[2025-09-30 14:35:44] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.48, #queue-req: 0, 
[2025-09-30 14:35:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:45] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:45] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 181, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:45] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 52.58, #queue-req: 0, 
[2025-09-30 14:35:45] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.54, #queue-req: 0, 
[2025-09-30 14:35:46] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 132.40, #queue-req: 0, 
[2025-09-30 14:35:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:46] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:46] Decode batch. #running-req: 1, #token: 258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.21, #queue-req: 0, 
[2025-09-30 14:35:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:47] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:47] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:47] Decode batch. #running-req: 1, #token: 487, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.08, #queue-req: 0, 
[2025-09-30 14:35:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:47] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:47] Decode batch. #running-req: 1, #token: 243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.21, #queue-req: 0, 
[2025-09-30 14:35:47] Decode batch. #running-req: 1, #token: 283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:35:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:48] Prefill batch. #new-seq: 1, #new-token: 384, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:48] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:48] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 51.70, #queue-req: 0, 
[2025-09-30 14:35:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:48] Prefill batch. #new-seq: 1, #new-token: 24, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:48] Decode batch. #running-req: 1, #token: 237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.70, #queue-req: 0, 
[2025-09-30 14:35:49] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.50, #queue-req: 0, 
[2025-09-30 14:35:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:49] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:49] Prefill batch. #new-seq: 1, #new-token: 61, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:49] Decode batch. #running-req: 1, #token: 153, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.20, #queue-req: 0, 
[2025-09-30 14:35:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:50] Prefill batch. #new-seq: 1, #new-token: 1064, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:50] Decode batch. #running-req: 1, #token: 1437, token usage: 0.02, cuda graph: True, gen throughput (token/s): 53.11, #queue-req: 0, 
[2025-09-30 14:35:50] Decode batch. #running-req: 1, #token: 1477, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:35:51] Decode batch. #running-req: 1, #token: 1517, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.05, #queue-req: 0, 
[2025-09-30 14:35:51] Decode batch. #running-req: 1, #token: 1557, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.83, #queue-req: 0, 
[2025-09-30 14:35:51] Decode batch. #running-req: 1, #token: 1597, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.55, #queue-req: 0, 
[2025-09-30 14:35:52] Decode batch. #running-req: 1, #token: 1637, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.49, #queue-req: 0, 
[2025-09-30 14:35:52] Decode batch. #running-req: 1, #token: 1677, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.43, #queue-req: 0, 
[2025-09-30 14:35:52] Decode batch. #running-req: 1, #token: 1717, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.46, #queue-req: 0, 
[2025-09-30 14:35:53] Decode batch. #running-req: 1, #token: 1757, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.50, #queue-req: 0, 
[2025-09-30 14:35:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:53] Prefill batch. #new-seq: 1, #new-token: 1064, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:53] Decode batch. #running-req: 1, #token: 1408, token usage: 0.02, cuda graph: True, gen throughput (token/s): 107.26, #queue-req: 0, 
[2025-09-30 14:35:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:35:53] Prefill batch. #new-seq: 1, #new-token: 1613, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:35:53] Decode batch. #running-req: 1, #token: 1776, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.69, #queue-req: 0, 
[2025-09-30 14:35:54] Decode batch. #running-req: 1, #token: 1816, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.19, #queue-req: 0, 
[2025-09-30 14:35:54] Decode batch. #running-req: 1, #token: 1856, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:35:54] Decode batch. #running-req: 1, #token: 1896, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.95, #queue-req: 0, 
[2025-09-30 14:35:55] Decode batch. #running-req: 1, #token: 1936, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:35:55] Decode batch. #running-req: 1, #token: 1976, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:35:55] Decode batch. #running-req: 1, #token: 2016, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:35:56] Decode batch. #running-req: 1, #token: 2056, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.68, #queue-req: 0, 
[2025-09-30 14:35:56] Decode batch. #running-req: 1, #token: 2096, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:35:56] Decode batch. #running-req: 1, #token: 2136, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:35:56] Decode batch. #running-req: 1, #token: 2176, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:35:57] Decode batch. #running-req: 1, #token: 2216, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:35:57] Decode batch. #running-req: 1, #token: 2256, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:35:57] Decode batch. #running-req: 1, #token: 2296, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:35:58] Decode batch. #running-req: 1, #token: 2336, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.80, #queue-req: 0, 
[2025-09-30 14:35:58] Decode batch. #running-req: 1, #token: 2376, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.67, #queue-req: 0, 
[2025-09-30 14:35:58] Decode batch. #running-req: 1, #token: 2416, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:35:59] Decode batch. #running-req: 1, #token: 2456, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.62, #queue-req: 0, 
[2025-09-30 14:35:59] Decode batch. #running-req: 1, #token: 2496, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:35:59] Decode batch. #running-req: 1, #token: 2536, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:36:00] Decode batch. #running-req: 1, #token: 2576, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.41, #queue-req: 0, 
[2025-09-30 14:36:00] Decode batch. #running-req: 1, #token: 2616, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:36:00] Decode batch. #running-req: 1, #token: 2656, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:36:01] Decode batch. #running-req: 1, #token: 2696, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:36:01] Decode batch. #running-req: 1, #token: 2736, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:36:01] Decode batch. #running-req: 1, #token: 2776, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:36:02] Decode batch. #running-req: 1, #token: 2816, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.05, #queue-req: 0, 
[2025-09-30 14:36:02] Decode batch. #running-req: 1, #token: 2856, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:36:02] Decode batch. #running-req: 1, #token: 2896, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:36:02] Decode batch. #running-req: 1, #token: 2936, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.45, #queue-req: 0, 
[2025-09-30 14:36:03] Decode batch. #running-req: 1, #token: 2976, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.44, #queue-req: 0, 
[2025-09-30 14:36:03] Decode batch. #running-req: 1, #token: 3016, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:36:03] Decode batch. #running-req: 1, #token: 3056, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:36:04] Decode batch. #running-req: 1, #token: 3096, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.13, #queue-req: 0, 
[2025-09-30 14:36:04] Decode batch. #running-req: 1, #token: 3136, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.88, #queue-req: 0, 
[2025-09-30 14:36:04] Decode batch. #running-req: 1, #token: 3176, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.88, #queue-req: 0, 
[2025-09-30 14:36:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:05] Prefill batch. #new-seq: 1, #new-token: 644, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:05] Prefill batch. #new-seq: 1, #new-token: 584, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:05] Decode batch. #running-req: 1, #token: 774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.55, #queue-req: 0, 
[2025-09-30 14:36:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:05] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:06] Decode batch. #running-req: 1, #token: 303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.01, #queue-req: 0, 
[2025-09-30 14:36:06] Decode batch. #running-req: 1, #token: 343, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:36:06] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.12, #queue-req: 0, 
[2025-09-30 14:36:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:06] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:06] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:07] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:07] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.41, #queue-req: 0, 
[2025-09-30 14:36:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:07] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 652, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:08] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:08] Decode batch. #running-req: 1, #token: 994, token usage: 0.02, cuda graph: True, gen throughput (token/s): 43.00, #queue-req: 0, 
[2025-09-30 14:36:08] Decode batch. #running-req: 1, #token: 1034, token usage: 0.02, cuda graph: True, gen throughput (token/s): 130.28, #queue-req: 0, 
[2025-09-30 14:36:09] Decode batch. #running-req: 1, #token: 1074, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.91, #queue-req: 0, 
[2025-09-30 14:36:09] Decode batch. #running-req: 1, #token: 1114, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.89, #queue-req: 0, 
[2025-09-30 14:36:09] Decode batch. #running-req: 1, #token: 1154, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.80, #queue-req: 0, 
[2025-09-30 14:36:09] Decode batch. #running-req: 1, #token: 1194, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.79, #queue-req: 0, 
[2025-09-30 14:36:10] Decode batch. #running-req: 1, #token: 1234, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.71, #queue-req: 0, 
[2025-09-30 14:36:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:10] Prefill batch. #new-seq: 1, #new-token: 652, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:10] Decode batch. #running-req: 1, #token: 981, token usage: 0.02, cuda graph: True, gen throughput (token/s): 113.68, #queue-req: 0, 
[2025-09-30 14:36:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:10] Prefill batch. #new-seq: 1, #new-token: 1759, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:11] Decode batch. #running-req: 1, #token: 1901, token usage: 0.03, cuda graph: True, gen throughput (token/s): 99.80, #queue-req: 0, 
[2025-09-30 14:36:11] Decode batch. #running-req: 1, #token: 1941, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.90, #queue-req: 0, 
[2025-09-30 14:36:11] Decode batch. #running-req: 1, #token: 1981, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:36:11] Decode batch. #running-req: 1, #token: 2021, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:36:12] Decode batch. #running-req: 1, #token: 2061, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:36:12] Decode batch. #running-req: 1, #token: 2101, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.34, #queue-req: 0, 
[2025-09-30 14:36:12] Decode batch. #running-req: 1, #token: 2141, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.29, #queue-req: 0, 
[2025-09-30 14:36:13] Decode batch. #running-req: 1, #token: 2181, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.19, #queue-req: 0, 
[2025-09-30 14:36:13] Decode batch. #running-req: 1, #token: 2221, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:36:13] Decode batch. #running-req: 1, #token: 2261, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:36:14] Decode batch. #running-req: 1, #token: 2301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:36:14] Decode batch. #running-req: 1, #token: 2341, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.73, #queue-req: 0, 
[2025-09-30 14:36:14] Decode batch. #running-req: 1, #token: 2381, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.63, #queue-req: 0, 
[2025-09-30 14:36:15] Decode batch. #running-req: 1, #token: 2421, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:36:15] Decode batch. #running-req: 1, #token: 2461, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:36:15] Decode batch. #running-req: 1, #token: 2501, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:36:16] Decode batch. #running-req: 1, #token: 2541, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.61, #queue-req: 0, 
[2025-09-30 14:36:16] Decode batch. #running-req: 1, #token: 2581, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.34, #queue-req: 0, 
[2025-09-30 14:36:16] Decode batch. #running-req: 1, #token: 2621, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:36:17] Decode batch. #running-req: 1, #token: 2661, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:36:17] Decode batch. #running-req: 1, #token: 2701, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:36:17] Decode batch. #running-req: 1, #token: 2741, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:36:17] Decode batch. #running-req: 1, #token: 2781, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:36:18] Decode batch. #running-req: 1, #token: 2821, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.95, #queue-req: 0, 
[2025-09-30 14:36:18] Decode batch. #running-req: 1, #token: 2861, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.50, #queue-req: 0, 
[2025-09-30 14:36:18] Decode batch. #running-req: 1, #token: 2901, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:36:19] Decode batch. #running-req: 1, #token: 2941, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:36:19] Decode batch. #running-req: 1, #token: 2981, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.46, #queue-req: 0, 
[2025-09-30 14:36:19] Decode batch. #running-req: 1, #token: 3021, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 14:36:20] Decode batch. #running-req: 1, #token: 3061, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:36:20] Decode batch. #running-req: 1, #token: 3101, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:36:20] Decode batch. #running-req: 1, #token: 3141, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.86, #queue-req: 0, 
[2025-09-30 14:36:21] Decode batch. #running-req: 1, #token: 3181, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:36:21] Decode batch. #running-req: 1, #token: 3221, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.83, #queue-req: 0, 
[2025-09-30 14:36:21] Decode batch. #running-req: 1, #token: 3261, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:36:22] Decode batch. #running-req: 1, #token: 3301, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:36:22] Decode batch. #running-req: 1, #token: 3341, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.64, #queue-req: 0, 
[2025-09-30 14:36:22] Decode batch. #running-req: 1, #token: 3381, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.30, #queue-req: 0, 
[2025-09-30 14:36:23] Decode batch. #running-req: 1, #token: 3421, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.29, #queue-req: 0, 
[2025-09-30 14:36:23] Decode batch. #running-req: 1, #token: 3461, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.24, #queue-req: 0, 
[2025-09-30 14:36:23] Decode batch. #running-req: 1, #token: 3501, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.24, #queue-req: 0, 
[2025-09-30 14:36:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:24] Prefill batch. #new-seq: 1, #new-token: 1135, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:24] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:24] Decode batch. #running-req: 1, #token: 754, token usage: 0.01, cuda graph: True, gen throughput (token/s): 45.76, #queue-req: 0, 
[2025-09-30 14:36:24] Decode batch. #running-req: 1, #token: 794, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.19, #queue-req: 0, 
[2025-09-30 14:36:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:25] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:25] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.33, #queue-req: 0, 
[2025-09-30 14:36:25] Decode batch. #running-req: 1, #token: 292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.40, #queue-req: 0, 
[2025-09-30 14:36:25] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:36:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:25] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:25] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:25] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:26] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:27] Prefill batch. #new-seq: 1, #new-token: 1150, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:27] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 30.41, #queue-req: 0, 
[2025-09-30 14:36:27] Prefill batch. #new-seq: 1, #new-token: 708, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:27] Decode batch. #running-req: 1, #token: 901, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.21, #queue-req: 0, 
[2025-09-30 14:36:27] Decode batch. #running-req: 1, #token: 941, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.74, #queue-req: 0, 
[2025-09-30 14:36:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:27] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:28] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 14:36:28] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:36:28] Decode batch. #running-req: 1, #token: 350, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.19, #queue-req: 0, 
[2025-09-30 14:36:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:29] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:29] Prefill batch. #new-seq: 1, #new-token: 595, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:29] Decode batch. #running-req: 1, #token: 683, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.65, #queue-req: 0, 
[2025-09-30 14:36:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:30] Prefill batch. #new-seq: 1, #new-token: 1198, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:30] Prefill batch. #new-seq: 1, #new-token: 605, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:30] Decode batch. #running-req: 1, #token: 797, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.71, #queue-req: 0, 
[2025-09-30 14:36:30] Decode batch. #running-req: 1, #token: 837, token usage: 0.01, cuda graph: True, gen throughput (token/s): 129.93, #queue-req: 0, 
[2025-09-30 14:36:30] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:30] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:31] Decode batch. #running-req: 1, #token: 277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.55, #queue-req: 0, 
[2025-09-30 14:36:31] Decode batch. #running-req: 1, #token: 317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:36:31] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:32] Prefill batch. #new-seq: 1, #new-token: 935, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:32] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:32] Decode batch. #running-req: 1, #token: 520, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.23, #queue-req: 0, 
[2025-09-30 14:36:32] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:32] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:32] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.11, #queue-req: 0, 
[2025-09-30 14:36:32] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:36:33] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.13, #queue-req: 0, 
[2025-09-30 14:36:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:33] Prefill batch. #new-seq: 1, #new-token: 27, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:33] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:33] Decode batch. #running-req: 1, #token: 426, token usage: 0.01, cuda graph: True, gen throughput (token/s): 56.95, #queue-req: 0, 
[2025-09-30 14:36:33] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:34] Prefill batch. #new-seq: 1, #new-token: 645, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:34] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:34] Decode batch. #running-req: 1, #token: 506, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.19, #queue-req: 0, 
[2025-09-30 14:36:34] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:34] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:35] Decode batch. #running-req: 1, #token: 284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.00, #queue-req: 0, 
[2025-09-30 14:36:35] Decode batch. #running-req: 1, #token: 324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.25, #queue-req: 0, 
[2025-09-30 14:36:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:35] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:35] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:35] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.24, #queue-req: 0, 
[2025-09-30 14:36:35] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:36] Prefill batch. #new-seq: 1, #new-token: 510, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:36] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:36] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:37] Decode batch. #running-req: 1, #token: 394, token usage: 0.01, cuda graph: True, gen throughput (token/s): 32.62, #queue-req: 0, 
[2025-09-30 14:36:37] Decode batch. #running-req: 1, #token: 434, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.30, #queue-req: 0, 
[2025-09-30 14:36:37] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:37] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:37] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.07, #queue-req: 0, 
[2025-09-30 14:36:38] Decode batch. #running-req: 1, #token: 294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0, 
[2025-09-30 14:36:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:38] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:38] Decode batch. #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.82, #queue-req: 0, 
[2025-09-30 14:36:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:38] Prefill batch. #new-seq: 1, #new-token: 204, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:38] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:39] Prefill batch. #new-seq: 1, #new-token: 396, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:39] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:39] Decode batch. #running-req: 1, #token: 367, token usage: 0.01, cuda graph: True, gen throughput (token/s): 31.91, #queue-req: 0, 
[2025-09-30 14:36:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:39] Prefill batch. #new-seq: 1, #new-token: 33, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:39] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.62, #queue-req: 0, 
[2025-09-30 14:36:40] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.54, #queue-req: 0, 
[2025-09-30 14:36:40] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.34, #queue-req: 0, 
[2025-09-30 14:36:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:41] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:41] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:41] Decode batch. #running-req: 1, #token: 381, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.20, #queue-req: 0, 
[2025-09-30 14:36:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:41] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:41] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.09, #queue-req: 0, 
[2025-09-30 14:36:42] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:36:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:42] Prefill batch. #new-seq: 1, #new-token: 438, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:42] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:43] Decode batch. #running-req: 1, #token: 484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.52, #queue-req: 0, 
[2025-09-30 14:36:43] Decode batch. #running-req: 1, #token: 524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.65, #queue-req: 0, 
[2025-09-30 14:36:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:43] Prefill batch. #new-seq: 1, #new-token: 44, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:43] Decode batch. #running-req: 1, #token: 271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.17, #queue-req: 0, 
[2025-09-30 14:36:44] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:36:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:44] Prefill batch. #new-seq: 1, #new-token: 1768, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:45] Decode batch. #running-req: 1, #token: 2120, token usage: 0.03, cuda graph: True, gen throughput (token/s): 39.54, #queue-req: 0, 
[2025-09-30 14:36:45] Decode batch. #running-req: 1, #token: 2160, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:36:45] Decode batch. #running-req: 1, #token: 2200, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:36:45] Decode batch. #running-req: 1, #token: 2240, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:36:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:46] Prefill batch. #new-seq: 1, #new-token: 1768, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:46] Decode batch. #running-req: 1, #token: 2108, token usage: 0.03, cuda graph: True, gen throughput (token/s): 98.03, #queue-req: 0, 
[2025-09-30 14:36:46] Decode batch. #running-req: 1, #token: 2148, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.32, #queue-req: 0, 
[2025-09-30 14:36:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:46] Prefill batch. #new-seq: 1, #new-token: 1367, #cached-token: 497, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:47] Decode batch. #running-req: 1, #token: 1875, token usage: 0.03, cuda graph: True, gen throughput (token/s): 102.65, #queue-req: 0, 
[2025-09-30 14:36:47] Decode batch. #running-req: 1, #token: 1915, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:36:47] Decode batch. #running-req: 1, #token: 1955, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.86, #queue-req: 0, 
[2025-09-30 14:36:48] Decode batch. #running-req: 1, #token: 1995, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:36:48] Decode batch. #running-req: 1, #token: 2035, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:36:48] Decode batch. #running-req: 1, #token: 2075, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.46, #queue-req: 0, 
[2025-09-30 14:36:48] Decode batch. #running-req: 1, #token: 2115, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:36:49] Decode batch. #running-req: 1, #token: 2155, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:36:49] Decode batch. #running-req: 1, #token: 2195, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:36:49] Decode batch. #running-req: 1, #token: 2235, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:36:50] Decode batch. #running-req: 1, #token: 2275, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:36:50] Decode batch. #running-req: 1, #token: 2315, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.03, #queue-req: 0, 
[2025-09-30 14:36:50] Decode batch. #running-req: 1, #token: 2355, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.69, #queue-req: 0, 
[2025-09-30 14:36:51] Decode batch. #running-req: 1, #token: 2395, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:36:51] Decode batch. #running-req: 1, #token: 2435, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:36:51] Decode batch. #running-req: 1, #token: 2475, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:36:52] Decode batch. #running-req: 1, #token: 2515, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.63, #queue-req: 0, 
[2025-09-30 14:36:52] Decode batch. #running-req: 1, #token: 2555, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:36:52] Decode batch. #running-req: 1, #token: 2595, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.17, #queue-req: 0, 
[2025-09-30 14:36:53] Decode batch. #running-req: 1, #token: 2635, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.07, #queue-req: 0, 
[2025-09-30 14:36:53] Decode batch. #running-req: 1, #token: 2675, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.04, #queue-req: 0, 
[2025-09-30 14:36:53] Decode batch. #running-req: 1, #token: 2715, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:36:54] Decode batch. #running-req: 1, #token: 2755, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:36:54] Decode batch. #running-req: 1, #token: 2795, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:36:54] Decode batch. #running-req: 1, #token: 2835, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.72, #queue-req: 0, 
[2025-09-30 14:36:54] Decode batch. #running-req: 1, #token: 2875, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:36:55] Decode batch. #running-req: 1, #token: 2915, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.50, #queue-req: 0, 
[2025-09-30 14:36:55] Decode batch. #running-req: 1, #token: 2955, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.41, #queue-req: 0, 
[2025-09-30 14:36:55] Decode batch. #running-req: 1, #token: 2995, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.46, #queue-req: 0, 
[2025-09-30 14:36:56] Decode batch. #running-req: 1, #token: 3035, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.47, #queue-req: 0, 
[2025-09-30 14:36:56] Decode batch. #running-req: 1, #token: 3075, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 14:36:56] Decode batch. #running-req: 1, #token: 3115, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.85, #queue-req: 0, 
[2025-09-30 14:36:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:57] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:57] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 192, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:57] Decode batch. #running-req: 1, #token: 548, token usage: 0.01, cuda graph: True, gen throughput (token/s): 46.13, #queue-req: 0, 
[2025-09-30 14:36:58] Decode batch. #running-req: 1, #token: 588, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.12, #queue-req: 0, 
[2025-09-30 14:36:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:58] Prefill batch. #new-seq: 1, #new-token: 39, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:58] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.84, #queue-req: 0, 
[2025-09-30 14:36:58] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0, 
[2025-09-30 14:36:59] Decode batch. #running-req: 1, #token: 319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.37, #queue-req: 0, 
[2025-09-30 14:36:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:59] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:36:59] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:36:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:00] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:00] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:00] Decode batch. #running-req: 1, #token: 430, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.14, #queue-req: 0, 
[2025-09-30 14:37:00] Decode batch. #running-req: 1, #token: 470, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.01, #queue-req: 0, 
[2025-09-30 14:37:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:00] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:00] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.10, #queue-req: 0, 
[2025-09-30 14:37:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:01] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:01] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:01] Decode batch. #running-req: 1, #token: 333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 114.14, #queue-req: 0, 
[2025-09-30 14:37:01] Decode batch. #running-req: 1, #token: 373, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.36, #queue-req: 0, 
[2025-09-30 14:37:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:01] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:01] Decode batch. #running-req: 1, #token: 274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:37:02] Decode batch. #running-req: 1, #token: 314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.38, #queue-req: 0, 
[2025-09-30 14:37:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:02] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:02] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:03] Decode batch. #running-req: 1, #token: 475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.40, #queue-req: 0, 
[2025-09-30 14:37:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:03] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:03] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.44, #queue-req: 0, 
[2025-09-30 14:37:03] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:37:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:04] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:04] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:04] Decode batch. #running-req: 1, #token: 358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.52, #queue-req: 0, 
[2025-09-30 14:37:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:05] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:05] Decode batch. #running-req: 1, #token: 1918, token usage: 0.03, cuda graph: True, gen throughput (token/s): 31.06, #queue-req: 0, 
[2025-09-30 14:37:05] Decode batch. #running-req: 1, #token: 1958, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.78, #queue-req: 0, 
[2025-09-30 14:37:06] Decode batch. #running-req: 1, #token: 1998, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:37:06] Decode batch. #running-req: 1, #token: 2038, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:37:06] Decode batch. #running-req: 1, #token: 2078, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.44, #queue-req: 0, 
[2025-09-30 14:37:07] Decode batch. #running-req: 1, #token: 2118, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:37:07] Decode batch. #running-req: 1, #token: 2158, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:37:07] Decode batch. #running-req: 1, #token: 2198, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:37:08] Decode batch. #running-req: 1, #token: 2238, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.30, #queue-req: 0, 
[2025-09-30 14:37:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:08] Prefill batch. #new-seq: 1, #new-token: 1558, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:08] Decode batch. #running-req: 1, #token: 1916, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.80, #queue-req: 0, 
[2025-09-30 14:37:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:08] Prefill batch. #new-seq: 1, #new-token: 1528, #cached-token: 190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:08] Decode batch. #running-req: 1, #token: 1720, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.94, #queue-req: 0, 
[2025-09-30 14:37:09] Decode batch. #running-req: 1, #token: 1760, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:37:09] Decode batch. #running-req: 1, #token: 1800, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.39, #queue-req: 0, 
[2025-09-30 14:37:09] Decode batch. #running-req: 1, #token: 1840, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.89, #queue-req: 0, 
[2025-09-30 14:37:10] Decode batch. #running-req: 1, #token: 1880, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.98, #queue-req: 0, 
[2025-09-30 14:37:10] Decode batch. #running-req: 1, #token: 1920, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.84, #queue-req: 0, 
[2025-09-30 14:37:10] Decode batch. #running-req: 1, #token: 1960, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:37:11] Decode batch. #running-req: 1, #token: 2000, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.81, #queue-req: 0, 
[2025-09-30 14:37:11] Decode batch. #running-req: 1, #token: 2040, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.76, #queue-req: 0, 
[2025-09-30 14:37:11] Decode batch. #running-req: 1, #token: 2080, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.45, #queue-req: 0, 
[2025-09-30 14:37:11] Decode batch. #running-req: 1, #token: 2120, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:37:12] Decode batch. #running-req: 1, #token: 2160, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:37:12] Decode batch. #running-req: 1, #token: 2200, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:37:12] Decode batch. #running-req: 1, #token: 2240, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:37:13] Decode batch. #running-req: 1, #token: 2280, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:37:13] Decode batch. #running-req: 1, #token: 2320, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.00, #queue-req: 0, 
[2025-09-30 14:37:13] Decode batch. #running-req: 1, #token: 2360, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:37:14] Decode batch. #running-req: 1, #token: 2400, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:37:14] Decode batch. #running-req: 1, #token: 2440, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:37:14] Decode batch. #running-req: 1, #token: 2480, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:37:15] Decode batch. #running-req: 1, #token: 2520, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:37:15] Decode batch. #running-req: 1, #token: 2560, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.52, #queue-req: 0, 
[2025-09-30 14:37:15] Decode batch. #running-req: 1, #token: 2600, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.10, #queue-req: 0, 
[2025-09-30 14:37:16] Decode batch. #running-req: 1, #token: 2640, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:37:16] Decode batch. #running-req: 1, #token: 2680, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:37:16] Decode batch. #running-req: 1, #token: 2720, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:37:17] Decode batch. #running-req: 1, #token: 2760, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:37:17] Decode batch. #running-req: 1, #token: 2800, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.93, #queue-req: 0, 
[2025-09-30 14:37:17] Decode batch. #running-req: 1, #token: 2840, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.66, #queue-req: 0, 
[2025-09-30 14:37:17] Decode batch. #running-req: 1, #token: 2880, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.52, #queue-req: 0, 
[2025-09-30 14:37:18] Decode batch. #running-req: 1, #token: 2920, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:37:18] Decode batch. #running-req: 1, #token: 2960, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:37:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:19] Prefill batch. #new-seq: 1, #new-token: 425, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:19] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:19] Decode batch. #running-req: 1, #token: 323, token usage: 0.01, cuda graph: True, gen throughput (token/s): 44.74, #queue-req: 0, 
[2025-09-30 14:37:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:19] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:19] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.03, #queue-req: 0, 
[2025-09-30 14:37:20] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.52, #queue-req: 0, 
[2025-09-30 14:37:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:20] Prefill batch. #new-seq: 1, #new-token: 433, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:20] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:21] Decode batch. #running-req: 1, #token: 509, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.42, #queue-req: 0, 
[2025-09-30 14:37:21] Decode batch. #running-req: 1, #token: 549, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0, 
[2025-09-30 14:37:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:21] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:21] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.28, #queue-req: 0, 
[2025-09-30 14:37:22] Decode batch. #running-req: 1, #token: 293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.39, #queue-req: 0, 
[2025-09-30 14:37:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:22] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:22] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:23] Decode batch. #running-req: 1, #token: 370, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.62, #queue-req: 0, 
[2025-09-30 14:37:23] Decode batch. #running-req: 1, #token: 410, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.25, #queue-req: 0, 
[2025-09-30 14:37:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:23] Prefill batch. #new-seq: 1, #new-token: 36, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:23] Decode batch. #running-req: 1, #token: 270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.56, #queue-req: 0, 
[2025-09-30 14:37:23] Decode batch. #running-req: 1, #token: 310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:37:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:24] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:24] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:24] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:25] Prefill batch. #new-seq: 1, #new-token: 1719, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:25] Decode batch. #running-req: 1, #token: 2063, token usage: 0.03, cuda graph: True, gen throughput (token/s): 28.70, #queue-req: 0, 
[2025-09-30 14:37:25] Decode batch. #running-req: 1, #token: 2103, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.26, #queue-req: 0, 
[2025-09-30 14:37:25] Decode batch. #running-req: 1, #token: 2143, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:37:26] Decode batch. #running-req: 1, #token: 2183, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:37:26] Decode batch. #running-req: 1, #token: 2223, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.17, #queue-req: 0, 
[2025-09-30 14:37:26] Decode batch. #running-req: 1, #token: 2263, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.20, #queue-req: 0, 
[2025-09-30 14:37:27] Decode batch. #running-req: 1, #token: 2303, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:37:27] Decode batch. #running-req: 1, #token: 2343, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.70, #queue-req: 0, 
[2025-09-30 14:37:27] Decode batch. #running-req: 1, #token: 2383, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:37:28] Decode batch. #running-req: 1, #token: 2423, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.68, #queue-req: 0, 
[2025-09-30 14:37:28] Decode batch. #running-req: 1, #token: 2463, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:37:28] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:28] Prefill batch. #new-seq: 1, #new-token: 1719, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:28] Decode batch. #running-req: 1, #token: 2060, token usage: 0.03, cuda graph: True, gen throughput (token/s): 97.29, #queue-req: 0, 
[2025-09-30 14:37:29] Decode batch. #running-req: 1, #token: 2100, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.28, #queue-req: 0, 
[2025-09-30 14:37:29] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:29] Prefill batch. #new-seq: 1, #new-token: 1468, #cached-token: 342, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:29] Decode batch. #running-req: 1, #token: 1835, token usage: 0.03, cuda graph: True, gen throughput (token/s): 101.92, #queue-req: 0, 
[2025-09-30 14:37:29] Decode batch. #running-req: 1, #token: 1875, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.88, #queue-req: 0, 
[2025-09-30 14:37:30] Decode batch. #running-req: 1, #token: 1915, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.76, #queue-req: 0, 
[2025-09-30 14:37:30] Decode batch. #running-req: 1, #token: 1955, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:37:30] Decode batch. #running-req: 1, #token: 1995, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.82, #queue-req: 0, 
[2025-09-30 14:37:31] Decode batch. #running-req: 1, #token: 2035, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.74, #queue-req: 0, 
[2025-09-30 14:37:31] Decode batch. #running-req: 1, #token: 2075, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.44, #queue-req: 0, 
[2025-09-30 14:37:31] Decode batch. #running-req: 1, #token: 2115, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:37:32] Decode batch. #running-req: 1, #token: 2155, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:37:32] Decode batch. #running-req: 1, #token: 2195, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:37:32] Decode batch. #running-req: 1, #token: 2235, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.21, #queue-req: 0, 
[2025-09-30 14:37:33] Decode batch. #running-req: 1, #token: 2275, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.15, #queue-req: 0, 
[2025-09-30 14:37:33] Decode batch. #running-req: 1, #token: 2315, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.04, #queue-req: 0, 
[2025-09-30 14:37:33] Decode batch. #running-req: 1, #token: 2355, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:37:33] Decode batch. #running-req: 1, #token: 2395, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.59, #queue-req: 0, 
[2025-09-30 14:37:34] Decode batch. #running-req: 1, #token: 2435, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:37:34] Decode batch. #running-req: 1, #token: 2475, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:37:34] Decode batch. #running-req: 1, #token: 2515, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:37:35] Decode batch. #running-req: 1, #token: 2555, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:37:35] Decode batch. #running-req: 1, #token: 2595, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.11, #queue-req: 0, 
[2025-09-30 14:37:35] Decode batch. #running-req: 1, #token: 2635, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:37:36] Decode batch. #running-req: 1, #token: 2675, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:37:36] Decode batch. #running-req: 1, #token: 2715, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:37:36] Decode batch. #running-req: 1, #token: 2755, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.99, #queue-req: 0, 
[2025-09-30 14:37:37] Decode batch. #running-req: 1, #token: 2795, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.90, #queue-req: 0, 
[2025-09-30 14:37:37] Decode batch. #running-req: 1, #token: 2835, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.65, #queue-req: 0, 
[2025-09-30 14:37:37] Decode batch. #running-req: 1, #token: 2875, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.45, #queue-req: 0, 
[2025-09-30 14:37:38] Decode batch. #running-req: 1, #token: 2915, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.32, #queue-req: 0, 
[2025-09-30 14:37:38] Decode batch. #running-req: 1, #token: 2955, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:37:38] Decode batch. #running-req: 1, #token: 2995, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:37:39] Decode batch. #running-req: 1, #token: 3035, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.30, #queue-req: 0, 
[2025-09-30 14:37:39] Decode batch. #running-req: 1, #token: 3075, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.24, #queue-req: 0, 
[2025-09-30 14:37:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:39] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:39] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:40] Decode batch. #running-req: 1, #token: 388, token usage: 0.01, cuda graph: True, gen throughput (token/s): 47.24, #queue-req: 0, 
[2025-09-30 14:37:40] Decode batch. #running-req: 1, #token: 428, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.23, #queue-req: 0, 
[2025-09-30 14:37:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:40] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:40] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.57, #queue-req: 0, 
[2025-09-30 14:37:41] Decode batch. #running-req: 1, #token: 336, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.23, #queue-req: 0, 
[2025-09-30 14:37:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:41] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:41] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:41] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 50.05, #queue-req: 0, 
[2025-09-30 14:37:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:41] Prefill batch. #new-seq: 1, #new-token: 34, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:42] Decode batch. #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.04, #queue-req: 0, 
[2025-09-30 14:37:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:42] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:42] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.36, #queue-req: 0, 
[2025-09-30 14:37:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:42] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:43] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:43] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:43] Decode batch. #running-req: 1, #token: 351, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.71, #queue-req: 0, 
[2025-09-30 14:37:43] Decode batch. #running-req: 1, #token: 391, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.26, #queue-req: 0, 
[2025-09-30 14:37:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:44] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:44] Decode batch. #running-req: 1, #token: 226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.92, #queue-req: 0, 
[2025-09-30 14:37:44] Decode batch. #running-req: 1, #token: 266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-30 14:37:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:44] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:44] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:45] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:45] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.80, #queue-req: 0, 
[2025-09-30 14:37:45] Decode batch. #running-req: 1, #token: 125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.93, #queue-req: 0, 
[2025-09-30 14:37:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:45] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 250, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:46] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:46] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.61, #queue-req: 0, 
[2025-09-30 14:37:46] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:46] Decode batch. #running-req: 1, #token: 332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:37:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:46] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:47] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.01, #queue-req: 0, 
[2025-09-30 14:37:47] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0, 
[2025-09-30 14:37:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:47] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:47] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:48] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:48] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.38, #queue-req: 0, 
[2025-09-30 14:37:48] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:48] Decode batch. #running-req: 1, #token: 416, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.79, #queue-req: 0, 
[2025-09-30 14:37:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:49] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:49] Decode batch. #running-req: 1, #token: 220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.31, #queue-req: 0, 
[2025-09-30 14:37:49] Decode batch. #running-req: 1, #token: 260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.72, #queue-req: 0, 
[2025-09-30 14:37:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:49] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:49] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:49] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:50] Decode batch. #running-req: 1, #token: 298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 64.04, #queue-req: 0, 
[2025-09-30 14:37:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:50] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:50] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:50] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:50] Decode batch. #running-req: 1, #token: 363, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.09, #queue-req: 0, 
[2025-09-30 14:37:51] Decode batch. #running-req: 1, #token: 403, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.18, #queue-req: 0, 
[2025-09-30 14:37:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:51] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:51] Decode batch. #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.21, #queue-req: 0, 
[2025-09-30 14:37:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:51] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:51] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 114.86, #queue-req: 0, 
[2025-09-30 14:37:51] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:51] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:52] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:52] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:52] Decode batch. #running-req: 1, #token: 337, token usage: 0.01, cuda graph: True, gen throughput (token/s): 38.07, #queue-req: 0, 
[2025-09-30 14:37:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:53] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 197, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:53] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:37:53] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.69, #queue-req: 0, 
[2025-09-30 14:37:53] Decode batch. #running-req: 1, #token: 296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:37:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:53] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:53] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:53] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:54] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:54] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:54] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 37.45, #queue-req: 0, 
[2025-09-30 14:37:54] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:55] Decode batch. #running-req: 1, #token: 550, token usage: 0.01, cuda graph: True, gen throughput (token/s): 120.81, #queue-req: 0, 
[2025-09-30 14:37:55] Decode batch. #running-req: 1, #token: 590, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.12, #queue-req: 0, 
[2025-09-30 14:37:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:55] Prefill batch. #new-seq: 1, #new-token: 25, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:55] Decode batch. #running-req: 1, #token: 253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.13, #queue-req: 0, 
[2025-09-30 14:37:55] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:55] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:56] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:56] Decode batch. #running-req: 1, #token: 427, token usage: 0.01, cuda graph: True, gen throughput (token/s): 102.88, #queue-req: 0, 
[2025-09-30 14:37:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:56] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:56] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:56] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:56] Decode batch. #running-req: 1, #token: 518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 49.25, #queue-req: 0, 
[2025-09-30 14:37:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:57] Prefill batch. #new-seq: 1, #new-token: 29, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:57] Decode batch. #running-req: 1, #token: 239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.51, #queue-req: 0, 
[2025-09-30 14:37:57] Decode batch. #running-req: 1, #token: 279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0, 
[2025-09-30 14:37:57] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:57] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:57] Decode batch. #running-req: 1, #token: 96, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.33, #queue-req: 0, 
[2025-09-30 14:37:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:58] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:58] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:58] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:58] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:59] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.00, #queue-req: 0, 
[2025-09-30 14:37:59] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0, 
[2025-09-30 14:37:59] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:37:59] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:37:59] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.88, #queue-req: 0, 
[2025-09-30 14:37:59] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.33, #queue-req: 0, 
[2025-09-30 14:38:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:00] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:00] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:00] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 67.86, #queue-req: 0, 
[2025-09-30 14:38:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:00] Prefill batch. #new-seq: 1, #new-token: 439, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:00] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:01] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:01] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:01] Decode batch. #running-req: 1, #token: 214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.27, #queue-req: 0, 
[2025-09-30 14:38:01] Decode batch. #running-req: 1, #token: 254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.76, #queue-req: 0, 
[2025-09-30 14:38:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:01] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:01] Decode batch. #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.64, #queue-req: 0, 
[2025-09-30 14:38:01] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:01] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:02] Prefill batch. #new-seq: 1, #new-token: 567, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:02] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:02] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:03] Decode batch. #running-req: 1, #token: 437, token usage: 0.01, cuda graph: True, gen throughput (token/s): 37.07, #queue-req: 0, 
[2025-09-30 14:38:03] Decode batch. #running-req: 1, #token: 477, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.00, #queue-req: 0, 
[2025-09-30 14:38:03] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:03] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:03] Decode batch. #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.53, #queue-req: 0, 
[2025-09-30 14:38:03] Decode batch. #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.61, #queue-req: 0, 
[2025-09-30 14:38:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:04] Prefill batch. #new-seq: 1, #new-token: 15, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:04] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:04] Decode batch. #running-req: 1, #token: 362, token usage: 0.01, cuda graph: True, gen throughput (token/s): 103.60, #queue-req: 0, 
[2025-09-30 14:38:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:05] Prefill batch. #new-seq: 1, #new-token: 505, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:05] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:05] Decode batch. #running-req: 1, #token: 511, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.58, #queue-req: 0, 
[2025-09-30 14:38:05] Decode batch. #running-req: 1, #token: 551, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.37, #queue-req: 0, 
[2025-09-30 14:38:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:06] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:06] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.08, #queue-req: 0, 
[2025-09-30 14:38:06] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.47, #queue-req: 0, 
[2025-09-30 14:38:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:06] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:06] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:07] Prefill batch. #new-seq: 1, #new-token: 13, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:07] Decode batch. #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.00, #queue-req: 0, 
[2025-09-30 14:38:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:07] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 310, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:07] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 123.14, #queue-req: 0, 
[2025-09-30 14:38:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:08] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:08] Prefill batch. #new-seq: 1, #new-token: 32, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:08] Prefill batch. #new-seq: 1, #new-token: 9, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:08] Decode batch. #running-req: 1, #token: 206, token usage: 0.00, cuda graph: True, gen throughput (token/s): 40.16, #queue-req: 0, 
[2025-09-30 14:38:09] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.71, #queue-req: 0, 
[2025-09-30 14:38:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:09] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:09] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:09] Decode batch. #running-req: 1, #token: 112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 56.59, #queue-req: 0, 
[2025-09-30 14:38:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:10] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:10] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:10] Decode batch. #running-req: 1, #token: 261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 41.09, #queue-req: 0, 
[2025-09-30 14:38:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:10] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:11] Decode batch. #running-req: 1, #token: 252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 126.47, #queue-req: 0, 
[2025-09-30 14:38:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:11] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 74, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:11] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:11] Decode batch. #running-req: 1, #token: 156, token usage: 0.00, cuda graph: True, gen throughput (token/s): 107.34, #queue-req: 0, 
[2025-09-30 14:38:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:12] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:12] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:12] Decode batch. #running-req: 1, #token: 340, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.90, #queue-req: 0, 
[2025-09-30 14:38:12] Decode batch. #running-req: 1, #token: 380, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.32, #queue-req: 0, 
[2025-09-30 14:38:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:12] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:13] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.61, #queue-req: 0, 
[2025-09-30 14:38:13] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.36, #queue-req: 0, 
[2025-09-30 14:38:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:14] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:14] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:14] Decode batch. #running-req: 1, #token: 348, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.15, #queue-req: 0, 
[2025-09-30 14:38:14] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:14] Prefill batch. #new-seq: 1, #new-token: 37, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:14] Decode batch. #running-req: 1, #token: 246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:38:15] Decode batch. #running-req: 1, #token: 286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.45, #queue-req: 0, 
[2025-09-30 14:38:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:15] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:15] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 58.71, #queue-req: 0, 
[2025-09-30 14:38:15] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:15] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:16] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:16] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:16] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:16] Decode batch. #running-req: 1, #token: 281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.13, #queue-req: 0, 
[2025-09-30 14:38:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:17] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:17] Decode batch. #running-req: 1, #token: 238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.06, #queue-req: 0, 
[2025-09-30 14:38:17] Decode batch. #running-req: 1, #token: 278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:38:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:17] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:17] Decode batch. #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 113.67, #queue-req: 0, 
[2025-09-30 14:38:17] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:17] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:18] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:19] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:19] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:19] Decode batch. #running-req: 1, #token: 308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 29.49, #queue-req: 0, 
[2025-09-30 14:38:19] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:19] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:19] Decode batch. #running-req: 1, #token: 232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.14, #queue-req: 0, 
[2025-09-30 14:38:19] Decode batch. #running-req: 1, #token: 272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.59, #queue-req: 0, 
[2025-09-30 14:38:20] Decode batch. #running-req: 1, #token: 312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:38:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:20] Prefill batch. #new-seq: 1, #new-token: 16, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:20] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:20] Decode batch. #running-req: 1, #token: 212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 111.95, #queue-req: 0, 
[2025-09-30 14:38:20] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:21] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:21] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 206, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:21] Decode batch. #running-req: 1, #token: 215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 39.60, #queue-req: 0, 
[2025-09-30 14:38:21] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:22] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:22] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:22] Decode batch. #running-req: 1, #token: 361, token usage: 0.01, cuda graph: True, gen throughput (token/s): 40.09, #queue-req: 0, 
[2025-09-30 14:38:22] Decode batch. #running-req: 1, #token: 401, token usage: 0.01, cuda graph: True, gen throughput (token/s): 132.38, #queue-req: 0, 
[2025-09-30 14:38:22] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:22] Prefill batch. #new-seq: 1, #new-token: 45, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:23] Decode batch. #running-req: 1, #token: 275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 125.62, #queue-req: 0, 
[2025-09-30 14:38:23] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.29, #queue-req: 0, 
[2025-09-30 14:38:23] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:24] Prefill batch. #new-seq: 1, #new-token: 835, #cached-token: 339, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:24] Decode batch. #running-req: 1, #token: 1203, token usage: 0.02, cuda graph: True, gen throughput (token/s): 37.57, #queue-req: 0, 
[2025-09-30 14:38:24] Decode batch. #running-req: 1, #token: 1243, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:38:25] Decode batch. #running-req: 1, #token: 1283, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:38:25] Decode batch. #running-req: 1, #token: 1323, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.25, #queue-req: 0, 
[2025-09-30 14:38:25] Decode batch. #running-req: 1, #token: 1363, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.17, #queue-req: 0, 
[2025-09-30 14:38:25] Decode batch. #running-req: 1, #token: 1403, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.11, #queue-req: 0, 
[2025-09-30 14:38:26] Decode batch. #running-req: 1, #token: 1443, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:38:26] Decode batch. #running-req: 1, #token: 1483, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-09-30 14:38:26] Decode batch. #running-req: 1, #token: 1523, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:38:27] Decode batch. #running-req: 1, #token: 1563, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.81, #queue-req: 0, 
[2025-09-30 14:38:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:27] Prefill batch. #new-seq: 1, #new-token: 835, #cached-token: 319, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:27] Decode batch. #running-req: 1, #token: 1168, token usage: 0.02, cuda graph: True, gen throughput (token/s): 110.94, #queue-req: 0, 
[2025-09-30 14:38:27] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:27] Prefill batch. #new-seq: 1, #new-token: 1653, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:27] Decode batch. #running-req: 1, #token: 1792, token usage: 0.03, cuda graph: True, gen throughput (token/s): 100.96, #queue-req: 0, 
[2025-09-30 14:38:28] Decode batch. #running-req: 1, #token: 1832, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.92, #queue-req: 0, 
[2025-09-30 14:38:28] Decode batch. #running-req: 1, #token: 1872, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:38:28] Decode batch. #running-req: 1, #token: 1912, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.79, #queue-req: 0, 
[2025-09-30 14:38:29] Decode batch. #running-req: 1, #token: 1952, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:38:29] Decode batch. #running-req: 1, #token: 1992, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.87, #queue-req: 0, 
[2025-09-30 14:38:29] Decode batch. #running-req: 1, #token: 2032, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.75, #queue-req: 0, 
[2025-09-30 14:38:30] Decode batch. #running-req: 1, #token: 2072, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.50, #queue-req: 0, 
[2025-09-30 14:38:30] Decode batch. #running-req: 1, #token: 2112, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.23, #queue-req: 0, 
[2025-09-30 14:38:30] Decode batch. #running-req: 1, #token: 2152, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.16, #queue-req: 0, 
[2025-09-30 14:38:31] Decode batch. #running-req: 1, #token: 2192, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.12, #queue-req: 0, 
[2025-09-30 14:38:31] Decode batch. #running-req: 1, #token: 2232, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.18, #queue-req: 0, 
[2025-09-30 14:38:31] Decode batch. #running-req: 1, #token: 2272, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.12, #queue-req: 0, 
[2025-09-30 14:38:32] Decode batch. #running-req: 1, #token: 2312, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.08, #queue-req: 0, 
[2025-09-30 14:38:32] Decode batch. #running-req: 1, #token: 2352, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0, 
[2025-09-30 14:38:32] Decode batch. #running-req: 1, #token: 2392, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.66, #queue-req: 0, 
[2025-09-30 14:38:32] Decode batch. #running-req: 1, #token: 2432, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.57, #queue-req: 0, 
[2025-09-30 14:38:33] Decode batch. #running-req: 1, #token: 2472, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:38:33] Decode batch. #running-req: 1, #token: 2512, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:38:33] Decode batch. #running-req: 1, #token: 2552, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:38:34] Decode batch. #running-req: 1, #token: 2592, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.19, #queue-req: 0, 
[2025-09-30 14:38:34] Decode batch. #running-req: 1, #token: 2632, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:38:34] Decode batch. #running-req: 1, #token: 2672, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.02, #queue-req: 0, 
[2025-09-30 14:38:35] Decode batch. #running-req: 1, #token: 2712, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.95, #queue-req: 0, 
[2025-09-30 14:38:35] Decode batch. #running-req: 1, #token: 2752, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.98, #queue-req: 0, 
[2025-09-30 14:38:35] Decode batch. #running-req: 1, #token: 2792, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.97, #queue-req: 0, 
[2025-09-30 14:38:36] Decode batch. #running-req: 1, #token: 2832, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.72, #queue-req: 0, 
[2025-09-30 14:38:36] Decode batch. #running-req: 1, #token: 2872, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.39, #queue-req: 0, 
[2025-09-30 14:38:36] Decode batch. #running-req: 1, #token: 2912, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.38, #queue-req: 0, 
[2025-09-30 14:38:37] Decode batch. #running-req: 1, #token: 2952, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:38:37] Decode batch. #running-req: 1, #token: 2992, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.34, #queue-req: 0, 
[2025-09-30 14:38:37] Decode batch. #running-req: 1, #token: 3032, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.35, #queue-req: 0, 
[2025-09-30 14:38:38] Decode batch. #running-req: 1, #token: 3072, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.36, #queue-req: 0, 
[2025-09-30 14:38:38] Decode batch. #running-req: 1, #token: 3112, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.81, #queue-req: 0, 
[2025-09-30 14:38:38] Decode batch. #running-req: 1, #token: 3152, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.82, #queue-req: 0, 
[2025-09-30 14:38:39] Decode batch. #running-req: 1, #token: 3192, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:38:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:39] Prefill batch. #new-seq: 1, #new-token: 872, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:39] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:39] Prefill batch. #new-seq: 1, #new-token: 744, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:39] Decode batch. #running-req: 1, #token: 933, token usage: 0.01, cuda graph: True, gen throughput (token/s): 41.93, #queue-req: 0, 
[2025-09-30 14:38:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:40] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:40] Decode batch. #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.67, #queue-req: 0, 
[2025-09-30 14:38:40] Decode batch. #running-req: 1, #token: 322, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:38:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:40] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:40] Prefill batch. #new-seq: 1, #new-token: 740, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:41] Decode batch. #running-req: 1, #token: 817, token usage: 0.01, cuda graph: True, gen throughput (token/s): 99.03, #queue-req: 0, 
[2025-09-30 14:38:41] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:42] Prefill batch. #new-seq: 1, #new-token: 1362, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:42] Prefill batch. #new-seq: 1, #new-token: 622, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:42] Decode batch. #running-req: 1, #token: 805, token usage: 0.01, cuda graph: True, gen throughput (token/s): 30.16, #queue-req: 0, 
[2025-09-30 14:38:42] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:42] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:42] Decode batch. #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.52, #queue-req: 0, 
[2025-09-30 14:38:42] Decode batch. #running-req: 1, #token: 344, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.28, #queue-req: 0, 
[2025-09-30 14:38:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:43] Prefill batch. #new-seq: 1, #new-token: 1235, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:43] Prefill batch. #new-seq: 1, #new-token: 615, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:43] Decode batch. #running-req: 1, #token: 801, token usage: 0.01, cuda graph: True, gen throughput (token/s): 43.46, #queue-req: 0, 
[2025-09-30 14:38:43] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:43] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:44] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.94, #queue-req: 0, 
[2025-09-30 14:38:44] Decode batch. #running-req: 1, #token: 345, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0, 
[2025-09-30 14:38:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:44] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:44] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:44] Prefill batch. #new-seq: 1, #new-token: 613, #cached-token: 75, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:44] Decode batch. #running-req: 1, #token: 690, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.78, #queue-req: 0, 
[2025-09-30 14:38:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:45] Prefill batch. #new-seq: 1, #new-token: 1170, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:45] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:45] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:46] Decode batch. #running-req: 1, #token: 738, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.87, #queue-req: 0, 
[2025-09-30 14:38:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:46] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 195, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:46] Decode batch. #running-req: 1, #token: 285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 123.21, #queue-req: 0, 
[2025-09-30 14:38:46] Decode batch. #running-req: 1, #token: 325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.31, #queue-req: 0, 
[2025-09-30 14:38:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:46] Prefill batch. #new-seq: 1, #new-token: 23, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:46] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:46] Prefill batch. #new-seq: 1, #new-token: 558, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:47] Decode batch. #running-req: 1, #token: 639, token usage: 0.01, cuda graph: True, gen throughput (token/s): 101.83, #queue-req: 0, 
[2025-09-30 14:38:47] Decode batch. #running-req: 1, #token: 679, token usage: 0.01, cuda graph: True, gen throughput (token/s): 131.49, #queue-req: 0, 
[2025-09-30 14:38:47] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:47] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:48] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 629, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:48] Decode batch. #running-req: 1, #token: 643, token usage: 0.01, cuda graph: True, gen throughput (token/s): 48.39, #queue-req: 0, 
[2025-09-30 14:38:48] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:48] Prefill batch. #new-seq: 1, #new-token: 870, #cached-token: 340, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:49] Decode batch. #running-req: 1, #token: 1215, token usage: 0.02, cuda graph: True, gen throughput (token/s): 48.55, #queue-req: 0, 
[2025-09-30 14:38:49] Decode batch. #running-req: 1, #token: 1255, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.67, #queue-req: 0, 
[2025-09-30 14:38:49] Decode batch. #running-req: 1, #token: 1295, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.54, #queue-req: 0, 
[2025-09-30 14:38:49] Decode batch. #running-req: 1, #token: 1335, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.27, #queue-req: 0, 
[2025-09-30 14:38:50] Decode batch. #running-req: 1, #token: 1375, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.15, #queue-req: 0, 
[2025-09-30 14:38:50] Decode batch. #running-req: 1, #token: 1415, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.13, #queue-req: 0, 
[2025-09-30 14:38:50] Decode batch. #running-req: 1, #token: 1455, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.14, #queue-req: 0, 
[2025-09-30 14:38:51] Decode batch. #running-req: 1, #token: 1495, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:38:51] Decode batch. #running-req: 1, #token: 1535, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.08, #queue-req: 0, 
[2025-09-30 14:38:51] Decode batch. #running-req: 1, #token: 1575, token usage: 0.02, cuda graph: True, gen throughput (token/s): 128.65, #queue-req: 0, 
[2025-09-30 14:38:52] Decode batch. #running-req: 1, #token: 1615, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.59, #queue-req: 0, 
[2025-09-30 14:38:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:52] Prefill batch. #new-seq: 1, #new-token: 870, #cached-token: 320, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:52] Decode batch. #running-req: 1, #token: 1211, token usage: 0.02, cuda graph: True, gen throughput (token/s): 109.96, #queue-req: 0, 
[2025-09-30 14:38:52] Decode batch. #running-req: 1, #token: 1251, token usage: 0.02, cuda graph: True, gen throughput (token/s): 129.76, #queue-req: 0, 
[2025-09-30 14:38:52] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:38:52] Prefill batch. #new-seq: 1, #new-token: 1836, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:38:53] Decode batch. #running-req: 1, #token: 1991, token usage: 0.03, cuda graph: True, gen throughput (token/s): 97.84, #queue-req: 0, 
[2025-09-30 14:38:53] Decode batch. #running-req: 1, #token: 2031, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.83, #queue-req: 0, 
[2025-09-30 14:38:53] Decode batch. #running-req: 1, #token: 2071, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.50, #queue-req: 0, 
[2025-09-30 14:38:54] Decode batch. #running-req: 1, #token: 2111, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.25, #queue-req: 0, 
[2025-09-30 14:38:54] Decode batch. #running-req: 1, #token: 2151, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.31, #queue-req: 0, 
[2025-09-30 14:38:54] Decode batch. #running-req: 1, #token: 2191, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.22, #queue-req: 0, 
[2025-09-30 14:38:55] Decode batch. #running-req: 1, #token: 2231, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.24, #queue-req: 0, 
[2025-09-30 14:38:55] Decode batch. #running-req: 1, #token: 2271, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.13, #queue-req: 0, 
[2025-09-30 14:38:55] Decode batch. #running-req: 1, #token: 2311, token usage: 0.04, cuda graph: True, gen throughput (token/s): 127.07, #queue-req: 0, 
[2025-09-30 14:38:56] Decode batch. #running-req: 1, #token: 2351, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.64, #queue-req: 0, 
[2025-09-30 14:38:56] Decode batch. #running-req: 1, #token: 2391, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.65, #queue-req: 0, 
[2025-09-30 14:38:56] Decode batch. #running-req: 1, #token: 2431, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.62, #queue-req: 0, 
[2025-09-30 14:38:56] Decode batch. #running-req: 1, #token: 2471, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.57, #queue-req: 0, 
[2025-09-30 14:38:57] Decode batch. #running-req: 1, #token: 2511, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.56, #queue-req: 0, 
[2025-09-30 14:38:57] Decode batch. #running-req: 1, #token: 2551, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.60, #queue-req: 0, 
[2025-09-30 14:38:57] Decode batch. #running-req: 1, #token: 2591, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.19, #queue-req: 0, 
[2025-09-30 14:38:58] Decode batch. #running-req: 1, #token: 2631, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.09, #queue-req: 0, 
[2025-09-30 14:38:58] Decode batch. #running-req: 1, #token: 2671, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.06, #queue-req: 0, 
[2025-09-30 14:38:58] Decode batch. #running-req: 1, #token: 2711, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:38:59] Decode batch. #running-req: 1, #token: 2751, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.03, #queue-req: 0, 
[2025-09-30 14:38:59] Decode batch. #running-req: 1, #token: 2791, token usage: 0.04, cuda graph: True, gen throughput (token/s): 126.00, #queue-req: 0, 
[2025-09-30 14:38:59] Decode batch. #running-req: 1, #token: 2831, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.78, #queue-req: 0, 
[2025-09-30 14:39:00] Decode batch. #running-req: 1, #token: 2871, token usage: 0.04, cuda graph: True, gen throughput (token/s): 125.40, #queue-req: 0, 
[2025-09-30 14:39:00] Decode batch. #running-req: 1, #token: 2911, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.43, #queue-req: 0, 
[2025-09-30 14:39:00] Decode batch. #running-req: 1, #token: 2951, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.42, #queue-req: 0, 
[2025-09-30 14:39:01] Decode batch. #running-req: 1, #token: 2991, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.32, #queue-req: 0, 
[2025-09-30 14:39:01] Decode batch. #running-req: 1, #token: 3031, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.30, #queue-req: 0, 
[2025-09-30 14:39:01] Decode batch. #running-req: 1, #token: 3071, token usage: 0.05, cuda graph: True, gen throughput (token/s): 125.30, #queue-req: 0, 
[2025-09-30 14:39:02] Decode batch. #running-req: 1, #token: 3111, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.90, #queue-req: 0, 
[2025-09-30 14:39:02] Decode batch. #running-req: 1, #token: 3151, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.79, #queue-req: 0, 
[2025-09-30 14:39:02] Decode batch. #running-req: 1, #token: 3191, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.75, #queue-req: 0, 
[2025-09-30 14:39:03] Decode batch. #running-req: 1, #token: 3231, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:39:03] Decode batch. #running-req: 1, #token: 3271, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.78, #queue-req: 0, 
[2025-09-30 14:39:03] Decode batch. #running-req: 1, #token: 3311, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.69, #queue-req: 0, 
[2025-09-30 14:39:03] Decode batch. #running-req: 1, #token: 3351, token usage: 0.05, cuda graph: True, gen throughput (token/s): 124.45, #queue-req: 0, 
[2025-09-30 14:39:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:04] Prefill batch. #new-seq: 1, #new-token: 1149, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:04] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:04] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:04] Decode batch. #running-req: 1, #token: 768, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.77, #queue-req: 0, 
[2025-09-30 14:39:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:05] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:05] Decode batch. #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.70, #queue-req: 0, 
[2025-09-30 14:39:05] Decode batch. #running-req: 1, #token: 347, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.18, #queue-req: 0, 
[2025-09-30 14:39:05] Decode batch. #running-req: 1, #token: 387, token usage: 0.01, cuda graph: True, gen throughput (token/s): 133.14, #queue-req: 0, 
[2025-09-30 14:39:05] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:05] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:06] Prefill batch. #new-seq: 1, #new-token: 586, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:06] Decode batch. #running-req: 1, #token: 691, token usage: 0.01, cuda graph: True, gen throughput (token/s): 105.22, #queue-req: 0, 
[2025-09-30 14:39:06] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:07] Prefill batch. #new-seq: 1, #new-token: 986, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:07] Prefill batch. #new-seq: 1, #new-token: 398, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:07] Decode batch. #running-req: 1, #token: 577, token usage: 0.01, cuda graph: True, gen throughput (token/s): 36.68, #queue-req: 0, 
[2025-09-30 14:39:07] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:07] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:07] Decode batch. #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.31, #queue-req: 0, 
[2025-09-30 14:39:08] Decode batch. #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.30, #queue-req: 0, 
[2025-09-30 14:39:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:08] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:08] Decode batch. #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 119.38, #queue-req: 0, 
[2025-09-30 14:39:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:08] Prefill batch. #new-seq: 1, #new-token: 394, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:08] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:09] Prefill batch. #new-seq: 1, #new-token: 827, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:09] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:09] Prefill batch. #new-seq: 1, #new-token: 437, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:09] Decode batch. #running-req: 1, #token: 604, token usage: 0.01, cuda graph: True, gen throughput (token/s): 35.11, #queue-req: 0, 
[2025-09-30 14:39:09] Decode batch. #running-req: 1, #token: 644, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.76, #queue-req: 0, 
[2025-09-30 14:39:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:10] Prefill batch. #new-seq: 1, #new-token: 52, #cached-token: 194, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:10] Decode batch. #running-req: 1, #token: 250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 122.64, #queue-req: 0, 
[2025-09-30 14:39:10] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 133.46, #queue-req: 0, 
[2025-09-30 14:39:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:10] Prefill batch. #new-seq: 1, #new-token: 12, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:10] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.39, #queue-req: 0, 
[2025-09-30 14:39:10] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:10] Prefill batch. #new-seq: 1, #new-token: 432, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:11] Prefill batch. #new-seq: 1, #new-token: 14, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:11] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 46.52, #queue-req: 0, 
[2025-09-30 14:39:11] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 502, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:11] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:12] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 76, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:12] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:12] Decode batch. #running-req: 1, #token: 315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 45.77, #queue-req: 0, 
[2025-09-30 14:39:12] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:12] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:12] Decode batch. #running-req: 1, #token: 290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 124.40, #queue-req: 0, 
[2025-09-30 14:39:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:13] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:13] Decode batch. #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 117.25, #queue-req: 0, 
[2025-09-30 14:39:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 14:39:13] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-30 14:39:13] INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-09-30 17:31:06] INFO:     127.0.0.1:50198 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 17:41:06] [http_server] Error: Request is disconnected from the client side (type 1). Abort request obj.rid='9cebb93fb4d94f06b1dd7f15e603fc5c'
[2025-09-30 17:47:43] INFO:     127.0.0.1:43392 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-30 17:48:55] [http_server] Error: Request is disconnected from the client side (type 1). Abort request obj.rid='12c490f6e87e46fabd42f8b1025edf1e'
